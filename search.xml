<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>NameSpace</title>
      <link href="/2021/02/01/%E5%88%86%E5%B8%83%E5%BC%8F/docker/NameSpace/"/>
      <url>/2021/02/01/%E5%88%86%E5%B8%83%E5%BC%8F/docker/NameSpace/</url>
      
        <content type="html"><![CDATA[<h2 id="简介">简介</h2><p>基于 NameSpace 实现对于 进程的资源隔离,linux 内核提供6种namespace隔离的系统调用,内容分别是Cgroup、主机名/域名、信号量和消息队列以及共享内存、进程编号、网络设备和端口、挂载点/文件系统、用户和用户组,借助此实现轻量级的虚拟化技术.</p><h2 id="namespace的系统调用">Namespace的系统调用</h2><p>NameSpace 的API包括clone、setns、unshare、ioctl</p><h3 id="clone">clone</h3><p>clone会创建一个新的系统进程,如果其参数中包含CLONE_NEW*,会创建一个包含该进程的新namespace。</p><h3 id="setns">setns</h3><p>让调用的进程加入已存的某个namespace</p><h3 id="unshare">unshare</h3><p>将调用进程从当前namespace迁移至新的namespace下。如果调用参数中包含CLONE_NEW*，会新建一个namespace包含调用进程。</p><h3 id="ioctl">ioctl</h3><p>用于查明 namespace 的信息。</p><h3 id></h3><h2 id="参考">参考</h2><p>1.<a href="https://man7.org/linux/man-pages/man7/namespaces.7.html" target="_blank" rel="noopener">namespaces — Linux manual page</a><br>2.<a href="https://blog.csdn.net/qq_37133717/article/details/86359947" target="_blank" rel="noopener">Docker核心原理之namespace</a><br>3.<a href="https://www.toptal.com/linux/separation-anxiety-isolating-your-system-with-linux-namespaces" target="_blank" rel="noopener">separation-anxiety-isolating-your-system-with-linux-namespaces</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> k8s container </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker文件系统</title>
      <link href="/2021/02/01/%E5%88%86%E5%B8%83%E5%BC%8F/docker/docker%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
      <url>/2021/02/01/%E5%88%86%E5%B8%83%E5%BC%8F/docker/docker%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<p>docker</p><h2 id="container-vs-vm">container VS Vm</h2><p>借助 CGroup 和 NameSpace 的帮助下,container 是一个隔离和限制的子系统.<br>基于 contronl group 可以对任意进程进行分组化管理,限制进程组的CPU,IO时间,内存等资源使用.<br>基于 NameSpace 实现对于 进程的资源隔离,linux 内核提供6种namespace隔离的系统调用,内容分别是主机名/域名、信号量和消息队列以及共享内存、进程编号、网络设备和端口、挂载点/文件系统、用户和用户组,借助此实现轻量级的虚拟化技术.<br>同一个namespace下的进程可以感受彼此的变化,且无法感知外界进程,相互间资源隔离;同一个cgroup下的进程共享资源,group之间互不干扰.</p><h2 id="docker-文件系统">docker 文件系统</h2><p>docker 中常见的三种文件系统: AUFS、DeviceMapper、OverlayFS.他们都是联合文件系统(Union File System,Unionfs)概念的具体实现.<br>联合文件系统指一种分层的轻量级文件系统,它可以把多个目录内容联合挂载在同一个目录下,从而形成一个单一的文件系统，使得用户可以如同使用一个文件系统一样使用联合文件系统.</p><h3 id="相关概念-镜像与容器">相关概念 : 镜像与容器</h3><p>Image 是只读的文件,包含源代码,依赖,动态链接,工具以及其他必须文件以支持程序运行.有时镜像也被称为快照,包含某一时刻的应用以及运行环境.当我们基于镜像创建Container时,会只读Image之上创建可写层(Container Layer),真正修改时,采取写时复制技术,将写的内容拷贝到分配的可写层空间,并修改(删除时并没有真正删除而是创建新的文件/文件夹拒绝对于’删除’的文件/文件夹的访问).</p><p>Container是虚拟运行时环境,基于此可以隔离应用.Container 是小型的可移植的单元,便于快速启动应用.(Vm提供硬件层面的虚拟,Container提供应用层面的虚拟).</p><p>Image 和 Container 都是docker平台的组成部分且相互联系.<br>Image可以独立存在,而Container需要基于Image构建运行时环境以支持应用运行.</p><p>我们定义Dockerfile脚本指定如何操作image,通过 docker build 运行 Image 变为 Container,同时我们也可以将修改过的Image/Container转变为新的Image.</p><h3 id="数据卷-volume">数据卷 volume</h3><h3 id="aufs"><a href="https://docs.docker.com/storage/storagedriver/aufs-driver/" target="_blank" rel="noopener">AUFS</a></h3><p>Another UFS/Alternative UFS<br>在AUFS 将不同的目录称之为branches,Docker中称之为layers。</p><h4 id="目录修改">目录修改</h4><p>关于Image和Container的信息被存储在<code>/var/lib/docker/aufs/</code>目录下</p><ul><li><code>diff/</code>:存储每个layer的内容，子目录名为镜像ID，该文件夹下包含一个存储该镜像父镜像ID的文件。</li><li><code>layers/</code>:存储image层关系(如何层层叠叠)的元信息。对于每个image和container，在该目录下存在一个文件描述相应信息。</li><li><code>mnt/</code>:image和container的挂载点。一般用于集合容器目录和挂载容器的联合文件系统。image由于是只读的，通常是空目录。</li></ul><p>当container运行(镜像生成容器)时，上述目录发生以下变化</p><ul><li><code>diff/</code>:生成容器层/可写层，包含父镜像的修改,例如新文件或者修改内容。</li><li><code>layers/</code>:新的容器层/可写层的父层。</li><li><code>mnt/</code>:容器的联合挂载点，这和容器中看到的文件内容一致。</li></ul><h4 id="aufs中container读写的方式">aufs中container读写的方式</h4><p>读文件</p><ul><li>文件不存在于容器层:当container读一个并不存在于容器层的文件时，会向其下一层寻找文件(递归),从找到的那一层读取.</li><li>文件只存在于容器层:从容器层读取。</li><li>文件在容器层和镜像层中都存在:如果container读取同时存在于此容器层和多个image层的文件时，从容器层读取.容器层的文件覆盖(obscure)了image层的同路径文件.</li></ul><p>修改文件</p><ul><li>第一次修改文件:当container第一次修改一个文件时，改文件并不存在于该container层。AUFS 驱动器会寻找从其下的image层递归寻找该文件，找到后拷贝到container可写层，进行写操作.需要注意的是，aufs的copy操作是拷贝整个文件而不是基于块的，即使修改只涉及大文件的一小部分。这种情况对容器写的性能影响较大，同时在存在多层的image中寻找文件也有不可忽视的延时。但是这种方式方便了后续的写操作，直接在container层的文件拷贝中写即可。</li><li>删除文件和目录:当container删除一个文件/目录时，并不会在只读的image操作实际操作，aufs会在container层生成特殊文件,阻碍从container层对于该文件/目录的访问。</li><li>重命名目录: <code>rename</code>系统调用在 aufs 中不支持。</li></ul><h3 id="devicemapper">DeviceMapper</h3><h3 id="overlayfs"><a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/" target="_blank" rel="noopener">OverlayFS</a></h3><p>OverlayFS 是类似于AUFS的联合文件系统，但是通过简单的继承实现更快的速度。它有两个版本，overlay和更新更稳定的overlay2</p><h4 id="overlay的运行">overlay的运行</h4><p>overlay文件系统中有两种目录，处于相对底层的目录称为lowerdir 和 处于相对高层的目录称为upperdir，此外暴露出的联合视角的目录称之为 merge;将目录称为layer，而联合的过程称为联合挂载。如下图所示：<br><img src="/images/ocerlay_constructs.jpg" alt="overlay 文件结构"><br>当文件同时存在于container层和image层时，container层的文件被读写，掩盖了image层相应文件的存在。</p><p>参考:<br>1.<a href="https://blog.csdn.net/qq_37133717/article/details/86359947" target="_blank" rel="noopener">Docker核心原理之namespace</a><br>2.<a href="https://blog.csdn.net/ningyuxuan123/article/details/81981835" target="_blank" rel="noopener">docker的cgroup</a><br>3.<a href="https://www.cnblogs.com/goWithHappy/p/thress-file-system-for-docker.html" target="_blank" rel="noopener">Docker三种文件系统总结</a><br>4.<a href="https://phoenixnap.com/kb/docker-image-vs-container" target="_blank" rel="noopener">Image VS Container</a><br>5.<a href="https://docs.docker.com/storage/storagedriver/aufs-driver/" target="_blank" rel="noopener">docker-aufs</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> k8s container </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>程序员修炼之道</title>
      <link href="/2021/01/03/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/"/>
      <url>/2021/01/03/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> 书籍 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go语言实战</title>
      <link href="/2021/01/03/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/Go%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98/"/>
      <url>/2021/01/03/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/Go%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/goinaction/code" target="_blank" rel="noopener">示例中的源代码</a></p><h1 id="关于go语言的介绍">关于Go语言的介绍</h1><h1 id="快速开始一个go程序">快速开始一个Go程序</h1><h1 id="打包和工具链">打包和工具链</h1><h1 id="数组-切片和映射">数组、切片和映射</h1><h1 id="go语言的类型系统">Go语言的类型系统</h1><h1 id="并发">并发</h1><h1 id="并发模式">并发模式</h1><h1 id="标准库">标准库</h1><h1 id="测试和性能">测试和性能</h1>]]></content>
      
      
      
        <tags>
            
            <tag> 书籍 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubeedge的前世今生</title>
      <link href="/2020/12/19/%E5%88%86%E5%B8%83%E5%BC%8F/Kubeedge/Kubeedge/"/>
      <url>/2020/12/19/%E5%88%86%E5%B8%83%E5%BC%8F/Kubeedge/Kubeedge/</url>
      
        <content type="html"><![CDATA[<p>Kubeedge 基于Kubernetes，并扩展提供在边缘端的原生容器化应用编排和设备管理；包含云端和边缘端两部分构成，支持在云和边之间网络、应用部署和元信息协同。</p>]]></content>
      
      
      
        <tags>
            
            <tag> kubeedge 分布式 资源管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K8S中的名词</title>
      <link href="/2020/12/17/%E5%88%86%E5%B8%83%E5%BC%8F/Kubernetes/%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/12/17/%E5%88%86%E5%B8%83%E5%BC%8F/Kubernetes/%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="简介">简介</h1><p><a href="https://kubernetes.io/zh/docs/home/" target="_blank" rel="noopener">Kubernetes</a> 是一个可移植、可扩展的开源平台，用于管理容器化的工作负载和服务，可用于声明式配置和自动化.</p><p>Kubernetes 提供服务发现和负载均衡、存储编排、自动部署和回滚、自我修复、自动装箱机制、秘钥和配置管理.</p><h1 id="组件">组件</h1><p>kubernetes 集群由一组被称为节点的机器构成，这些节点上运行着kubernetes所管理的容器化应用.<br>工作节点管理着作为应用负载的组件的Pod，控制平面管理着集群中的控制节点和Pod.在生产环境中，为了保证故障转移和高可用性，控制平面一般跨主机运行，集群通常跨节点.</p><h2 id="控制平面control-plane"><a href="https://kubernetes.io/docs/concepts/overview/components/" target="_blank" rel="noopener">控制平面(Control Plane)</a></h2><p>在集群中，控制平面组件做出全局的决策，比如调度、检测和回复集群变动(例如为满足副本数而新建pod).<br>Control Plane 包含若干部分，Kube-apiserver，etcd，kube-scheduler，kube-controller-manager，cloud-control-manager</p><p><a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/" target="_blank" rel="noopener">kube-apiserver</a></p><blockquote><p>apiserver 负责管理和配置API(Application Programing Interface)的对象，例如Pods，servers等.<br>apiserver 并不是唯一的，可以有多个实例.</p></blockquote><p><a href="https://etcd.io/docs/" target="_blank" rel="noopener">etcd</a></p><blockquote><p>etcd是一个高可用的分布式键值存储系统，内部使用raft协议作为一致性算法，基于Go语言实现.<br>在kubernetes中作为集群数据的备用存储库.</p></blockquote><p><a href>kube-schedule</a></p><blockquote><p>schedule负责决定新创建的Pods部署在哪个Node，考虑因素包括单个和总体的资源要求、硬件/软件/策略约束、偏好性和排斥性因素、数据本地存储因素、服务间负载因素以及deadline等等.</p></blockquote><p><a href="https://kubernetes.io/docs/concepts/architecture/controller/" target="_blank" rel="noopener">kube-controller-manager</a></p><blockquote><p>控制平面组件运行着控制进程，逻辑上，不同的控制进程是相互独立的，但是为了降低复杂度，将所有控制进程编译进一个单独的二进制文件，作为一个进程运行.<br>控制进程包括:</p></blockquote><ul><li>节点控制器:负责在节点宕机时提醒并作出回应.</li><li>副本控制器:负责保持Pods的副本数量保持正常.</li><li>终端控制器:填充终端对象(即加入Service与Pod)</li><li>服务账户和令牌控制器:为新的命名空间创建默认账户和API访问令牌</li></ul><p>cloud-controller-manager</p><blockquote><p>云控制管理器指嵌入特定云的控制逻辑的控制平面插件。下面的控制器包含对于云平台的依赖</p></blockquote><ul><li>节点控制器:在节点停止响应后，检查云供应商是否已经删除节点</li><li>路由控制器:在底层云基础架构中设置路由</li><li>服务控制器: 用于创建、更新和删除云平台供应商的负载均衡器</li></ul><h2 id="node-组件">Node 组件</h2><p>节点组件运行在每个node节点上，运行pods并提供k8s的运行时环境。</p><h3 id="kubelet">kubelet</h3><p>kubelet是集群中运行在节点上的代理，确保容器运行在pod中。<br>kubelet接收一系列包含各种机制的Pod描述文件，并确保容器健康运行。此外，kubelet不管理不由k8s创建的容器。</p><h3 id="kube-proxy"><a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/" target="_blank" rel="noopener">kube-proxy</a></h3><p>kube-proxy 是运行在每个节点的网络代理，实现Service/服务 概念的部分功能。<br>kube-proxy 维持着节点上的网络规则，这些规则允许集群内外的网络会话与Pods通信。<br>如果操作系统的数据包过滤层可用，那么kube-proxy基于此实现网络规则，否则kube-proxy仅转发流量本身。</p><h3 id="container-runtime容器运行时环境">Container Runtime(容器运行时环境)</h3><p>K8s支持多种运行时环境：Docker、containerd、CRI-O和任何实现对于Kubernetes CRI的继承的软件。</p><h2 id="插件addons">插件(Addons)</h2><p>插件使用K8s资源(DaemonSet、Deploymnet)实现集群功能，由于提供集群级别的功能，所以插件中命名空间域的资源属于<code>kube-system</code>命名空间。</p><h3 id="dns">DNS</h3><p>集群DNS是一个DNS服务器，与环境中的其他DNS服务器一起工作，为k8s集群服务提供DNS服务。<br>k8s集群所启动的容器会将该DNS服务器包含在其DNS搜索列表。</p><h3 id="web界面仪表盘">web界面(仪表盘)</h3><p>Dashboard是k8s集群通用的、基于web的用户界面。借助其，用户可以直接管理应用和排除应用故障。</p><h3 id="容器资源监控">容器资源监控</h3><p>Container Resource Monitoring 将容器的通用时序衡量指标记录于中心数据库，并提供web界面浏览数据。</p><h3 id="集群级别的日记">集群级别的日记</h3><p>一个集群级别的记录机制可以保存容器日志到集中日志存储，并提供搜索和浏览接口。</p><h1 id="相关概念">相关概念</h1><h2 id="cluster-architecture">Cluster Architecture</h2><p>主从架构</p><h3 id="node"><a href="https://kubernetes.io/docs/concepts/architecture/nodes/" target="_blank" rel="noopener">Node</a></h3><p>Kubernetes 通过在Node上运行由容器构成的Pods 来运行Workloads；Node可以是虚拟的，也可以是物理机器；每个Node都包含运行Pods所必需的服务，由 control plane 管理；组件包括kubelet，container runtime和kube-proxy</p><h4 id="管理">管理</h4><p>有两种方式可以添加Node，一种是由node上的kublet自注册到control plane，另一种是使用kubectl人工增加节点，添加之后control plane会检测新node是有有效。</p><h4 id="node状态">Node状态</h4><p>Node状态由Addresses、Conditions、Capacity and Allocatable、Info 四部分构成<br>Addresses包括HostName、ExternalIp(用于集群外使用)、InternalIp(集群内使用)<br>Conditions描述Node的状态，其值有Ready、DiskPressure(当Disk容量低时为True)、MemoryPressure、PIDPressure、NetworkUnavailable<br>Capacity-and-Allocatable 描述的资源包括CPU、内存、节点上可被调度的最大pod数量。Capacity和Allocatable分别指总共资源和可分配的资源。<br>Info 描述了Node的通用信息，比如内核版本，k8s版本，docker版本，os版本等等。</p><h4 id="node-controller">Node Controller</h4><p>Node Controller是K8s控制平面的组件，负责管理在各个层面管理node。<br>Node Controller有三个主要功能，</p><ul><li>分配CIDR地址块</li><li>检测节点的健康状态，更新节点的状态并当节点不可达时下线其pods</li><li>保证node controller的node列表与云服务提供商的列表一致，当某个节点状态为unhealthy时，查询云提供商后决定是否删除节点。</li></ul><h4 id="心跳">心跳</h4><p>更新节点的状态以及租约。</p><h4 id="可靠性">可靠性</h4><p>通过移除pod以及限制移除pod的频率实现。</p><h3 id="control-plane-node-communication"><a href="https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/" target="_blank" rel="noopener">Control Plane-Node Communication</a></h3><p>主要有两方面的交流，一方面是 Node 到 Control Plane的通信，另一方面是Control Plane 到 Node 的通信。</p><h4 id="node-to-control-plane">Node to Control Plane</h4><p>所有的node的API请求最终到达apiserver，而不是直接到达Control Plane(其组件与apiserver通过安全端口连接)；apiserver在https 443 端口监听远程连接，node需要提供客户端凭据来验证自己的身份，而pod需要使用service 账号才能连接apiserver；<br>所以node/pod到control plane的通信可以运行在非信任网络或者公开网络中。</p><h4 id="control-plane-to-node">Control Plane to Node</h4><p>一般有两种情况，control plane(apiserver)与节点上的kublet进程通信，另一种是使用apiserver的转发功能向node、pod、service通信。<br>apiserver to kublet</p><ul><li>拉取pods的日志</li><li>通过kubectl创建pods</li><li>提供kubelet的端口转发功能</li></ul><blockquote><p>通常情况下，这些连接不验证kubelet的服务证书，因而可能遭到中间人攻击，对此可以使用<code>--kubelet-certificate-authority</code>标志来对连接进行认证。</p></blockquote><p>apiserver to pods/nodes/services</p><blockquote><p>通常情况下，连接默认为纯HTTP连接，没有认证也没有加密；可以通过在 nodes/pods/services 前加前缀 <code>https:</code> 来提供加密服务，但是不能实现证书认证，因而不能安全地在非受信网络和公共网络上运行。</p></blockquote><h3 id="controller"><a href="https://kubernetes.io/docs/concepts/architecture/controller/" target="_blank" rel="noopener">Controller</a></h3><p>controller 类似于恒温器，努力将当前集群的状态调整到设定的状态。</p><h4 id="controller-模式">Controller 模式</h4><p>一个controller至少追踪一个k8s资源的状态。<br>controller可以直接改变状态或者通过外部方式(api server)改变状态。<br>direct control</p><blockquote><p>一些控制器需要从集群外起作用。例如增加cluster的node，controller增加node后会通知API server状态变更，然后可以创建新的pod或者container。</p></blockquote><p>control via API server</p><blockquote><p>一些控制器通过API server，调整状态。例如Job Controller(k8s 内置controller)，通过API server创建或移除pod/container。</p></blockquote><h4 id="设计">设计</h4><p>k8s里有一系列controller负责控制不同方面的集群状态</p><h3 id="cloud-controller-manager"><a href="https://kubernetes.io/docs/concepts/architecture/cloud-controller/" target="_blank" rel="noopener">Cloud Controller Manager</a></h3><h2 id="containers">Containers</h2><p>共享宿主机操作系统</p><h2 id="workloads">Workloads</h2><p>即运行在K8S上的一个应用，可能又多个Pod构成</p><h2 id="servicesloadbalancingand-networking">Services,Loadbalancing,and Networking</h2><h2 id="storage">Storage</h2><h2 id="configuration">Configuration</h2><h2 id="security">Security</h2><h2 id="pliocies">Pliocies</h2><h2 id="scheduling-and-eviction">Scheduling and Eviction</h2>]]></content>
      
      
      
        <tags>
            
            <tag> kubernetes 分布式 资源管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K8S中的PODS</title>
      <link href="/2020/12/16/%E5%88%86%E5%B8%83%E5%BC%8F/Kubernetes/pod/"/>
      <url>/2020/12/16/%E5%88%86%E5%B8%83%E5%BC%8F/Kubernetes/pod/</url>
      
        <content type="html"><![CDATA[<p>Kubernetes 中的Pods是一系列container的集合,一系列container运行的环境，集合内的container共享存储/网络资源,可以统一管理pods中的多个container;</p><h4 id="pods更新操作">Pods更新操作</h4><p>kuberlet 会创建一个新的pod，然后替代这个旧的pod</p><h4 id="资源分享和交流resource-sharing-and-communication">资源分享和交流(Resource sharing and communication)</h4><p>pod 允许其中的container分享数据和交流<br>pod内的container共享一个ip和相应的port空间</p><h4 id="dns">DNS</h4>]]></content>
      
      
      
        <tags>
            
            <tag> kubernetes 分布式 资源管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法导论</title>
      <link href="/2020/12/10/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA/"/>
      <url>/2020/12/10/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<p>《算法导论》第三版书籍阅读笔记</p>]]></content>
      
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gossip协议</title>
      <link href="/2020/11/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Gossip%E5%8D%8F%E8%AE%AE/"/>
      <url>/2020/11/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Gossip%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<p>Gossip协议是一个通信协议，一种传播和扩散消息的方式，常用于数据库复制，信息扩散，集群成员身份确认、故障探测等；类似于瘟疫和社交网络的传播方式；Gossip协议的应用包括Redis Cluster、Consul、Apache Cassandra。</p><p>六度分隔理论</p><blockquote><p>世界上，任意两个陌生人之间的间隔不会超过六个人。</p></blockquote><p>问题</p><blockquote><p>集群中的任意一个节点信息更新并扩散给网络中其他节点</p></blockquote><p>基本思想</p><blockquote><p>信息增加的节点会周期性/触发性的随机选择一些节点，并将信息传递给这些节点，而这些节点也会如此操作，最终所有节点</p></blockquote><p>停止条件</p><ul><li>轮次数或者时间限制</li><li>是否普遍存在回路</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Merkle树</title>
      <link href="/2020/11/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Merkle%E6%A0%91/"/>
      <url>/2020/11/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/Merkle%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<p>用途</p><blockquote><p>Merkle树大多用来进行完整性验证。<br>Merkle树还可以用来对数据进行快速对比，快速定位到不一致的数据。<br>分布式存储系统中，数据常常会保存副本，需要对副本进行比较以判断副本是否过期，这时在节点间传输数据比较的效率太低，可以选择对于文件的Hash值进行比较来判断是否一致。</p></blockquote><p>原理</p><blockquote><p>Merkle树节点中存储的值是hash值，其中叶子节点存储数据文件的hash值，而非叶子节点存储叶子节点的叶子节点的hash和。<br>对于有N个节点的Merkle树，如果数据不一致，从根节点出，O(logN) 次可以查找到不同的数据块。<br>还有一种数据结构 Hash List,将N个子结点所代表的文件数据的hash值之和作为节点值，同样可以对比文件是否一致，但是需要O(N)次才能找到不一致的点</p></blockquote><p>Merkle 在Dynamo中的应用</p><blockquote><p>Dynamo集群的所有机器分布在一致性Hash环中，每一个机器负责存储Hash环某个区间的所有数据，同时为了保持数据的可靠性，一台机器上存储的数据会在其他机器上有备份；处于某些原因(比如某机器下线，需要复制该机器上的所有数据，保持副本数)，副本需要保持一致进行后续的同步；一般同步需要传输数据，然后对比，如果要传输机器上的所有数据，不仅耗时间长而且可能造成网络拥挤；<br>为了解决这个问题，可以针对每台机器的每个区间的数据构造一颗Merkle树；当两台机器间对比数据时，从所属的Merkle树的根节点开始对比，不需要任何的传输，如果不一样，可以以log(N)的时间复杂度定位不一致的数据的位置。</p></blockquote><p>在Git中的应用</p><blockquote></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Data Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/11/24/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6.824/Readme/"/>
      <url>/2020/11/24/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6.824/Readme/</url>
      
        <content type="html"><![CDATA[<p>recording learning of distriuted storage</p><p><a href="https://pdos.csail.mit.edu/6.824/" target="_blank" rel="noopener">MIT 6.824 course</a><br>PingCAP的相关资源<br><a href="https://github.com/pingcap/awesome-database-learning" target="_blank" rel="noopener">关于数据库的一些知识</a><br><a href="https://pingcap.com/community-cn/paper-reading/" target="_blank" rel="noopener">关于分布式系统的论文</a><br><a href="https://github.com/yjjnls/books" target="_blank" rel="noopener">大规模分布式存储系统：原理解析与架构实战</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>大规模分布式存储系统</title>
      <link href="/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F-%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98/"/>
      <url>/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F-%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<h2 id="第1章-概述">第1章 概述</h2><h3 id="概念">概念</h3><p>分布式存储系统</p><blockquote><p>大量普通PC服务器通过Internet互联,对外作为一个整体提供存储服务</p></blockquote><p>特性</p><ul><li>可扩展:在扩展的同时,性能也线性提升</li><li>低成本:基于分布式存储系统的自动容错以及负载均衡功能使得其可以在普通机器上扩展</li><li>高性能:</li><li>易用性:分布式存储系统要求对外提供易用的外部接口,同时具备完备的监控和运维功能,并支持与其他系统集成</li></ul><p>分布式存储系统的挑战在于数据、状态信息的持久化,要求在自动化、自动容错、并发读写的过程中保证数据的一致性.分布式存储涉及的技术主要来自于两个领域:分布式系统和数据库,分类如下</p><ul><li>数据分布:如何均匀地将数据分布到多台服务器,又如何实现跨服务器的读写服务</li><li>一致性:在分布式系统中,会存在一份数据的多个副本存在于多个服务器,如何管理副本同时保证不同副本之间的数据一致性?</li><li>容错:如何检测服务器故障,在检测到错误之后如何迁移数据到安全的服务器</li><li>负载均衡:在日常运行以及服务器上下线时如何保证负载均衡,在迁移的过程中如何保证不影响已有服务?</li><li>事务并发和控制:实现分布式事务?如何实现多版本并发控制?</li><li>易用性:</li><li>压缩/解压缩:如何根据数据的特点设计压缩和解压缩算法,如何平衡压缩算法的存储资源和CPU资源消耗?</li></ul><h3 id="分布式存储分类">分布式存储分类</h3><p>分布式存储数据的类型</p><ul><li>非结构化数据:包括文档、文本、图片、影响、音频和视频信息等</li><li>结构化数据:一般存储在关系数据库中</li><li>半结构化数据:介于结构化数据和非结构化数据之间;例如HTML,不需要预设规则,可以自描述</li></ul><p>不同的分布式存储系统适合处理不同的数据类型,文中将分布式存储系统分为四类:分布式文件系统,分布式键值系统,分布式表格系统,分布式数据库</p><h4 id="分布式文件系统">分布式文件系统</h4><p>互联网需要存储大量的非结构化数据,例如图片、视频等,称之为Blob(Binary Large Object);<br>典型:Facebook Haystack 、 Taobao File System 、Google File System</p><h4 id="分布式键值系统">分布式键值系统</h4><p>分布式键值系统用于存储关系简单的半结构化数据,提供基于主键的CRUD功能.</p><h4 id="分布式表格系统">分布式表格系统</h4><p>存储关系较为复杂的半结构化数据<br>典型系统: Google Bigtable 、 Megastore</p><h4 id="分布式数据库">分布式数据库</h4><p>一般从单机数据库扩展而来,用于存储结构化数据<br>典型系统:Mysql Sharding 、Amazon RDS 、 Microsoft SQL Azure</p><p>基础篇</p><ul><li>第2章 单机存储系统</li><li>第3章 分布式存储系统</li></ul><h2 id="第2章-单机存储系统">第2章 单机存储系统</h2><h3 id="21-硬件基础">2.1 硬件基础</h3><h3 id="22-单机存储引擎">2.2 单机存储引擎</h3><blockquote><p>存储引擎是存储系统的发动机,直接决定了存储系统能够提供的性能和功能.<br>存储系统的基本功能包括:增删读改,读取操作又分为随机读取和顺序扫描.</p></blockquote><p>哈希存储引擎是哈希表的持久化实现,支持增删盖和随机读取,不支持顺序扫描,对应的存储系统是键值存储系统<br>B树存储引擎是B树的持久化实现,不仅支持单条数据的增删改查,还支持顺序扫描(范围查询),对应的存储系统是关系数据库<br>LSM(Log_structured Merge Tree)存储引擎与B树存储引擎一样,支持单条数据的增删读改,也支持顺序扫描,其通过批量转储技术规避磁盘随机写入问题,广泛用于互联网的后台存储系统.例如Google Bigtable 、Google LevelDB、Cassandra</p><h4 id="221-哈希存储引擎">2.2.1 哈希存储引擎</h4><p>Bitcask</p><h4 id="222-b树存储引擎">2.2.2 B树存储引擎</h4><p>Mysql Innodb</p><h4 id="223-lsm树存储引擎">2.2.3 LSM树存储引擎</h4><p>典型 Level DB<br>其思想是将数据的修改增量保持在内存中,达到指定的大小限制后,将这些修改操作批量写入磁盘,读取时需要合并磁盘中的历史数据和内存中最近的修改操作;尽管避免了磁盘随机写入的问题,但是在读取时会访问比较多的磁盘文件</p><h3 id="23-数据模型">2.3 数据模型</h3><p>如果存储引擎相当于存储系统的发动机,那么数据局模型相当于存储系统的外壳.<br>存储系统的数据模型主要包括3类:文件、关系、键值模型</p><h4 id="231-文件模型">2.3.1 文件模型</h4><p>文件模型以目录树的形式组织文件,包含打开/关闭、读取/写入文件的操作,包括打开/关闭目录,遍历目录的操作<br>在单机文件系统的标准,例如POSIX 要求在并发时保证操作的原子性(例如读操作不能读取到脏数据);但是在分布式文件系统中,处于性能考虑,不遵守该标准;例如NFS(Network File System) 允许客户端缓存文件数据,多个客户端修改同一个文件容易出现不一致的问题.<br>对象模型与文件模型有些相似,用于存储图片、视频、文件等二进制数据块,典型的包括Amazon Simple Storage(S3), Taobao File System(TFS),这些系统弱化了目录树的概念,S3只支持一级目录,不支持子目录,TFS甚至不支持目录结构.同时与文件模型不同,对象模型要求对象一次性写入到系统,修改时只能删除整个对象,无法部分修改.</p><h4 id="232-关系模型">2.3.2 关系模型</h4><p>每个关系都会一个表格,由多个元组(行)构成,而每个元组又包含多个属性(列).关系名、属性名以及属性类型称之为该关系的模式(scheme);<br>数据库的SQL语言用于描述查询和修改操作<br>此外,SQL还包含两个重要特性,索引以及事务;索引可以降低查询时需要扫描的数据量,而事务是保证各个数据操作过程中,多操作并发的ACID(原子性 一致性 隔离性 持久性)</p><h4 id="233-键值模型">2.3.3 键值模型</h4><p>大量的NOSQL系统采取的键值模型,每行记录由主键和值两部分构成,支持基于主键的PUT、GET、DELETE操作<br>由于键值模型比较简单,支持的应用场景有限,NOSQL 系统中使用较为广泛的模型表格型</p><blockquote><p>表格模型弱化了关系模型中的多表关联,支持基于单表的简单操作,典型的系统包括Google BigTable 和 HBase.</p></blockquote><p>表格模型除了支持简单的基于主键的操作之外,还支持范围扫描,也支持基于列的操作</p><h4 id="234-sql-和-nosql">2.3.4 SQL 和 NOSQL</h4><p>随着互联网的快速发展,数据规模越来越大,并发量也越来越高,关系数据的应对这样的需求有些力不从心,而非关系数据库NOSQL(Not Only SQL),带来许多新的理念,比如良好的可扩展性,弱化数据库的设计范式,降低一致性的要求,一定程·度上解决del海量数据和高并发的问题,但是需要注意的是NOSQL只是对于SQL特性的一种取舍和升华,使得SQL更加适应于海量数据的应用场景.<br>关系数据库在海量数据中面临的挑战</p><ul><li>事务:关系模型要求多个SQL操作满足ACID特性,所有的SQL操作要么都成功要么都失败;但是在分布式系统中,如果多操作属于不同的服务器,那么他们的原子性需要二阶段提交协议保证,但是该协议无法保证高性能,也不能应对单机故障.</li><li>联表:关系数据库为了避免出现数据冗余的情况,会利用范式进行限制,这样会出现频繁的联表操作,但是海量数据的场景中,为了避免联表操作带来的性能损失,会使用数据冗余等违反范式的方法.</li><li>性能:关系数据库使用B树存储引擎,其更新性能不如LSM树,此外,在只有基于主键的增删查改的场景中,其性能又不如键值存储系统</li></ul><p>随着数据规模越来越大,NOSQL 数据库广泛应用于互联网业务中,但是其也面临如下问题</p><ul><li>缺乏统一标准:关系数据库经过几十年的发展已经形成SQL语言这样的业界标准,也有了完善的生态链;而现在的NOSQL 系统的使用方法不同,切换成本高,很难通用.</li><li>使用以及运维复杂:NOSQL系统无论选型还是使用方式,都有很大的学问,往往需要理解系统的实现,缺乏专业的运维工具和人员</li></ul><h3 id="24-事务和并发控制">2.4 事务和并发控制</h3><h3 id="25-故障恢复">2.5 故障恢复</h3><p>数据库运行过程中会出现故障,事务可能执行到一半没有提交,而系统重启时,需要恢复一致的状态,即要么提交整个事务,要么回滚.<br>数据库系统以及其他分布式存储系统一般采用操作日志的技术来实现故障恢复.<br>操作日志分为回滚日志(记录事务修改之前的状态)、重做日志(记录事务修改之后的状态)</p><h4 id="251-操作日志">2.5.1 操作日志</h4><h4 id="252-重做日志">2.5.2 重做日志</h4><ol><li>成组提交</li><li>检查点</li></ol><h3 id="26-数据压缩">2.6 数据压缩</h3><p>数据压缩分为两种,有损压缩和无损压缩,前者压缩比例高,但是有可能失真,一般用于压缩图片、视频、音频;而无损压缩算法可以完全还原原始数据,一般适用于文本.<br>早期的压缩技术是基于编码上的优化技术,其中以霍夫曼编码最为知名.后面的<a href="https://baike.baidu.com/item/LZ%E7%BC%96%E7%A0%81/3155215" target="_blank" rel="noopener">LZ</a>系列压缩算法几乎通用无损压缩领域.</p><h4 id="261-压缩算法">2.6.1 压缩算法</h4><h4 id="262-列式存储">2.6.2 列式存储</h4><p>传统的行式存储是将一个个完整的数据行存储在数据页中,在查询需要大多数的列时,磁盘IO是高效的;但是一次查询涉及几百万甚至亿级行数据的,且仅关心少数几个列时,这种磁盘IO很难说是高效的.这种情况下,列式数据库更加高效.<br>列式数据库是将同一个数据列的各个值存放在一起/一行,插入某行时,该行的各个数据列的值也会存放到不同的地方;当需要获取某个行的全部数据时,需要从不同的地方读取各个数据列的值,然后合并成数据行,所以对于涉及量较小的查询或者大部分查询都需要整行的数据的查询,列式数据库并不适用.</p><h2 id="第3章-分布式存储系统">第3章 分布式存储系统</h2><p>分布式系统面临的第一个问题就是数据分布,即将数据均匀的分布到多个存储节点.另外为了保证可靠性和可用性,需要将数据复制成多个副本,这就带来了多个副本之间数据一致性的问题.此外,大规模分布式系统的重要目标是节省成本,大多采用性价比更高而非可靠性更高的服务器,因而在软件层面需要应对服务器故障的问题,达到容错的目标.<br>分布式系统中有两个重要协议,Paxos选举协议和两阶段提交协议.<br>Paxos协议用于多个节点之间达成一致,往往仅用于实现总控节点选举,因为用于日常事务提交会降低效率.二阶段提交协议用于保证跨多个节点操作的原子性.</p><h3 id="31-基本概念">3.1 基本概念</h3><h4 id="311-异常">3.1.1 异常</h4><h4 id="312-一致性">3.1.2 一致性</h4><p>由于异常的存在,分布式存储系统一般会将数据冗余存储多份,每一份称之为副本.如此在一个节点出现故障时,可以从其他节点的副本中读取数据.<br>副本是分布式存储系统容错技术的唯一手段,因而如何保证多个副本之间的一致性是分布式理论核心.<br>可以从两个角度来理解一致性:操作的一致性和存储的一致性<br>一致性具体又可以分为强一致性、弱一致性、最终一致性.</p><ul><li>强一致性:对一个副本的操作,要求同样在其他副本生效</li><li>弱一致性:对一个副本的操作,不要求在其他副本上生效</li><li>最终一致性:是弱一致性的一种特例,对一个副本的操作,保证在一定的时间窗口内同样会在其他副本中生效</li></ul><p>从存储系统的角度,一致性 主要分为如下几个方面</p><ul><li>副本一致性:存储系统的多个副本之间的数据是否一致,不一致的时间窗口又是怎样的等</li><li>更新顺序一致性:存储系统的多个副本之间是否按照相同的顺序执行更新操作</li></ul><h4 id="313-衡量标准">3.1.3 衡量标准</h4><p>性能:系统的吞吐能力和响应时间 例如 QPS(query per second) TPS(transaction per second) 和 系统的响应延迟,高吞吐和低延迟之间需要取舍和权衡<br>可用性:系统在面临各种异常时可以提供正常服务的能力,通常可以用系统停服的时间和正常提供服务的时间的比例来衡量<br>一致性:<br>可扩展性:</p><h3 id="32-性能分析">3.2 性能分析</h3><h3 id="33-数据分布">3.3 数据分布</h3><p>分布式系统与传统系统的区别在于将数据分布到多个节点,并在多个节点之间实现负载均衡<br>数据分布的方式主要有两种,哈希分布和顺序分布</p><ul><li>哈希分布:例如一致性哈希,Amazon的Dynamo系统</li><li>顺序分布:即每张表格上的数据按照主键整体有序,例如Google的Bigtable系统</li></ul><h4 id="331-哈希分布">3.3.1 哈希分布</h4><p>只支持随机读写,使用场景包括:某些互联网应用根据用户进行数据拆分,可以通过哈希方法进行数据分布,同一个用户的数据将分布到同一个节点,支持对于同一个用户的数据进行顺序扫描,涉及多个用户的数据由应用层解决.<br>数据倾斜<br>节点上下线时的数据迁移</p><h4 id="332-顺序分布">3.3.2 顺序分布</h4><p>哈希分布破坏了数据的有序性,只支持随机读取操作,不支持顺序扫描.<br>顺序分布在分布式表格系统中比较常见,一般的做法是将大表顺序划分为连续的范围,每一个范围称为一个子表,总控服务器按照一定的策略将这些子表分配到存储节点.<br>同时由于数据的插入和删除,会导致某些子表大小偏离正常标准太多,太大或者太小,系统还需要考虑子表的分裂与合并.</p><h4 id="333-负载均衡">3.3.3 负载均衡</h4><p>分布式存储系统的每个集群中一般会有一个总控节点,其他节点为工作节点,由总控节点根据全局负载信息进行整体调度.<br>在节点上下线以及数据增删的情况下,总控节点需要将数据从负载较高的节点迁移至负载较低的节点.<br>工作节点通过心跳包将节点负载相关的信息例如CPU 磁盘 内存 网络等资源利用率,读写次数和读写数据量等数据发送给总控节点.总控节点根据全局信息调节负载.</p><h3 id="34-复制">3.4 复制</h3><p>为了保证分布式存储系统的高可靠和高可用,数据在系统中一般存储多个副本,分布式存储系统通过复制协议将数据同步到多个节点,并保证多个副本之间的数据一致性.<br>同一个数据的多个副本中有一个主副本,其他为备副本,由主副本将数据复制到备副本.<br>复制协议分为两种,强复制协议以及异步复制,两者的区别在于用户的写请求是否需要同步到各副本之后才可以返回成功.</p><h4 id="341-复制的概述">3.4.1 复制的概述</h4><p>利用操作日志(commit log)实现主副本到备副本的复制;基于Quorum机制的NWR协议</p><h4 id="342-一致性和可用性">3.4.2 一致性和可用性</h4><p>CAP理论</p><h3 id="35-容错">3.5 容错</h3><h4 id="351-常见故障">3.5.1 常见故障</h4><h4 id="352-故障检测">3.5.2 故障检测</h4><p>心跳机制检测<br>租约机制(带有超时时间的授权)检测</p><h4 id="353-故障恢复">3.5.3 故障恢复</h4><h3 id="36-可扩展性">3.6 可扩展性</h3><h4 id="361-总控节点">3.6.1 总控节点</h4><h4 id="362-数据库扩容">3.6.2 数据库扩容</h4><h4 id="363-异构系统">3.6.3 异构系统</h4><p>同一个组内的节点存储同一个服务的数据,这样的系统称之为同构系统,同构系统的问题在于增加副本所导致的数据传输发生只在对应的组之间,由于带宽的限制,导致传输时间长,因而增加故障发生的概率</p><h3 id="37-分布式协议">3.7 分布式协议</h3><h4 id="371-两阶段提交协议">3.7.1 两阶段提交协议</h4><p>节点分类:协调者和事务参与者<br>阶段:请求阶段(协商确认阶段) 和 提交阶段</p><h4 id="372-paxos">3.7.2 Paxos</h4><h4 id="373-paxos-和-2pc">3.7.3 Paxos 和 2PC</h4><p>在分布式系统中,Paxos 用于保证多个副本之间的数据一致性,而2PC保证了跨节点/数据分片的操作的原子性</p><h3 id="38-跨机房部署">3.8  跨机房部署</h3><p>//## 第二篇 范型篇</p><h2 id="第4章-分布式文件系统">第4章 分布式文件系统</h2><p>分布式文件系统的功能主要有两个,一个是存储文档、图像、视频之类的Blob类型数据,另一个是分布式表格系统的持久化存储层<br>分布式文件系统中最著名的是GFS(Google file System),它构建在廉价的PC服务器之上,支持自动容错.GFS内部将大文件划分为大小约64MB的数据块(chunk),并通过主控服务器(Master)实现元数据管理、副本管理、自动负载均衡等操作.其他的分布式文件系统包括Tabao File System(TFS)、Facebook Haystack</p><h3 id="41-gfs">4.1 GFS</h3><h4 id="411-系统架构">4.1.1 系统架构</h4><p>GFS系统的节点可以分为三种角色:GFS Master(主控服务器)、GFS ChunkServer(CS,数据块服务器)以及GFS客户端<br>GFS文件被划分为固定大小的数据块(chunk),由主服务器在创建时分配一个64位全局唯一的chunk句柄.CS以普通的Linux文件的形式将chunk存储在磁盘中.为了保证可靠性,chunk在不同的机器中复制多份,默认为三份.<br>主服务器中维护了系统的元数据,包括文件及chunk命名空、文件到chunk的映射、chunk位置信息.他也负责整个系统的全局控制,如chunk租约管理、垃圾回收无用chunk、chunk复制等.主控服务器会定期与CS通过心跳的方式交换信息.</p><p>客户端是GFS提供给应用程序的访问接口,它是一组专用接口,以库文件的形式提供.客户端访问GFS时,首先访问主控服务节点,获取与之交互信息的CS信息,然后直接访问这些CS,完成数据存取工作.</p><p>需要注意的是,GFS客户端不缓存文件数据,只缓存从主控服务器中获取的元数据,这是GFS的应用特点决定的.<br>GFS主要的应用是MapReduce 和 Bigtable,对于MapReduce ,GFS客户端使用方式为顺序读写,没有缓存文件的必要;而BigTable作为分布式表格系统,内部实现了缓存机制.</p><h4 id="412-关键问题">4.1.2 关键问题</h4><ol><li>租约机制</li></ol><blockquote><p>GFS数据追加以记录为单位,每个记录的大小为几十KB到几MB不等,如果 每个记录追加都请求master,会让master成为系统性能瓶颈.因此GFS中通过租约(lease)机制将chunk写操作授权给ChunkServer.<br>拥有授权的ChunkServer称为主ChunkServer,其他ChunkServer称为备ChunkServer.租约授权针对单个chunk,在租约有效期内对于该chunk的写操作都由主ChunkServer负责,从而减轻Master的负载.租约的有效期一般比较长,且在没有异常的情况下,主ChunkServer可以不断向Master请求延长租约的有效期直至整个chunk写满<br>例子:对于chunk的多个副本都有自己的版本号,每次对于副本的更新以及租约授权和延长租约时都会增加版本号,版本号低的副本会被Master标记成可删除,当定时垃圾回收任务触发时,会通知ChunkServer回收之</p></blockquote><ol start="2"><li>一致性模型</li></ol><blockquote><p>GFS主要是为了追加而不是改写设计的.一方面是因为改写的需求比较小或者可以通过追加实现,另一方面追加的一致性模型相对更为简单(部分副本追加失败的后果是存在读过期数据的可能,而改写的后果是不正确的数据)<br>理想情况下,追加成功的记录会在GFS的各个副本中存在而且严格一致;但是如果出现异常,可能出现某些副本追加成功而某些副本没有成功,失败的副本可能会出现一些可识别的填充记录.由于客户端在追加失败后会重试,导致某些记录在某些副本中被追加多次;在并发追加的情况下,客户端连续发出的追加操作在chunk副本上并不一定是连续执行的,中间可能夹杂其他客户端的追加操作;应用层对于这些异常情况应当加以识别和处理.</p></blockquote><ol start="3"><li>追加流程</li></ol><blockquote><p>GFS追加的过程中,将控制流和数据流分开<br>1)客户端向Master请求chunk每个副本所在的ChunkServer,其中主ChunkServer持有修改租约.如果没有CHunkServer持有租约,那么意味着该chunk最近没有写操作,Master会发起一个任务,按照一定的策略将chunk的租约授权给其中一台ChunkServer.<br>2)Master返回客户端主副本和备副本所在的ChunkServer的位置信息,客户端会缓存这些信息供以后使用.如果不出现故障,客户端之后写该chunk不需要再次请求Master.<br>3)客户端将追加的记录发送到每一个副本.每一个ChunkServer会在内部的LRU结构中缓存这些数据.GFS中采用数据流和控制流分离的方法,从而能够基于网络拓扑结构更好地调度数据流的传输.<br>4)当所有的副本都确定收到了数据,客户端会发起一个写请求控制命令给主副本.由于主副本可能收到多个客户端对于同一个chunk的并发追加操作,主副本将确定这些操作的顺序并写入本地.<br>5)主副本将写请求提交给所有的备副本.每个备副本会根据主副本确定的顺序将执行写操作.<br>6)各备副本成功后应答主副本.<br>7)主副本应答客户端,如果有副本发生错误,将出现主副本写成功但是某些备副本写不成功的情况,客户端将重试.</p></blockquote><p>GFS追加流程有两个特色:流水线及分离数据流与控制流.<br>流水线操作</p><blockquote><p>当一个ChunkServer接受到一些数据时,它就立刻开始转发;由于全双工网络的特性,发送数据不会影响接受数据.</p></blockquote><p>分离数据流和控制流</p><blockquote><p>分离可以优化数据传输,控制流应该按照主副本到备副本的方向,而数据流可以依照网络拓扑向时延最小的ChunkServer发送数据.<br>需要注意的是,分离会导致追加流程控制的复杂性,所以分离的前提是每次追加的数据都比较大,所以分离有优化效果</p></blockquote><p>异常情况:</p><ul><li>追加的过程中,出现主副本租约过期而失去chunk修改操作的授权</li><li>主副本或者备副本所在的ChunkServer出现故障</li></ul><ol start="4"><li>容错机制</li></ol><p>Master容错</p><ul><li>通过操作日志以及checkpoint的方式保存状态</li></ul><blockquote><p>Master 保留了三种元数据,命令空间(整个文件系统的目录结构和chunk的基本信息)、文件到chunk之间的映射、chunk副本的位置信息(一般会有3个副本);Master总是先记录操作日志然后修改内存,故障时Master可以通过操作日志恢复,定期的checkpoint可以降低回放的日志量.</p></blockquote><ul><li>热备份</li></ul><blockquote><p>GFS所有对于元数据的修改够必须保证发送到实时热备份,才算成功,如果Master宕机可以秒级切换到热备份.同时通过Chubby服务选主操作保证只有一台Master.</p></blockquote><p>ChunkServer 容错</p><blockquote><p>GFS通过复制多个副本实现对于ChunkServer的容错.对于每个chunk,必须将所有的副本都写入成功才视为成功写入,如果相关副本丢失或者不可恢复,master会自动将副本复制到其他ChunkServer,确保副本数量达到标准.同时ChunkServer还会对存储的数据位置校验和,保证副本数据正确.</p></blockquote><h4 id="413-master设计">4.1.3 Master设计</h4><ol><li><p>Master 内存占用<br>Master系统中维护了系统的元数据,包括文件和chunk命令空间、文件到chunk的映射以及chunk副本的位置,前两者需要持久化到磁盘,而后者不需要持久化,可以通过ChunkServer回到获取最新信息.<br>内存是稀缺资源,我们需要估算Master的内存使用量.<br>文中通过论证(chunk元数据的构成),得出结论:Master的内存容量不会成为GFS的系统瓶颈.</p></li><li><p>负载均衡<br>GFS中副本的分布策略需要考虑多种因素,如网络拓扑、机架分布、磁盘利用率等.为了提高系统的可用性,GFS会避免将同一个chunk的副本放置在同一个机架.<br>在系统中,以下三种情况会创建chunk副本:chunk创建、chunk复制、负载均衡.<br>chunk在创建时,选择副本的初始位置会考虑以下因素</p></li></ol><ul><li>新副本所在的ChunkServer的磁盘利用率低于平均水平</li><li>限制每个ChunKServer最近创建副本的数量(避免新加入的机器创建过多副本)</li><li>chunk的副本不能过于集中</li></ul><p>当chunk副本数量小于一定数量时,Master会尝试复制一个chunk副本.<br>同时,Master会定时扫描当前副本的分布情况,如果发现磁盘使用量或者机器负载不均衡,将再次执行负载均衡操作.</p><ol start="3"><li><p>垃圾回收<br>GFS采用延迟删除的机制,在操作删除文件之后,GFS并不要求立刻归还可用的物理存储,而是在Master元数据中将文件名改为一个隐藏的名称,并包含一个删除时间戳.Master在后续的定时检查中,超过时间戳就会将之从内存中删除,在后续与ChunkServer心跳交互中,Master会回复已经不存在与Master元数据中的chunk信息,此时ChunkServer会释放这些chunk副本.同时chunk副本版本号低也会被Master通过垃圾回收删除.<br>为了减轻系统的负载,垃圾回收一般在服务低峰期进行.</p></li><li><p>快照<br>快照操作是对源文件/目录进行操作,生成此刻该源文件/目录的一个瞬间状态存在于目标文件或者目录中.<br>GFS采用标准的写时复制机制生成快照,即在未写时,快照操作仅仅增加GFS中chunk的引用计数,表示该chunk被快照文件引用了,当修改时,需要在ChunkServer上拷贝chunk的数据生成新的chunk,后续得修改操作都落在新生成的chunk和是哪个.<br>实际快照操作中涉及很多步骤,比如需要事先收回对于chunk的写操作权限的租约,Master需要生成新的chunk元数据,对于执行快照的文件的所有chunk增减引用计数.</p></li></ol><h4 id="414-chunkserver设计">4.1.4 ChunkServer设计</h4><p>ChunkServer管理大小为64MB的chunk,存储时需要保证chunk尽量均匀的分布在不同的磁盘,需要考虑的因素包括磁盘空间、最近新建chunk数等.<br>同时,Linux文件系统删除64MB大文件消耗时间长,所有可以将该chunk移动至磁盘回收站,新建chunk时可以重用.<br>ChunkServer是磁盘和网络IO密集的应用,应当做到磁盘和网络操作异步化,以最大限度发挥机器性能,但是也增加了编程难度.</p><h4 id="415-讨论">4.1.5 讨论</h4><p>GFS是一个具有良好扩展性并且能够在软件层面自动处理各种异常情况的系统.<br>这种自动化对于容错能力有很高的要求,在实际编程中,也要考虑各种异常情况并加以处理.<br>此外单Master的可行性在GFS得到印证,单Master简化了系统实现,提高工作效率,同时也有相关的日志、热备机制保证单Master的可用性.</p><h3 id="42-taobao-file-system">4.2 Taobao File System</h3><p>互联网应用经常要存储用户上传的文档、图片、视频等,例如Facebook相册、淘宝图片、Dropbox文档等等.<br>文档、图片、视频一般称为Blob(Binary Large Object)数据,存储Blob数据的文件系统也相应称为Blob存储系统.<br>Blob文件系统的特点在于数据写入后基本都是只读,很少出现更新操作.</p><p>由于淘宝数据量大且增长很快,由于性能和成本的考虑,淘宝自研了TFS系统.<br>TFS架构设计时考虑如下两个问题:</p><ul><li>Metadata信息存储.由于图片数据巨大,单机存放不了所有的元数据信息,假设每个图片的元数据占用100字节,100亿图片的元数据占用的空间就是1TB,单机无法提供元数据存储和其他服务.</li><li>减少图片读取的IO次数.普通的Linux文件系统,读取一个文件一般需要三次磁盘IO:首先读取目录元数据到内存,其次将文件的inode节点装载到内存,最后读取实际的文件内容.但是TFS的小文件个数太多,无法将所有目录及文件的inode信息缓存到内存,因此磁盘IO次数很难达到每个图片读取只需要一个磁盘IO的理想状态.<br>因此,TFS采取的思路是:<strong>多个逻辑图片文件共享一个物理文件</strong>.</li></ul><h4 id="421-系统架构">4.2.1 系统架构</h4><p>由于TFS文件之间往往 不存在连续,所以相对于GFS,它不维护文件目录树,每个小文件使用64位的编号表示;同时,鉴于TFS数据读多写少的特点,TFS的写流程更加简单.</p><p>详细内容可看书籍</p><h4 id="422-讨论">4.2.2 讨论</h4><p>图片应用中有几个问题,首先是图片去重,然后是图片更新和删除.<br>去重</p><blockquote><p>由于用户会上传大量相同的照片,因此上传到TFS之前,需要去重;<br>一般在外部维护一套文件级别的去重系统,采用MD5或者SHA1等Hash算法为图片文件计算指纹(FingerPrint).</p></blockquote><p>更新</p><blockquote><p>图片的更新操作是在TFS中写入新图片,并在应用系统的数据库内保存新图片的位置,图片的删除操作仅仅在应用系统中将图片删除.<br>图片在TFS中的位置是通过&lt; Block id,Block offset&gt; 标识的,因此每个Block中只要有一个有效的文件,整个Block就无法回收.</p></blockquote><h3 id="43-facebook-haystack">4.3 Facebook Haystack</h3><p>Facebook目前存储了2600亿张图片,总大小为20PB,平均每张80KB,每周新增照片为10亿(总大小为60TB),大约每秒3500次新增/写操作,读操作峰值可达每秒百万次.</p><h4 id="431-系统架构">4.3.1 系统架构</h4><p>其设计思路与TFS类似,也是多个逻辑文件共享一个物理文件.<br>Haystack系统主要分为三个部分,目录(Directory)、存储(Storage)以及缓存(Cache).</p><p>详情见书籍</p><h4 id="432-讨论">4.3.2 讨论</h4><h3 id="44-内容分发网络-cdn">4.4 内容分发网络 CDN</h3><p>CDN通过将网络内容发布到靠近用户的边缘节点,使不同地域的用户在访问相同网页时可以就近获得内容,既可以减轻原服务器的负载,也可以减轻整个网络中分布不均匀的情况,进而改善网络性能.</p><p>在CDN中,DNS在对域名解析时不再向用户返回源服务器的IP,而是返回某个由智能CDN负载均衡系统选定的某个边缘节点的IP;用户利用这个IP访问边缘节点,然后该节点通过内部DNS解析获得源服务器IP并请求获取所需页面或者内容,如果成功,边缘节点会缓存数据,下次用户访问可以直接读取,不需要每次都访问源服务器.</p><h4 id="441-cdn-架构">4.4.1 CDN 架构</h4><p>大致构成是分级cache+多级负载均衡(四层:ip+port 和 七层:url),详细内容见书籍</p><p>其他优化</p><ul><li>分级存储:由于缓存数据具有较高的局部性,在squid服务器(源服务器的缓存服务器)上使用SSD+SAS+SATA 混合存储,图片随着热点变化而迁移,最热门的存储到SSD,中等热度的存储到SAS,轻热度的存储到SATA,通过这样的方式可以很好的结合SSD的性能和SAS、SATA磁盘的成本优势.</li><li>低功耗服务器定制:CDN缓存服务是IO密集型而不是CPU密集型服务,因而采用定制服务器降低整体功耗.</li></ul><h4 id="442-讨论">4.4.2 讨论</h4><p>由于Blob存储系统读访问量大,更新或者删除很少,适合通过CDN技术分发到距离用户更近的节点.<br>同时需要注意的CDN是一种缓存系统,不能实现与源服务器的强一致性,源服务器更新或者删除Blob数据,不能及时反映到CDN节点中.<br>此外,随着硬件发展,SSD价格不断下降,分级存储的优势不再明显,目前已经全部配置SSD.</p><h2 id="第五章-分布式键值系统">第五章 分布式键值系统</h2><p>分布式键值模型可以看做分布式表格模型的一种特例,它只支持对单个key-value的增删改查,因此适合用3.3.1中提到的哈希分布算法.<br>Amazon Dynamo 是分布式键值系统,最初用于支持购物车应用.<br>Tair是淘宝开发的分布式键值系统,借鉴了Dynamo系统的一些设计思路并作出创新,其中最大的变化是从P2P架构修改为带有中心节点的架构.</p><h3 id="51-amazon-dynamo">5.1 Amazon Dynamo</h3><p>Dynamo以简单的键值方式存储数据,不支持复杂的查询.<br>Dynamo主要用于Amazon的购物车以及S3云存储服务.<br>Dynamo通过组合P2P的各种技术大打造了线上可运行的分布式键值系统,对于设计时面临的问题提出了自己的解决方案.</p><ul><li>使用改进的一致性哈希(虚拟节点)解决数据分布问题.</li><li>使用复制写协议(Reolicated-write protocol,NWR参数可调)作为复制协议.</li><li>通过向量时钟处理数据冲突问题.</li><li>通过数据回传机制(Hinted handoff)处理临时故障.</li><li>基于Merkle哈希树,在永久故障后恢复数据</li><li>基于Gossip实现成员资格和错误检测</li></ul><h4 id="511-数据分布">5.1.1 数据分布</h4><p>Dynamo 采用一致性哈希算法将数据分布到多个存储节点中;</p><p>由于节点的异构性,不同节点的处理能力差异很大,因此Dynamo采用了改进的一致性哈希算法:每个物理节点根据其性能的差异分配多个token,每个token对应一个虚拟节点,而每个虚拟节点的处理能力基本相当,随机分布在哈希空间中.存储时,数据按照哈希值落到某个虚拟节点负责的区域,然后被存储在该虚拟节点所对应的物理节点中.</p><p>同时为了找到数据所属的物理节点，要求每个节点维持一定的集群信息用于定位。Dynamo要求每个节点维护整个集群的信息，客户端也缓存整个集群的信息，因此大部分请求可以一次定位到目标节点。</p><p>由于机器或者人为因素，系统中的节点成员加入或者退出经常发生，Wie拉堡镇每个节点缓存的都是Dynamo集群中最新的成员信息，所有节点每隔固定时间会通过Gossip协议的方式与其他节点中任意一个连接，并交互信息。</p><p>Gossip协议用于P2P系统中自治的节点协调对整个集群的认识，比如集群的节点状态、负载情况。</p><p>节点的加入和退出或者其他信息变更都会引起周围节点信息的变更，进而按照Gossip协议扩散到整个集群。同时，考虑到节点退出的可能，定期相邻节点交换信息可以尽快扩散该信息。</p><h4 id="512-一致性和复制">5.1.2 一致性和复制</h4><p>为了处理节点失效的情况，需要对节点中的数据进行复制备份；<br>假设对于任意的一份数据，共有N份备份，如果有一个备份数据所在的节点宕机，那么经过gossip协议获知后，会寻找一个节点代替该节点的作用，负责记录宕机节点的写操作；如果该节点永久失效，需要利用<a href="/2020/11/27/基础知识/数据结构/Merkle树/" title="Merkle树">Merkle树</a>对于该节点的数据文件快速同步。</p><p>NWR在Dynamo中提高读写的效率:N标识复制的备份数，R指成功读操作的最少节点数，W表示成功写操作的最少节点数；只要满足W+R&gt;N,那么可以保证宕机数目不超富哦N-W-R-1的情况下，写的数据必然可以被读到；</p><p>NWR 也有一些缺陷。在Dynamo这样的P2P集群中，每个节点存储的集群信息同一时刻并不一定一致(比如，某个数据文件对应的备份节点顺序不一致)，在同一条记录被多个节点同时更新的情况下，无法保证多个节点之间更新顺序。因此，Dynamo引入向量时钟(Vector Clock)的技术手段尝试解决冲突。</p><p>向量时钟用 [ nodes,counter ] 对表示。其中nodes表示节点，counter是一个计数器，初始为0，节点每次更新操作加1。首先Sx对某个对象进行一次写操作，产生一个对象版本D1([ Sx,1 ]),接着Sx继续操作，counter值更新为2，产生第二个版本D2([ Sx,2 ]);之后 ，Sy与Sz同时对该对象进行写操作，Sy将自身的信息加入向量时钟产生了新的版本 D3([ Sx,2 ],[ Sy,1 ]),Sz产生了新的版本信息 D4([ Sx,2 ],[ Sz,1 ]),如何产生了冲突的版本D3和D4，有两种解决方法：一种是一阿里客户端逻辑解决或者根据时间戳来确定(选择最新的副本,但是如何保证集群内节点之间的时间同步算法准确性又是另一个问题).</p><p>向量时钟并不能解决版本冲突的问题，Dynamo只能保证最终一致性。</p><h4 id="513-容错">5.1.3 容错</h4><p>Dynamo 把异常分为两种类型:临时性的异常(比如机器假死)和永久性的异常(比如硬盘保修或机器报废等)。其容错机制包括</p><ul><li>数据回传</li></ul><blockquote><p>在Dynamo的设计中，一份数据有多个备份，被写到多个机器节点，如果某一台机器宕机，会有另外一台机器代替他的功能，原本写到该机器的数据会写到这台机器；如果宕机的机器恢复，替代的机器通过Gossip协议发现后，会启动传输任务将暂存的数据回传给宕机的机器。</p></blockquote><ul><li>Merkle树同步</li></ul><blockquote><p>如果超过一定时间，机器仍然处于宕机状态，那就认为该机器不可恢复。此时需要借助Merkle树机制从其他副本进行数据同步。每台机器对每一段范围的数据维护一颗Merkle树，机器同步时首先传输Merkle树信息，并且只需要同步从根到叶子节点的所有节点值均不相同的文件。</p></blockquote><ul><li>读取修复</li></ul><blockquote><p>在NWR中，假设 N=3,W=2,R=2,某个机器K宕机，可能有部分写操作已经返回客户端成功了，但是并没有同步到所有的副本，如果机器K出现永久性异常，比如磁盘故障，三个副本间的数据不一致。客户端的读取操作，会发现不一致，则启动异步的读取修复任务。该任务会合并多个副本的数据，并使用合并后的结果更新过期的副本，从而使副本保持一致。</p></blockquote><h4 id="514-负载均衡">5.1.4 负载均衡</h4><p>Dynamo 使用一致性Hash算法，其负载均衡取决于如何给每台分配虚拟节点号，即token。由于集群环境的异构性，每台物理机器包含多个虚拟节点。一般有两种分配方法。</p><ul><li>随机分配</li></ul><blockquote><p>每个物理节点加入时根据其配置情况分配若干个token。<br>这种方法可控性较差，每个物理节点分配的虚拟节点很分散，当节点加入/离开系统时，集群中的原有节点都需要扫描所有的数据从而找到属于新节点的需要复制的数据，Merkle树也需要全部更新；此外，增量归档/备份变得不可能。</p></blockquote><ul><li>数据范围等分+随机分配</li></ul><blockquote><p>为了来解决以上问题，首先将数据的哈希空间等分为Q=NxS份(N=机器个数,S=每台机器的虚拟节点数)，然后每台机器随机选择S个虚拟节点作为token；这种方法较为均衡，而且每台机器可以对每个范围的数据维护逻辑上的Merkle树，新节点的加入/离开时只需扫描部分数据进行同步即可，并更新这部分数据对应的逻辑Merkle树，增量归档也变得简单。</p></blockquote><h4 id="515-读写流程">5.1.5 读写流程</h4><p>去中心化<br>写数据</p><blockquote><p>Dynamo写入数据时，首先根据一致性哈希算法算出每个数据副本所在的存储节点，选出其中一个作为本次写操作的协调者。紧接着，该协调者并发的向所有其他副本发送写请求，每个副本包括协调者将接受的数据写入本地。当节点将副本写入本地之后，会回复协调者，如果失败，些日哦阿哲会将之加入重试列表不断重试。直到包括协调者的W个副本写入成功，协调者回复客户端写入成功。协调者回复成功后，还会继续等待或者重试，知道所有的副本都写入成功。</p></blockquote><p>读数据</p><blockquote><p>Dynamo读取数据时，首先根据一致性哈希算法计算出每个副本所在的存储节点，选择其中一个作为协调者。接着，协调者根据负载策略选择R个副本，并发的向它们所在节点发送读请求，每个节点包括协调者读取本地数据，读取成功后恢回复协调者读取结果，等待R个副本读取成功后，协调者可以回复客户端。<br>这里由具体的分为两种情况，如果R个副本返回的数据完全一致，那么直接将某个副本的读取结构返回客户端即可，否则需要依据冲突处理规则合并多个副本的读取结果。</p></blockquote><h4 id="516-单机实现">5.1.6 单机实现</h4><p>Dynamo 存储节点包括三个组件：请求协调、成员和故障检测、存储引擎。</p><h4 id="517-讨论">5.1.7 讨论</h4><p>Dynamo 采用无中心化的P2P设计，增加了系统可扩展性，但是也带来了一致性的问题，需要上层应用加以处理。</p><h3 id="52-淘宝-tair">5.2 淘宝 Tair</h3><p>Tair是淘宝开发的一个分布式键值存储引擎。<br>Tair分为持久化和非持久化两种使用方式，非持久化的Tair可以看做一个分布式缓存，持久化的Tair数据存放于磁盘中。</p><h4 id="521-系统架构">5.2.1 系统架构</h4><p>Tair作为分布式系统，由一个中心控制节点和若干个服务节点组成，其中中心控制节点成为Config Server，服务节点成为Data Server。<br>Config Server 负责管理所有的Data Server,Data Server 对外提供各种数据服务，并以心跳的方式将自身状况汇报给Config Server。<br>Config Server 是单点控制点，使用一主一备保证可靠性。</p><p>客户端首先请求Config Server 获取数据所在的 Data Server，然后向Data Server发送读写请求。Tair将数据存放在多台Data Server中，实现异常容错。</p><h4 id="522-关键问题">5.2.2 关键问题</h4><ol><li><p>数据分布<br>根据数据的主键计算哈希值后，分配到Q个桶中，桶是负载均衡和数据迁移的基本单位。<br>Config Server 依照一定的策略将每个桶指派到不同的Data Server上。</p></li><li><p>容错<br>当某个Data Server 不可用时，Config Server 可以检测到。每个哈希桶在Tair中有多个副本，如果是备副本，Config Server 会重新指定一台Data Server，如果是持久化存储，还会复制数据到新的Data Server上。如果是主副本，Config Server 会将备副本中某个正常的副本提升为主副本，对外提供服务，bong选择另一台Data Server 增加一个备副本。</p></li><li><p>数据迁移<br>机器的加入/离开或者负载不均衡可能导致桶的迁移，迁移的过程中需要对外保证服务。请求首先指向桶的原有机器，当某个桶未迁移时，请求会由该桶负责，正在迁移时，同样由该桶负责，但会记录写请求，迁移完成后，将写记录发送给迁移的桶，应用修改。迁移完成后会从原桶的机器转发请求到迁移桶的机器。</p></li><li><p>Config Server<br>客户端缓存路由表，大多数情况下，客户端不需要访问Config Server。<br>每次路由的变更，Config Server 都会将新的配置信息推给Data Server；当客户端访问Data Server，会发送给客户端路由表的版本号，如果客户端发现自己的版本号过期，那么会访问 Config Server 获取新的路由表，或者当访问 Data Server 不可达时，也会获取新的路由表。</p></li><li><p>Data Server负责数据的存储，并根据Config Server 的要求完成数据的复制和迁移工作。</p></li></ol><h4 id="523">5.2.3</h4><p>相对于Dynamo的P2P结构，Tair引入了中心节点Config Server，更容易处理数据的一致性问题。</p><h2 id="第6章-分布式表格系统">第6章 分布式表格系统</h2><p>分布式表格系统对外提供表格模型，每个表格由很多行组成，通过主键唯一标识，每一行包含很多列。整个表格在系统中全局有序，适用于3.3.2节中的顺序分布。<br>Google Bigtable 是分布式表格系统的始祖，它采用双层结构，底层采用GFS作为持久化存储层。GFS+Bigtable 双层结构是一种里程碑式的架构，其他系统包括Microsoft 分布式存储系统 Windows Azure Storage以及开源的Hadoop系统，均为其模仿者。<br>Bigtable的问题在于对外接口不够丰富，因此，Google后续开发了两台系统，一套是Megastore，构建于Bigtable之上，提供更加丰富的接口支持；另一套是Spanner，支持跨多个数据中心数据库事务。<br>本章主要介绍Bigtable的架构及实现，接着分析Megastore的架构最后介绍Microsoft Azure Storage的架构。</p><h3 id="61-google-bigtable">6.1 Google Bigtable</h3><h3 id="62-google-megastore">6.2 Google Megastore</h3><h3 id="63-windows-azure-storage">6.3 Windows Azure Storage</h3><h2 id="第7章-分布式数据库">第7章 分布式数据库</h2><h2 id="第8章-oceanbase-架构初探">第8章 OceanBase 架构初探</h2><p><a href="https://www.oceanbase.com/community" target="_blank" rel="noopener">OceanBase 社区</a><br><a href="https://github.com/tobato/oceanbase" target="_blank" rel="noopener">OceanBase Github</a></p><h2 id="第9章-分布式存储引擎">第9章 分布式存储引擎</h2><h2 id="第10章-数据库功能">第10章 数据库功能</h2><h2 id="第11章-质量保证-运维及实践">第11章 质量保证、运维及实践</h2>]]></content>
      
      
      
        <tags>
            
            <tag> 书籍 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go学习笔记</title>
      <link href="/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/Go%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/Go%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="第一部分-语言">第一部分 语言</h1><h2 id="第一章-类型">第一章 类型</h2><h3 id="变量">变量</h3><h3 id="常量">常量</h3><h3 id="基本类型">基本类型</h3><h3 id="引用类型">引用类型</h3><h3 id="类型转换">类型转换</h3><h3 id="字符串">字符串</h3><h3 id="指针">指针</h3><h3 id="自定义类型">自定义类型</h3><h2 id="第二章-表达式">第二章 表达式</h2><h3 id="保留字">保留字</h3><h3 id="运算符">运算符</h3><h3 id="初始化">初始化</h3><h3 id="控制流">控制流</h3><h2 id="第三章-函数">第三章 函数</h2><h3 id="函数定义">函数定义</h3><h3 id="变参">变参</h3><figure class="highlight plain"><figcaption><span>```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 返回值</span><br><span class="line">可返回多个值</span><br><span class="line"></span><br><span class="line">### 匿名函数</span><br><span class="line">闭包</span><br><span class="line"></span><br><span class="line">### 延迟调用</span><br><span class="line">defer</span><br><span class="line"></span><br><span class="line">### 错误处理</span><br><span class="line">recover panic</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 第四章 数据</span><br><span class="line">### Array</span><br><span class="line">与以往数组的不同之处</span><br><span class="line">- 数组必须是值类型,赋值和传参会复制整个数组,而不是指针</span><br><span class="line">- 数组长度必须是常量,且是类型的组成部分.([2]int 和 [3]int 是不同类型)</span><br><span class="line">- 支持 &quot;==&quot;、&quot;!=&quot;操作符,因为内存总是被初始化过的</span><br><span class="line">- 指针数组[n]\*T,数组指针\*[n]T</span><br><span class="line"></span><br><span class="line">注意直接使用数组与数组指针的区别,直接使用数组是值拷贝,函数内的改变与外界无关</span><br><span class="line">### Slice</span><br><span class="line">slice 并不是数组或者数组指针,它通过内部指针和相关属性引用数组片段,以实现变长方案.</span><br><span class="line"></span><br><span class="line">runtime.h</span><br></pre></td></tr></table></figure><p>struct Slice<br>{                   // must not move anything<br>byte* array;    // actual data<br>uintgo len;     // number of elements<br>uintgo cap;     // allocated number of elements<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### reslice</span><br><span class="line">在slice的基础上再次slice,需要注意的是基于原slice的,注意不要超过其cap.</span><br><span class="line"></span><br><span class="line">#### append</span><br><span class="line">即是在array[slice.high]写数据.</span><br><span class="line">如果超过原slice的cap限制,会重新分配数组并复制数据到新的slice.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### copy</span><br><span class="line">函数copy允许在两个slice之间复制数据，复制长度以len小的为准。两个slice可指向同一个底层数组，允许元素区间重叠。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### Map</span><br><span class="line">引用类型，哈希表。键必须支持相等运算符(== 、!=)类型，比如number、string、pointer、array、struct以及对应的interface。值可以是任何类型，没有限制。</span><br><span class="line"></span><br><span class="line">需要注意的是，从map中取出的是一个value临时复制品，对其成员的修改是没有任何意义的，正确做法是用value或者指针完整替换。</span><br><span class="line"></span><br><span class="line">### Struct</span><br><span class="line">#### 匿名字段</span><br><span class="line">#### 面向对象</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 第五章 方法</span><br><span class="line">### 方法定义</span><br><span class="line">方法总是绑定对象实例，并隐式将实例作为第一实参(receiver).</span><br><span class="line">- 只能为当前包内命名类型定义方法。</span><br><span class="line">- 参数receiver 可以任意命名。如方法中未曾使用，可省略参数名。</span><br><span class="line">- 参数receiver 类型可以是 T 或者 *T 。基类型 T 不能是 接口或指针.</span><br><span class="line">- 不支持方法重载，receiver 只是参数签名的组成部分。</span><br><span class="line">- 可用实例 value 或 pointer 调用全部方法，编译器自动转换。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">没有构造和析构方法，通常用简单工厂模式返回对象实例。</span><br></pre></td></tr></table></figure><p>type Queue struct {<br>elements []interface{}<br>}</p><p>func NewQueue() *Queue {    // 创建对象实例<br>return &amp;Queue{make([]interface{}, 10)}<br>}</p><p>func (*Queue) Push(e interface{}) error {   // 匿名参数，省略 receiver 参数名<br>panic(“not implemented”)<br>}</p><p>//func (Queue) Push(e int) error {    //不支持方法重载,receiver只是参数签名的组成部分,Error : method redeclared :Queue.Push<br>//    panic(“not implemented”)<br>//}</p><p>func (self *Queue) length() int {   //receiver 参数名可以是self、this 或其他。<br>return len(self.elements)<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">方法不过是一种特殊的函数，只需将其还原，就知道 receiver T 和 *T 的差别。</span><br></pre></td></tr></table></figure><p>type Data struct {<br>x int<br>}</p><p>func (self Data) ValueTest() {  // func ValueTest(self Data);<br>fmt.Printf(“Value: p%\n”, &amp;self)<br>}<br>/、n、<br>func (self *Data) PointerTest() {   // func PointerTest(self *Data);<br>fmt.Printf()<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 匿名字段</span><br><span class="line">实例类型定义中包含匿名字段，实例作为隐含参数时，可以直接引用匿名字段，由编译器负责查找。</span><br></pre></td></tr></table></figure><p>type User struct {<br>id   int<br>name string<br>}</p><p>type Manager struct {<br>User<br>}</p><p>func (self *User) ToString() string { // receiver = &amp;(Manager.User)<br>return fmt.Sprintf(“User: %p, %v”, self, self)<br>}</p><p>func print_5_2() {<br>fmt.Printf(&quot;======= 5.2 =======\n&quot;)</p><pre><code>m := Manager{User{1, &quot;Tom&quot;}}fmt.Printf(&quot;Manager: %p\n&quot;, &amp;m)fmt.Println(m.ToString())</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">通过匿名字段，可以获得和继承类似的复合能力。依据编译器查找顺序，只需在外层定义同名方法，就可以实现 &quot;override&quot; 。</span><br></pre></td></tr></table></figure><p>type User struct {<br>id   int<br>name string<br>}</p><p>type Manager struct {<br>User<br>title string<br>}</p><p>func (self *User) ToString() string { // receiver = &amp;(Manager.User)<br>return fmt.Sprintf(“User: %p, %v”, self, self)<br>}</p><p>func (self *Manager) ToString() string {<br>return fmt.Sprintf(“Manager: %p, %v”, self, self)<br>}</p><p>func print_5_2() {<br>fmt.Printf(&quot;======= 5.2 =======\n&quot;)</p><pre><code>m := Manager{User{1, &quot;Tom&quot;}, &quot;Administrator&quot;}fmt.Printf(&quot;Manager: %p\n&quot;, &amp;m)fmt.Println(m.ToString())fmt.Println(m.User.ToString())</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 方法集</span><br><span class="line">每个类型都有与之关联的方法集，这会影响到接口实现规则。</span><br><span class="line">- 类型 T 方法集包括全部 receiver T 方法。</span><br><span class="line">- 类型 *T 方法集包括全部 receiver T + *T 方法。</span><br><span class="line">- 如类型 S 包含匿名字段 T ，则S方法集包含 T 方法。</span><br><span class="line">- 如类型 S 保安匿名字段 *T，则S方法集包含 T + *T 方法。</span><br><span class="line">- 不管嵌入 T 或 \*T，*S 方法集总包含 T + *T 方法。</span><br><span class="line"></span><br><span class="line">使用实例value和pointer 调用方法(含匿名字段)不受方法集约束，编译器总是查找全部方法，并自动转化receiver实参。</span><br><span class="line">&gt;`这部分着实不太理解，可能需要结合实际再看`</span><br><span class="line"></span><br><span class="line">### 表达式</span><br><span class="line">根据调用者不同，方法分为两种表现形式：</span><br><span class="line">&gt;instance.method(args...) ----&gt; \&lt;type&gt;.func(instance,args...)</span><br><span class="line">前者称为 method value，后者 method expression。</span><br><span class="line">两者都可以向普通函数一样赋值和传参，区别在于method value绑定实例，而method expression 需显式传参。</span><br></pre></td></tr></table></figure><p>type User struct {<br>id   int<br>name string<br>}</p><p>func (self *User) Test() {<br>fmt.Printf(&quot;%p, %v\n&quot;, self, self)<br>}</p><p>func print_5_4() {<br>fmt.Printf(&quot;======= 5.4 =======\n&quot;)</p><pre><code>u := User{1, &quot;Tom&quot;}u.Test()mValue := u.TestmValue() // 隐式传达 receivermException := (*User).TestmException(&amp;u) // 显示传达 receiver//mValue 在赋值时赋值了receiver，因为不是指针类型，不受后续修改影响//这里书上给的代码有问题，Test 中的隐藏参数定义为值类型才会复制，使得两次输出不同u.id, u.name = 2, &quot;Jack&quot;u.Test()mValue()</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">需要注意的method value 会复制receiver</span><br></pre></td></tr></table></figure><p>type User struct {<br>id   int<br>name string<br>}</p><p>func (self User) Test() {<br>fmt.Printf(&quot;%p, %v\n&quot;, self, self)<br>}</p><p>func print_5_4() {<br>u := User{1, “Tom”}</p><pre><code>//mValue 在赋值时赋值了receiver，因为不是指针类型，不受后续修改影响//这里书上给的代码有问题，Test 中的隐藏参数定义为值类型才会复制，使得两次输出不同u.id, u.name = 2, &quot;Jack&quot;u.Test()mValue()</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">在汇编层次，method value 和闭包的实现方式相同，实际返回 FuncVal 类型对象。</span><br></pre></td></tr></table></figure><p>FuncVal { method_address, receiver_copy }</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可依据方法集转换 method expression，注意receiver类型的差异。</span><br></pre></td></tr></table></figure><p>type User struct {<br>id int<br>name string<br>}</p><p>func (self *User) TestPointer() {<br>fmt.Printf(“TestPointer: %p, %v\n”, self, self)<br>}</p><p>func (self User) TestValue() {<br>fmt.Printf(“TestValue: %p, %v\n”, self, self)<br>}</p><p>func main() {<br>u := User{1, “Tom”}<br>fmt.Printf(“User: %p, %v\n”, &amp;u, u)</p><pre><code>mv := User.TestValuemv(u)mp := (*User).TestPointermp(&amp;u)mp2 := (*User).TestValue    // *User 方法集 包含 TestValuemp2(&amp;u)                     // 签名变为 func TestValue(self *User)                            // 实际依然是 receiver value copy</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">将方法还原为函数。</span><br></pre></td></tr></table></figure><p>type Data struct {}<br>func (Data) TestValue() {}<br>func (*Data) TestPointer() {}<br>func main() {<br>var p *Data = nil<br>p.TestPointer()</p><pre><code>(*Data)(nil).TestPointer()  // method value(*Data).TestPointer(nil)    // method expression//p.TestValue()             // invalid memory address or nil pointer dereference//(Data)(nil).TestValue()   // cannot convert nil to type Data//Data.TestValue(nil)       // cannot use nil as type Data in function argument</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 第六章 接口</span><br><span class="line">### 接口定义</span><br><span class="line">接口是一个或多个方法签名的集合，任何类型的 方法集 中只要拥有与之对应的全部方法，就表示它 &quot;实现&quot; 了该接口，无须在该类型上显示添加接口声明。</span><br><span class="line">所谓对应方法，指有相同名称、参数列表(不包含参数名)以及返回值。当然，该类型可以有其他方法</span><br><span class="line">命名规范：</span><br><span class="line">- 接口名习惯以er结尾</span><br><span class="line">- 接口只有方法签名，没有实现</span><br><span class="line">- 接口没有数据字段</span><br><span class="line">- 可在接口中嵌入其他接口</span><br><span class="line">- 类型可实现多个接口</span><br></pre></td></tr></table></figure><p>type Stringer interface {<br>String() string<br>}</p><p>type Printer interface {<br>Stringer //接口嵌入<br>Print()<br>}</p><p>type User struct {<br>id   int<br>name string<br>}</p><p>func (self *User) String() string {<br>return fmt.Sprintf(“user %d, %s”, <a href="http://self.id" target="_blank" rel="noopener">self.id</a>, <a href="http://self.name" target="_blank" rel="noopener">self.name</a>)<br>}</p><p>func (self *User) Print() {<br>fmt.Println(self.String())<br>}</p><p>func main() {<br>var t Printer = &amp;User{1, “Tom”}<br>t.Print()<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">空接口 interface&#123;&#125; 没有任何方法签名，即任何类型都实现了空接口，起作用类似于面向对象语言里的根对象 object,可以存储任何类型的数据。</span><br></pre></td></tr></table></figure><p>func Print(v interface{}) {<br>fmt.Printf(&quot;%T: %v\n&quot;, v, v)<br>}</p><p>func main() {<br>Print(1)<br>Print(“Hello, World”)<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">匿名接口可以用作变量类型，或结构成员。</span><br></pre></td></tr></table></figure><p>type Tester struct {<br>s interface {<br>String() string<br>}<br>}</p><p>type User struct {<br>id   int<br>name string<br>}</p><p>func (self *User) String() string {<br>return fmt.Sprintf(“user %d, %s”, <a href="http://self.id" target="_blank" rel="noopener">self.id</a>, <a href="http://self.name" target="_blank" rel="noopener">self.name</a>)<br>}</p><p>func main() {<br>tt := Tester{&amp;User{1, “Tome”}}<br>fmt.Println(tt.s.String())<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">### 执行机制</span><br><span class="line">接口对象由接口表(interface table)指针和数据指针组成。</span><br></pre></td></tr></table></figure><p>runtime.h<br>struct Iface<br>{<br>Itab* tab;<br>void* data;<br>};</p><p>struct Itab<br>{<br>InterfaceType* inter;<br>Type* type;<br>void (*fun[])(void);<br>};</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">接口表存储元数据信息，包括接口类型、动态类型，以及实现接口的方法指针。无论是反射还是接口调用方法，都会用到这些信息。</span><br><span class="line"></span><br><span class="line">数据指针持有的是目标对象的只读复制品，复制完整对象或者指针。</span><br></pre></td></tr></table></figure><p>type User struct {<br>id   int<br>name string<br>}</p><p>func main() {<br>u := User{1, “Tom”}<br>var i interface{} = u</p><pre><code>u.id = 2u.name = &quot;Jack&quot;fmt.Printf(&quot;%v\n&quot;, u)fmt.Printf(&quot;%v\n&quot;, i.(User))</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">接口转型返回临时对象，只有指针才能修改其状态。</span><br></pre></td></tr></table></figure><p>type User struct {<br>id   int<br>name string<br>}</p><p>func main() {<br>u = User{1, “Tom”}<br>var vi, pi interface{} = u, &amp;u<br>//vi.(User).name = “Jack”// Error : cannot assign to vi.(User).name<br>pi.(*User).name = “Jack”</p><pre><code>fmt.Printf(&quot;%v\n&quot;, vi.(User))fmt.Printf(&quot;%v\n&quot;, pi.(*User))</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">只有当 tab 和 data 都为 nil时，接口才为 nil。</span><br></pre></td></tr></table></figure><p>var a interface{} = nil         // tab = nil, data = nil<br>var b interface{} = (*int)(nil) // tab 包含 *int 类型信息，data = nil</p><p>type iface struct {<br>itab, data uintptr<br>}</p><p>ia := *(*iface)(unsafe.Pointer(&amp;a))<br>ib := *(*iface)(unsafe.Pointer(&amp;b))</p><p>fmt.Println(a == nil, ia)<br>fmt.Println(b == nil, ib, reflect.ValueOf(b).IsNil())</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 接口转换</span><br><span class="line">利用类型推断，可判断接口对象是否某个具体的接口或类型。</span><br></pre></td></tr></table></figure><p>type User struct {<br>id   int<br>name string<br>}</p><p>func (self *User) String() string {<br>return fmt.Sprintf(&quot;%d, %s&quot;, <a href="http://self.id" target="_blank" rel="noopener">self.id</a>, <a href="http://self.name" target="_blank" rel="noopener">self.name</a>)<br>}</p><p>func main() {<br>var o interface{} = &amp;User{1, “Tom”}<br>if i, ok := o.(fmt.Stringer); ok { // User实现了String()方法，实现了Stringer接口<br>fmt.Println(i)<br>}</p><pre><code>u := o.(*User)// u := o.(User)// panic : interface{} is *sixthree.User, not sixthree.Userfmt.Println(u)</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">还可用 switch 做批量类型判断，不支持 fallthrough。</span><br></pre></td></tr></table></figure><p>func main() {<br>var o interface{} = &amp;User{1, “Tom”}<br>switch v := o.(type) {<br>case nil: // o == nil<br>fmt.Println(“nil”)<br>case fmt.Stringer: // interface<br>fmt.Println(“interface “, v)<br>case func() string: // func<br>fmt.Println(v())<br>case *User: // *struct<br>fmt.Printf(”%d, %s\n”, <a href="http://v.id" target="_blank" rel="noopener">v.id</a>, <a href="http://v.name" target="_blank" rel="noopener">v.name</a>)<br>default:<br>fmt.Println(“unknow”)<br>}<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">超级接口可以转化为子集接口(只能向下转型，父接口指向实际子接口)，反之出错。</span><br></pre></td></tr></table></figure><p>type Stringer interface {<br>String() string<br>}</p><p>type Printer interface {<br>String() string<br>Print()<br>}</p><p>type User struct {<br>id   int<br>name string<br>}</p><p>func (self *User) String() string {<br>return fmt.Sprintf(&quot;%d, %s&quot;, <a href="http://self.id" target="_blank" rel="noopener">self.id</a>, <a href="http://self.name" target="_blank" rel="noopener">self.name</a>)<br>}</p><p>func (self *User) Print() {<br>fmt.Println(self.String())<br>}</p><p>func main() {<br>var o Printer = &amp;User{1, “Tom”}<br>var s Stringer = o<br>fmt.Println(s.String())<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 接口技巧</span><br><span class="line">让编译器检查，以确保某个类型实现接口。</span><br></pre></td></tr></table></figure><p>var _ fmt.Stringer = (*Data)(nil)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">某些时候，可以让函数直接&quot;实现&quot;接口。</span><br></pre></td></tr></table></figure><p>type Tester interface {<br>Do()<br>}</p><p>type FuncDo func()</p><p>func (self FuncDo) Do() {<br>self()<br>}</p><p>func main() {<br>var t Tester = FuncDo(func() {<br>println(“Hello, World”)<br>})<br><a href="http://t.Do" target="_blank" rel="noopener">t.Do</a>()<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 第七章 并发</span><br><span class="line">### Goroutine</span><br><span class="line">Go 在语言层面对并发编程提供支持，一种类似协程，称作 goroutine 的机制。</span><br><span class="line"></span><br><span class="line">只需要在函数调用语句前添加 go 关键字，就可创建并发执行单元。开发人员无需了解任何执行细节，调度器会自动将其安排至合适的系统线程上执行。goroutine 是一种非常轻量级的实现，可在单个进程里执行成千上万的并发任务。</span><br><span class="line"></span><br><span class="line">入口函数 main 以 goroutine 运行。另有与之配套的 channel 类型，用以实现&quot;以通讯来共享内存&quot;的 CSP 模式。</span><br></pre></td></tr></table></figure><p>go func() {<br>println(“Hello, World!”)<br>}()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">调度器不能保证多个 goroutine 执行次序，且进程退出时不会等待它们结束。</span><br><span class="line"></span><br><span class="line">默认情况下，进程启动后仅允许一个系统线程服务于 goroutine 。可使用环境变量或标准库函数 runtime.GOMAXPROCS 修改，让调度器用多个线程实现多核并行，而不仅仅是并发。</span><br></pre></td></tr></table></figure><p>func sum(id int) {<br>var x int64<br>for i := 9; i &lt; math.MaxUint32; i++ {<br>x += int64(i)<br>}</p><pre><code>println(id, x)</code></pre><p>}</p><p>func main() {<br>wg := new(sync.WaitGroup)<br>wg.Add(2)</p><pre><code>for i := 0; i &lt; 2; i++ {go func(id int) {defer wg.Done()sum(id)}(i)}wg.Wait()</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">也可以调用 runtime.Goexit 将立即终止当前 goroutine 执行，调度器确保所有已注册 defer 延迟调用被执行。</span><br></pre></td></tr></table></figure><p>func main() {<br>wg := new(sync.WaitGroup)<br>wg.Add(1)</p><pre><code>go func() {defer wg.Done()defer println(&quot;A.defer&quot;)func() {defer println(&quot;B.defer&quot;)runtime.Goexit() // 终止当前 goroutineprintln(&quot;B&quot;)     // 不会执行}()println(&quot;A&quot;)}()wg.Wait()</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">和协程 yield 作用类似，Gosched 让出底层线程，将当前 goroutine 暂停，放回队列等待下次被调度执行。</span><br></pre></td></tr></table></figure><p>func main() {<br>wg := new(sync.WaitGroup)<br>wg.Add(2)</p><pre><code>go func() {defer wg.Done()for i := 0; i &lt; 6; i++ {println(i)if i == 3 {runtime.Gosched()}}}()go func() {defer wg.Done()println(&quot;Hello, World!&quot;)}()wg.Wait()</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### Channel</span><br><span class="line">引用类型 channel 是 CSP 模式的具体实现，用于多个 goroutine 通讯。其内部实现了同步，确保并发安全。</span><br><span class="line"></span><br><span class="line">默认为同步模式，需要发送和接受配对，否则就会被阻塞，知道另一方准备好后被唤醒。</span><br></pre></td></tr></table></figure><p>func main() {<br>data := make(chan int)  // 数据交换队列<br>exit := make(chan bool) // 退出通知</p><pre><code>go func() {for d := range data { // 从队列迭代接受数据，直到 closefmt.Println(d)}fmt.Println(&quot;recv over.&quot;)exit &lt;- true // 发出退出通知}()data &lt;- 1 // 发送数据data &lt;- 2data &lt;- 3close(data)fmt.Println(&quot;send over.&quot;)&lt;-exit // 等待退出通知</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">异步方式通过判断缓冲区来决定是否阻塞。如果缓冲区已满，发送被阻塞；缓冲区为空，接受被阻塞。</span><br><span class="line"></span><br><span class="line">通常情况下，异步 channel 可减少排队阻塞，具备更高的效率。但应该考虑使用指针规避大对象拷贝，将多个元素打包，减少缓冲区大小等。</span><br></pre></td></tr></table></figure><p>func main() {<br>fmt.Println(&quot;=== out_2 ====&quot;)<br>data := make(chan int, 3) // 缓冲区可以存储 3 个元素<br>exit := make(chan bool)</p><pre><code>data &lt;- 1 // 在缓冲区未满前，不会阻塞。data &lt;- 2data &lt;- 3go func() {for d := range data { // 在缓冲区未空前，不会阻塞。fmt.Println(d)}exit &lt;- true}()data &lt;- 4 // 如果缓冲区已满，阻塞。data &lt;- 5close(data)&lt;-exit // 等待退出通知。</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">缓冲区是内部属性，并非类型构成要素。</span><br></pre></td></tr></table></figure><p>var a, b chan int = make(chan int), make(chan int, 3)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">除了用 range 外，还可以用 ok-idiom 模式判断 channel 是否关闭。</span><br></pre></td></tr></table></figure><p>for {<br>if d, ok := &lt;-data; ok {<br>fmt.Println(d)<br>} else {<br>break<br>}<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">向 closed channel 发送数据会引发 panic 错误，接受立即返回零值。而 nil channel,无论收发都会被阻塞。</span><br><span class="line"></span><br><span class="line">内置函数 len 返回未被读取的缓冲元素数量，cap 返回缓冲区大小。</span><br></pre></td></tr></table></figure><p>d1 := make(chan int)<br>d2 := make(chan int, 3)<br>d2 &lt;- 1</p><p>fmt.Println(len(d1), cap(d1))// 0 0<br>fmt.Println(len(d2), cap(d2))// 1 3</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### 单向</span><br><span class="line">可以将 channel 隐式转换为单向队列，只收或只发。</span><br></pre></td></tr></table></figure><p>c := make(chan int, 3)</p><p>var send chan&lt;- int = c// send-only<br>var recv &lt;-chan int = c// receive-only<br>send &lt;- 1<br>// &lt;-send// Error : receive from send-only type chan&lt;- int<br>&lt;-recv<br>// recv &lt;- 2// Error : send to receive-only type &lt;-chan int</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">不能将单向 channel 转换为普通 channel</span><br></pre></td></tr></table></figure><p>d := (chan int)(send)// Error : cannot convert type chan&lt;- int to type chan int<br>d := (chan int)(recv)// Error : cannot convert type &lt;-chan int to type chan int</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### 选择</span><br><span class="line">如果需要同时处理多个 channel，可使用 select 语句。可以随机选择一个可用 channel 做收发操作，或执行 default case。</span><br></pre></td></tr></table></figure><p>func main() {<br>a, b := make(chan int, 3), make(chan int)</p><pre><code>go func() {v, ok, s := 0, false, &quot;&quot;for {select { // 随机选择可用 channel，接收数据。case v, ok = &lt;-a:s = &quot;a&quot;case v, ok = &lt;-b:s = &quot;b&quot;}if ok {fmt.Println(s, v)} else {os.Exit(0)}}}()for i := 0; i &lt; 5; i++ {select { // 选择随机可用 channel，发送数据。case a &lt;- i:case b &lt;- i:}}close(a)select {} // 没有可用 channel，阻塞 main goroutine。</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在循环中使用 select default case 需要小心，避免形成洪水。</span><br><span class="line"></span><br><span class="line">#### 模式</span><br><span class="line">可以用简单工厂模式打包并发任务和 channel。</span><br></pre></td></tr></table></figure><p>func NewTest() chan int {<br>c := make(chan int)<br>rand.Seed(time.Now().UnixNano())</p><pre><code>go func() {time.Sleep(time.Second)c &lt;- rand.Int()}()return c</code></pre><p>}</p><p>func main() {<br>t := NewTest()<br>println(&lt;-t)// 等待 goroutine 结束返回。<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">用 channel 实现信号量(semaphore).</span><br></pre></td></tr></table></figure><p>func main() {<br>wg := sync.WaitGroup{}<br>wg.Add(3)<br>sem := make(chan int, 1)</p><pre><code>for i := 0; i &lt; 3; i++ {go func(id int) {defer wg.Done()sem &lt;- 1// 向 sem 发送数据，阻塞或者成功for x := 0; x &lt; 3; x++ {fmt.Println(id, x)} &lt;-sem// 接受数据，使得其他阻塞 goroutine 可以发送数据。}(i)}wg.Wait()</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">用 closed channel 发出退出通知。</span><br></pre></td></tr></table></figure><p>func main() {<br>var wg sync.WaitGroup<br>quit := make(chan bool)</p><pre><code>for i := 0; i &lt; 2; i++ {wg.Add(1)go func(id int) {defer wg.Done()task := func() {println(id, time.Now().Nanosecond())time.Sleep(time.Second)}for {select {case &lt;-quit:// closed channel 不会阻塞，因此可用作退出通知。returndefault:// 执行正常任务task()}}}(i)}time.Sleep(time.Second * 5)// 让测试 goroutine 运行 5s、close(quit)// 发出退出通知。wg.Wait()</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">用 select 实现超时(timeout).</span><br></pre></td></tr></table></figure><p>func main() {<br>w := make(chan bool)<br>c := make(chan int, 2)</p><pre><code>go func() {select {case v := &lt;-c:fmt.Pirntln(v)case &lt;-time.After(time.Second * 3):fmt.Println(&quot;timeout.&quot;)}w &lt;- true}()// c &lt;- 1// 注释掉，以免引发 timeout。&lt;-w</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">channel 是第一类对象，可传参(内部实现为指针)或者作为结构成员。</span><br></pre></td></tr></table></figure><p>type Request struct {<br>data []int<br>ret  chan int<br>}</p><p>func NewRequest(data …int) *Request {<br>return &amp;Request{data, make(chan int, 1)}<br>}</p><p>func Process(req *Request) {<br>x := 0<br>for _, i := range req.data {<br>x += i<br>}</p><pre><code>req.ret &lt;- x</code></pre><p>}</p><p>func main() {<br>req := NewRequest(10, 20, 30)<br>Process(req)<br>fmt.Println(&lt;-req.ret)<br>}</p><pre><code>## 第八章 包### 工作空间### 源文件### 包结构### 文档## 第九章 进阶### 内存布局### 指针陷阱### cgo### Reflect# 第二部分 源码## Memory Allocator## Garbage Collector## Goroutine Scheduler## Channel## Defer## Finalizer# 第三部分 附录</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 书籍 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>chubby分布式锁服务</title>
      <link href="/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F/chubby/"/>
      <url>/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F/chubby/</url>
      
        <content type="html"><![CDATA[<p>Google File System  和  Google BigTable 中都使用Chubby 分布式锁服务，比较好奇，待完整分析</p>]]></content>
      
      
      
        <tags>
            
            <tag> Distributed </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%85%AC%E5%BC%80%E8%AF%BE/MIT6.824/Readme/"/>
      <url>/2020/11/19/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%85%AC%E5%BC%80%E8%AF%BE/MIT6.824/Readme/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>EdgeCloudSim 模拟</title>
      <link href="/2020/10/29/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/EdgeCloudSim/"/>
      <url>/2020/10/29/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/EdgeCloudSim/</url>
      
        <content type="html"><![CDATA[<p>首先EdgeCloudSim基于CloudSim 因为应当先分析 CloudSim</p><p>着重参考 [相关论文](Microservices Scheduling Model Over Heterogeneous Cloud-Edge Environments As Support for IoT Applications)</p><h1 id="cloudsim">CloudSim</h1><p><a href="http://cloudbus.org/cloudsim/" target="_blank" rel="noopener">官网</a><br><a href="https://github.com/Cloudslab/cloudsim" target="_blank" rel="noopener">CloudSim Github</a><br><a href="http://cloudbus.org/cloudsim/container.html" target="_blank" rel="noopener">CloudSim Container</a><br><a href="https://www.cloudsimtutorials.online/cloudsim-simulation-toolkit-an-introduction/" target="_blank" rel="noopener">CloudSim 各个组件的解释</a><br><a href="https://www.cloudsimtutorials.online/beginners-guide-to-cloudsim-project-structure/" target="_blank" rel="noopener">CloudSim 根据代码结构分析</a></p><p>一个DataCenter 有多个Host物理机器,一个host分为多个Vm</p><p>CLoudSim 如何记录cpu 内存利用率 SimLogger.addVmUtilizationLog<br><a href="https://stackoverflow.com/questions/28436419/cloudsim-monitoring-vm-cpu-utilization-and-bw-utilization-in-constant-intervals" target="_blank" rel="noopener">解决方法1</a></p><p>如何触发连续任务,如何实现选择固定的vm<br>继承DataCenterBroker,重写processOtherEvent方法,实现提交任务即可<br>可借鉴<a href="https://github.com/nisere/onlinesim" target="_blank" rel="noopener">OnlienCloudSim 实现</a><br>simEvent 的实现包括DataCenter DataCenterBroker 包含processEvent 方法,CloudSim同样包括该方法<br>processEvent 中processOtherEvent 可以针对相关的event处理,可以增加相应的cloudlet？</p><p>在这里 如何对于一个cloudlet/task如何实现跨DataCenter的平衡和调度?需要知道每个VM的资源的使用情况?如何考虑多条不同类别调用链之前的干扰(会有资源干扰么)?</p><p>调度可以参考 《云计算》pdf</p><p>CloudletScheduler 是  VM 调度 自己的等待队列作业的方法</p><h2 id="javasim">JavaSim</h2><p><a href="https://blog.csdn.net/zyxhangiian123456789/article/details/88389406" target="_blank" rel="noopener">参考1</a><br>JavaSim 是面向对象的Java离散时间仿真工具包,仿真模型分为3种:连续时间、离散时间、连续时间离散事件</p><ul><li>连续时间:状态随时间连续而变化的系统,通常用微分方程来描述.</li><li>离散事件:仅在选定时间考虑系统.在观测点之间选择适当的小间隔,可以用离散的时间来近似模拟连续时间</li><li>连续时间离散事件:时间参数是连续的,观察期是一个间隔.</li></ul><h1 id="edgecloudsim">EdgeCloudSim</h1><p>两个讨论地方:<br><a href="https://github.com/CagataySonmez/EdgeCloudSim/issues" target="_blank" rel="noopener">Github Issues</a><br><a href="https://groups.google.com/g/edgecloudsim/" target="_blank" rel="noopener">Google Group</a></p><p>如何调度有顺序的任务,利用消息触发机制,sendEvent 然后触发调度<br>分析博客:<br><a href="https://blog.csdn.net/wjh1313677/article/details/45626023" target="_blank" rel="noopener">参考1</a><br><a href>参考2</a><br><a href>参考3</a></p><p>core/SimManager 的 processEvent 在运行过程中没有被调用,那么如何模拟调用链以及event在cloudSim如何实现</p><h2 id="simsetting">SimSetting</h2><p>中有不同策略:NLY_EDGE,ONLY_MOBILE,HYBRID<br>BasicEdgeOrchestrator中 其中Hybrid策略,首先判断计算要求是否能在移动端满足,如果能就在移动端进行,否则卸载到边缘端</p><p>Example4利用<a href="https://blog.csdn.net/yuyanjingtao/article/details/90177004" target="_blank" rel="noopener">fuzzy logic</a> <a href="https://www.youtube.com/watch?v=RFP2M0w4NlY" target="_blank" rel="noopener">Youtube 视频</a><br>判断是否 将任务卸载到云端还是留在边缘端<br>模糊逻辑有相关概念也对应类FIS的相关函数:隶属度、模糊化、去模糊化等等</p><p>如何实现任务之间的依赖？<br><a href="https://groups.google.com/g/edgecloudsim/c/-H-7XuxwqoA/m/KtLQBxn-BAAJ" target="_blank" rel="noopener">可能的解决方案</a></p><h2 id="network-模块">network 模块</h2><p>队列模型(MM1Queue)<br><a href="https://blog.csdn.net/t949500898/article/details/107420217" target="_blank" rel="noopener">参考1</a><br><a href="https://max.book118.com/html/2018/0303/155583383.shtm" target="_blank" rel="noopener">参考2 排队论PPT</a><br>排队现象存在的基础:资源的有限性+需求的随机性<br>排队系统的复杂性在于随机性：到达与离去的(服务率)均不确定,工作于随机状态</p><p>如何描述一个排队系统<br>排队系统三要素 m , $\lambda$ , $\mu$</p><ul><li>m: 窗口数,表示资源的量<ul><li>可同时向顾客提供服务的设备数</li><li>单窗口:m=1,多窗口:m&gt;1</li></ul></li><li>$\lambda$: 顾客平均到达率</li><li>$\mu$: 系统平均服务率</li></ul><p>到达与服务的分布类型</p><ul><li>指数分布</li><li>泊松分布</li><li>r阶爱尔兰分布</li><li>R阶指数分布</li><li>确定性分布</li></ul><p>系统工作方式</p><ul><li>服务规则<ul><li>先来先服</li><li>后到先服</li><li>基于优先级服务</li></ul></li><li>排队规则<ul><li>等待型<ul><li>不拒绝系统</li></ul></li><li>截止型<ul><li>n=m,即时拒绝,电话网</li><li>m&gt;n,延时拒绝,缓冲区数据通信</li></ul></li></ul></li></ul><p>如何分析一个排队系统</p><ul><li>排队对长k的概率分布、均值、方差</li><li>等待时间w的均值、方差</li><li>服务时间$$</li><li>系统时间</li><li>系统效率<ul><li>窗口占有率: $\eta = r/m $</li></ul></li><li>稳定性</li><li>$\rho = \lambda / \mu$<ul><li>if $\rho &gt; m$,不拒绝系统,not stable</li><li>if $\rho &gt; m$,截止型系统,stable</li></ul></li></ul><p>简单的基于</p><h1 id="workflowsim">WorkflowSim</h1><p><a href="https://github.com/WorkflowSim/WorkflowSim-1.0" target="_blank" rel="noopener">Github</a><br>基于CloudSim的任务流编排工具,某个任务依赖于其他任务的执行而执行</p><h1 id="multirecloudsim">MultiRECloudSim</h1><p><a href="https://github.com/JackiePeng336/MultiRECloudSim" target="_blank" rel="noopener">Github</a><br><a href="https://blog.csdn.net/cp3equalsrefs3/article/details/106243451" target="_blank" rel="noopener">CSDN 介绍</a></p><h1 id="cloudsimplus">CloudSimPlus</h1><h1 id="pureedgesim">PureEdgeSim</h1><h2 id="使用事项">使用事项</h2><ol><li>使用idea导入libs下 本地jar包</li></ol><h2 id="实验实现">实验实现</h2><p>基于PureEdgeSim实现</p><h3 id="根据配置确定vm的初始放置位置">根据配置确定Vm的初始放置位置</h3><p>重写CustomDataCenterBroker的defaultDatacenterMapper方法,返回配置中Vm所制定的DataCenter</p><h3 id="出现问题">出现问题</h3><ol><li>利用率卡在50%</li></ol><blockquote><p>由于资源分配丰富,所有的Vm都分配在同一个DataCenter,导致那个DataCenterCpu利用率100%,另外一个0%,总共卡在50%.</p></blockquote><h3 id="cloudlet-链">Cloudlet 链</h3><ol start="2"><li>cloudlet链</li></ol><blockquote><p>利用其提供的CloudSim继承自Simluation的addOnEventProcessingListener的触发下一个任务(可以根据调用链的类型以及其节点确定下一个CLoudLet以及VM的位置)</p></blockquote><h3 id></h3><h2 id="程序设计">程序设计</h2><p>TaskChainDef 的构成是什么样的?</p><ul><li>一系列Task的组合,是链表还是数组,由于chain的定义是不变的,似乎数组更合适</li><li>确定是Task的组合么？是否能够确定?</li><li>chainDef包含的task</li></ul><h2 id="task时间问题">Task时间问题</h2><p>offloadingTime:作业生成时间,通过Task.setTime设置<br>receptionTime:作业到达可以执行的时间.<br>借助listener 如何设置传输时间(WAN_PROPAGATION_DELAY 默认只有边到云端的传播时间)</p><p>ServerManager.loadVms 从文件中读取VM配置</p><h1 id="data">Data</h1><p><a href="https://datasetsearch.research.google.com/" target="_blank" rel="noopener">Google 数据检索平台</a><br><a href="https://databank.illinois.edu/datasets/IDB-6738796" target="_blank" rel="noopener">Pre-processed Tracing Data for Popular Microservice Benchmarks</a><br><a href="https://zenodo.org/record/3628454#.X6vRj2gzbb0" target="_blank" rel="noopener">Execution Traces of an MNIST Workflow on a Serverless Edge Testbed</a><br><a href="https://zenodo.org/record/3254576#.X6vMg2gzbb1" target="_blank" rel="noopener">Workflow Trace Archive shell trace</a><br><a href="https://iotanalytics.unsw.edu.au/iottraces" target="_blank" rel="noopener">iotanalytics</a><br><a href="https://cloudstor.aarnet.edu.au/plus/s/ds5zW91vdgjEj9i?path=%2FRaw_datasets" target="_blank" rel="noopener">TON_IoT</a><br><a href="https://cloudstor.aarnet.edu.au/plus/s/ds5zW91vdgjEj9i?path=%2FProcessed_datasets%2FProcessed_Network_dataset" target="_blank" rel="noopener">IIOT NETWORK TRAFFIC</a><br><a href="https://github.com/saifulislamPhD/IoT-Compute-Dataset" target="_blank" rel="noopener">Dataset consists of heterogeneous IoT jobs/tuples containing</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 源码解析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法题</title>
      <link href="/2020/09/22/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E7%AE%97%E6%B3%95%E9%A2%98/"/>
      <url>/2020/09/22/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E7%AE%97%E6%B3%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="面试题">面试题</h1><h2 id="剑指offer">剑指Offer</h2><ol><li>二维数组中的查找</li><li>替换空格</li><li>从尾到头打印链表</li><li>重建二叉树</li><li>用两个栈实现队列</li><li>旋转数组的最小数字</li><li>斐波拉契数列</li><li>二进制中1的个数</li><li>数值的整数次方</li><li>打印1到最大的n位数</li><li>在O(1)时间删除链表结点</li><li>调整数组顺序使奇数位于偶数前面</li><li>链表中的倒数第k个结点</li><li>反转链表</li><li>合并两个排序的链表</li><li>树的子结构</li><li>二叉树的镜像</li><li>顺时针打印矩阵</li><li>包含min函数的栈</li><li>栈的压入、弹出序列</li><li>从上往下打印二叉树</li><li>二叉搜索树的后序遍历序列</li><li>二叉树中和为某一值的路径</li><li>复杂链表的复制</li><li>二叉搜索树与双向链表</li><li>字符串的排列</li><li>数组中出现次数超过一半的数字</li><li>最小的k个数</li><li>连续子数组的最大和</li><li>从1到n整数中1出现的次数</li><li>把数组排成最小的数</li><li>丑数</li><li>第一个只出现一次的字符</li><li>数组中的逆序对</li><li>两个链表的第一个公共结点</li><li>数字在排序数组中出现的次数</li><li>二叉树的深度</li><li>判断是否平衡二叉树</li><li>数组中只出现一次的数字</li><li>和为s的两个数字</li><li>和为s的连续正数序列</li><li>翻转单词顺序</li><li>左旋转字符串</li><li>n个骰子的点数</li><li>扑克牌的顺子</li><li>圆圈中最后剩下的数字</li><li>求1+2+…+n</li><li>不用加减乘除做加法</li><li>不能被继承的类</li><li>把字符串转换成整数</li><li>树中两个结点的最低公共祖先</li><li>数组中重复的数字</li><li>构建乘积数组</li><li>正则表达式匹配</li><li>表示数值的字符串</li><li>字符流中第一个不重复的字符</li><li>链表中环的入口结点</li><li>删除链表中重复的结点</li><li>二叉树的下一个结点</li><li>对称的二叉树</li><li>把二叉树打印成多行</li><li>按之字形顺序打印二叉树</li><li>序列化二叉树</li><li>二叉树搜索树的第k个结点</li><li>数据流中的中位数</li><li>滑动窗口的最大值</li><li>矩阵中的路径</li><li>机器人的运动范围</li></ol><h2 id="内容概括">内容概括</h2><p><a href="https://www.zhihu.com/question/34814570/answer/674463475" target="_blank" rel="noopener">参考</a></p><h3 id="算法">算法</h3><ul><li>排序算法:快速排序,归并排序,技术排序</li><li>搜索算法:回溯,递归,剪枝</li><li>图论：最短路径,最小生成树,网络流建模</li><li>动态规划：背包问题,最长子序列,计数问题</li><li>基础技巧：分治,倍增,二分,贪心</li></ul><h3 id="数据结构">数据结构</h3><ul><li>数组与链表：单双向链表,跳舞链条,环</li><li>栈与队列</li><li>树与图：最近公共祖先 并查集</li><li>哈希表</li><li>堆:大小根堆 可并堆</li><li>字符串：字典树 后缀树</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/09/12/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/log/"/>
      <url>/2020/09/12/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/log/</url>
      
        <content type="html"><![CDATA[<ul><li><p>RocketMQ</p></li><li><p>Spring bean 分类</p></li><li><p>什么是Spring MVC ？简单介绍下你对springMVC的理解?</p></li><li><p>SpringMVC的流程？</p></li><li><p>Springmvc的优点:</p></li><li><p>Spring MVC的主要组件？</p></li><li><p><a href="https://blog.csdn.net/a745233700/article/details/80963758" target="_blank" rel="noopener">SpringMVC常见面试题总结</a></p></li><li><p><a href="https://blog.csdn.net/a745233700/article/details/80959716" target="_blank" rel="noopener">Spring常见面试题总结</a></p></li><li><p>注解</p></li><li><p>@Repository：用于标注数据访问组件,即dao组价</p></li><li><p>@Primary @Qualifier</p></li><li><p>selcet/poll/epoll 都属于 同步IO</p></li><li><p>Netty</p></li><li><p>mybatic 面试题</p></li><li><p>MyBatis中#和$区</p></li><li><p>VM 调优参数</p></li><li><p>CyclicBarrier的使用</p></li><li><p>CountDownLatch CyclicBarrier的使用</p></li><li><p>GC 对象复制之后 的forward poi</p></li><li><p>TCC：Try-Confirm-Cancel</p></li><li><p>JTA</p></li><li><p>RPC</p></li><li><p>代理模式</p></li><li><p>反射</p></li><li><p>微服务整体架构描述</p></li><li><p>JUC</p></li><li><p>spring AOP，JDK和CGlib的区别，除了针对接口和类以外的不同</p></li><li><p>实现 ReadWriteLock</p></li><li><p>泛型的类型擦除</p></li></ul><p>弱引用的应用场景</p><blockquote><p>当不使用时,告知对方是可以清除的</p></blockquote><p>大文件 小内存的 排序</p><p>面试常见算法题目</p><p>什么时候报OOM<br>长连接和短链接<br>redis数据类型和应用场景<br>外排序，败者树</p><p>浅拷贝  深拷贝</p><blockquote><p>浅拷贝只拷贝地址,深拷贝 拷贝所有的变量<br>深拷贝实现</p></blockquote><ul><li>每次拷贝所有变量</li><li>重写拷贝对象的clone方法</li><li>序列化然后反序列化<br>循环依赖</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>求职准备</title>
      <link href="/2020/09/11/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E6%B1%82%E8%81%8C%E5%87%86%E5%A4%87/"/>
      <url>/2020/09/11/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E6%B1%82%E8%81%8C%E5%87%86%E5%A4%87/</url>
      
        <content type="html"><![CDATA[<p>求职准备分类</p><h3 id="java基础"><a href="/2020/06/30/工作求职/Java/" title="Java基础">Java基础</a></h3><p>Java基础内容</p><h3 id="jvm"><a href="/2020/08/15/工作求职/JVM/" title="JVM">JVM</a></h3><p>从编程语言、数据结构、算法三个方面总结程序员的面试知识点。</p><h3 id="多线程"><a href="/2020/09/02/工作求职/多线程/" title="多线程">多线程</a></h3><p>多线程相关的知识</p><h3 id="spring"><a href="/2019/05/15/工作求职/Spring/" title="Spring">Spring</a></h3><p>讨论影响代码质量的3个要素（规范性、完整性、鲁棒性），强调高质量代码除完成基本功能外，还能考虑特殊情况，并对非法输入进行合理处理。</p><h3 id="nginx"><a href="/2020/09/04/工作求职/Nginx/" title="Nginx">Nginx</a></h3><p>总结编程面试中解决难题的有效思考模式，如在面试中遇到复杂难题，可以利用画图、举例和分解将其化繁为简，先形成清晰思路再动手编程。</p><h3 id></h3><p>介绍优化时间效率和用空间换时间的常用算法。</p><h3 id="数据库"><a href="/2020/08/28/工作求职/数据库/" title="数据库">数据库</a></h3><p>总结应聘者如何充分表现学习和沟通能力，并通过具体面试题讨论如何培养知识迁移、抽象建模和发散思维能力。</p><h3 id="操作系统"><a href="/2020/07/06/工作求职/OS/" title="操作系统">操作系统</a></h3><p>分析总结哪些面试举动是不良行为，而哪些表现又是面试官所期待的行为。</p><h3 id="计算机网络"><a href="/2020/07/06/工作求职/计算机网络/" title="计算机网络">计算机网络</a></h3><p>优选久经欧美知名企业面试考验的经典题目，帮助国内读者开阔视野、增补技能。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 求职准备 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试常见题全面分析</title>
      <link href="/2020/09/10/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%A2%98%E5%85%A8%E9%9D%A2%E5%88%86%E6%9E%90/"/>
      <url>/2020/09/10/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%A2%98%E5%85%A8%E9%9D%A2%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="java">JAVA</h2><h3 id="泛型">泛型</h3><p><a href="http://www.itxm.cn/post/4185.html" target="_blank" rel="noopener">java为什么要用类型擦除实现泛型？详解</a><br>泛型是将类型作为参数,实现代码复用可以保证</p><ul><li>定义一次类,可以被各种类使用</li><li>具体使用时,只保存自己定义类型,而不是object引用</li></ul><h4 id="c-实现">C++ 实现</h4><p>利用宏定义实现代码替换,来实现模板类,在编译期对不同类型基于模板类生成不同的代码,代码冗余</p><h4 id="java">JAVA</h4><p>java 泛型在底层利用Object引用实现泛型,编译时做类型检查，在运行时擦除<br>java 泛型在对象进和出的时候强制对象类型转换为Object和目标对象,仅仅是引用的转换</p><h3 id="重写的实现">重写的实现</h3><p><a href="https://www.cnblogs.com/kexinxin/p/10147209.html" target="_blank" rel="noopener">参考1</a><br><a href="http://zhongmingmao.me/2018/12/17/jvm-basic-invoke/" target="_blank" rel="noopener">参考2</a><br>字节码中包含4中对方法的调用</p><ul><li>invokevirtual为最常见的情况，包含virtual dispatch机制；</li><li>invokerspecial是作为对private和构造方法的调用，绕过了virtual dispatch;</li><li>invokeinterface的实现跟invokevirtual类似；</li><li>invokestatic是对静态方法的调用</li></ul><p>其中invokevirtual 实现了虚分配  完成重写方法的调用<br>虚分配机制</p><blockquote><p>该机制会首先从调用对象中寻找该方法的实现,如果没有,就到父类接口寻找,直至找到或者抛出异常,并不依赖于引用的定义类型<br>在虚分派机制下如何调用父类被覆盖的方法?<br>使用virtualspecial指令,字节码在定义时会执行父类对象及其方法</p></blockquote><p>在JVM 中使用方法表实现虚分派机制</p><blockquote><p>方法表值不记录静态函数,私有函数,final,构造函数;方法表与类class相关<br>JVM中的一种实现是</p><ul><li>表中每项对应一个实例方法(方法的实际代码)的索引</li><li>父类比子类先得到解析,即父类的方法放在方法表前列(根据方法名参数类型顺序构成的唯一标识,子类发现重复即覆盖索引)</li><li>如果子类重写父类的方法,那么父类方法的索引将更改指向为该类的相应实例方法</li><li>JVM 遇到一个方法时首先根据它在方法表中的偏移量类访问</li></ul></blockquote><p>invokeinterface与invokevirtual的比较</p><blockquote><p>当使用invokeinterface来调用方法时，由于不同的类可以实现同一interface,我们无法确定在某个类中的interface中的方法处在哪个位置。于是，也就无法解释CONSTANT_interfaceMethodref-info为直接索引，而必须每次都执行一次在methodtable中的搜索了。所以，在这种实现中，通过invokeinterface访问方法比通过invokevirtual访问明显慢很多。</p></blockquote><h3 id="解析和分派">解析和分派</h3><p>编译期符号引用会在加载时被解析成实际引用<br>虚方法表一般在类加载的连接阶段进行初始化，准备了类的变量初始值后，虚拟机会把该类的虚方法表也一同初始化完毕</p><h3 id="基本数据类型和类">基本数据类型和类</h3><p>int  Integer  atomicInteger<br>int 是基本数据类型,有默认值,但是编译器可能提醒需要初始化才能使用<br>Integer 是final class  继承Number 和compartor,包含final修饰的int变量 value,MIN,MAX; 里面包含 object 的基本方法(hashcode equals toString);Integer.valueOf()等等<br>integer ++ 相当于新生成了变量</p><p>atomicInteger 并发场景下,利用volatile修饰int,保持变量的可见性</p><h3 id="automic-分析">automic 分析</h3><h2 id="jvm">JVM</h2><ol><li>垃圾回收 和 G1<br>垃圾回收的原因 对象利用<br>判断垃圾的方法：可达分析 和 引用计数(循环引用的问题难以解决)<br>垃圾回收算法：标记清除 标记整理 复制  分代收集(标记清除+复制)<br>垃圾回收器的分类 ：针对年轻代 和针对老年代的<br>分配担保以及老年代不足引起的fullgc<br>3色标记 黑灰白<br>四种引用 强软弱虚<br>CMS VS G1<br>垃圾回收的阶段初始标记 并发标记 重新标记(对象消失 浮动垃圾 写屏障) 并发清除<br>GC root的概念卡表 以及如何加快,和如何应对出现的伪共享问题<br>oopmap<br>参考：<br><a href="https://cloud.tencent.com/developer/article/1599225" target="_blank" rel="noopener"></a></li></ol><h3 id="gc-优化">GC 优化</h3><p>首先监控GC状态：jstat -gc<br>然后根据结果GC(MIRROgc/FULLGC) 时间和频率 如果频率相对高而且时间长那么需要优化<br>优化方法:</p><ul><li>代码分析</li><li>增加内存</li><li>更改老年代年轻代比例</li></ul><h2 id="mysql">MYSQL</h2><h3 id="数据同步">数据同步</h3><p>mysql 多副本保持数据一致性,需要同步;有两种选择多写以及复制</p><ul><li>多写：主收到写命令后,需要向从数据库发送写命令 根据返回结果确认是否完成该次写操作(涉及分布式事务的提交,引出二段式提交以及三段式提交) 异步 半同步  全同步</li><li>复制 ：首先进行 全量复制(线下人工可靠;线上:利用工具 队列 流式数据写入) 之后进行增量复复制：读写分离<ul><li>首先要保证master端的bnglog 和slave端的relay日志功能开启</li><li>master端在执行完命令后悔记录在binlog中</li><li>slave端发出IO请求到master端 要求同步指定位置之后的数据</li><li>master端接收到IO请求,会返回数据以及本地同步的终点位置,可以用于下一次同步</li><li>slave端接收到数据会写进自己的relay日志中,slave端检测到relay日志发生变化就会读取更新然后写进数据库</li></ul></li></ul><h3 id="索引">索引</h3><p>mysql 索引</p><ul><li>主键索引 聚簇索引 范围查询 局部性好</li><li>唯一索引的使用需要谨慎 :因为插入和更新时需要加载所有数据到缓冲池(缓冲池的概念和用处 缓冲池的淘汰策略)去,不能有效的利用写缓冲</li><li>主键 建议使用 自增ID 这样在添加记录的时候不会造成页的分裂</li><li>为什么不适用红黑树 b+树多路查找树可以有效降低树的高度,提高查询效率,而且非叶子交接点没有数据相同的空间可以更有效的利用索引</li></ul><p>mysql 双写的原因和解决方法;索引的插入导致页的分裂和合并</p><blockquote></blockquote><h3 id="mysql-事务">mysql 事务</h3><p>mysql的四个事务隔离级别<br>利用MVCC 可以满足读已提交和可重复读(偏向update)的要求,配合间隙锁避免幻读<br>间隙所</p><h3 id="举例">举例</h3><h4 id="读写事务并发">读写事务并发</h4><p>读写事务的顺序可以有4种</p><ul><li>读后写</li><li>写后读</li><li>读中间发生写</li><li>写中间发生读</li></ul><p>对于前两种,不需要进行控制,后两种需要利用利用,MVCC 加以控制<br>innodb在行记录添加了隐藏字段 包括修改记录的事务ID字段 比如update/insert/delete 和 指向当前记录上一版本的回滚指针(利用undolog实现,可以实现未提交事务的原子性)<br>在可重复读的事务隔离级别下,读操作共享一个readview,readview是一个数据结构,包含创建其的事务ID,创建时活跃的事务ID列表,以及该列表的最小ID和创建时未分配的最小ID<br>在读时使用算法去读取行记录或者undolog中的历史链记录来实现update层次的可重复读<br>从当前行记录可以获得,该记录的修改写事务ID</p><ul><li>如果其小于readview的最小值,意味着 该写事务必然在读事务之前发生且已经结束,那么尽管读</li><li>如果事务ID 等于 readview的所属事务ID ,那么是自己改的,可以读</li><li>如果在readview范围内,那么要寻找该事物是否在readview的活跃列表里,如果在,那么意味着该写事务仍在进行,所以不能读未提交,需要沿着历史链继续寻找可以读的记录;如果不在,意味着该写事物在读操作发生之前已经结束,所以可以读已提交</li><li>如果其大于readview的最大值,意味着 该行记录是在读事务发生后更改的,那么不能读,要沿着undolog的历史版本链去找可以读的</li></ul><h4 id="写写事务并发">写写事务并发</h4><h4 id="幻读">幻读</h4><h4 id="insert-从代码层次到数据库执行的流程">insert 从代码层次到数据库执行的流程</h4><ul><li>spring 事务管理:事务传播机制</li><li>mybatic 动态sql</li><li>mysql server<ul><li>命令优化</li><li>存储引擎 innodb<ul><li>遵循二段锁提交协议,首先对表添加写意向锁,在没有对表添加读锁的情况可以实现</li><li>如果是自增主键,那么需要自增锁生成ID,随后对主键索引添加间隙锁,insert之后对于记录添加写锁</li><li>由于是对主键索引/唯一索引操作所以无法使用写缓冲,将页读入缓存,写入,然后双写刷回</li><li>如果没有其他事务,就会逐一释放锁</li></ul></li></ul></li></ul><h4 id="checkpoint"><a href="https://blog.51cto.com/10170308/1678302" target="_blank" rel="noopener">checkpoint</a></h4><h4 id="串行化">串行化</h4><ol start="3"><li>redis<br>redis 数据结构及其原理<br>redis 主从部署 哨兵模式 选举机制 读写分离<br>缓存穿透/雪崩/击穿/降级/熔断<br>缓存击穿的解决方法</li></ol><ul><li>在业务端利用reids SETNX 互斥的获得锁,去更新键值</li><li>检查高频字段是否超时,快超时时加长过期时间</li><li>使用消息队列，让流量在消息队列中囤积下，逐个消费，缓解后端压力。<br>redis 缓存和数据库双写一致性<br>redis IO多路复用<br>redis 分布式<ul><li>redis 集群</li><li>redis 分布式锁</li></ul></li></ul><p>redis 锁</p><ul><li>setnx(key,1) + expire(key,30) =set(key，1，30，NX) del(key);避免多线程操作导致删除了别人的锁,可以把threadId作为key值<br>分布式锁的单点故障问题:在redis集群模式下可以尝试获取大多数master 的锁,超过一般才算,避免死锁可以按照一定顺序去获得锁<br>zookeeper分布式锁</li></ul><p>发布订阅功能</p><ol start="4"><li>并发 编程</li></ol><ul><li>伪共享 影响并发效率</li></ul><p>http 请求到完成的过程</p><blockquote><p>DNS系统迭代查询域名对应的ip;<br>TCP 3次握手建立连接;发送报文请求<br>发送端从顶层到底层的报文封装;从底层(信道集线器)到ip层(路由器)的数据传输;接收端从底层到顶层的解封</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx</title>
      <link href="/2020/09/04/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/Nginx/"/>
      <url>/2020/09/04/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/Nginx/</url>
      
        <content type="html"><![CDATA[<p>Nginx是一个web服务器和反向代理服务器，用于HTTP、HTTPS、SMTP、POP3和IMAP协议</p><h2 id="nginx-描述">Nginx 描述</h2><p>nginx 是一个高性能的web服务器和方向代理服务器;</p><ol><li>Nginx 特性</li></ol><blockquote><p>反向代理/L7负载均衡器<br>动态二进制升级<br>嵌入式Perl解释器<br>可用于重新编写URL，具有非常好的PCRE支持</p></blockquote><ol start="2"><li>Nginx VS Apache</li></ol><blockquote><p>轻量级，同样起web 服务，比apache 占用更少的内存及资源<br>抗并发，nginx 处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能<br>高度模块化的设计，编写模块相对简单<br>最核心的区别在于apache是同步多进程模型，一个连接对应一个进程；nginx是异步的，多个连接（万级别）可以对应一个进程</p></blockquote><ol start="3"><li>nginx是如何实现高并发的</li></ol><blockquote><p>一个主进程，多个工作进程，每个工作进程可以处理多个请求，每进来一个request，会有一个worker进程去处理。<br>Worker处理到可能发生阻塞的地方，比如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理的worker继续处理其他请求，而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往下走。<br>由于web server的工作性质决定了每个request的大部份生命都是在网络传输中，实际上花费在server机器上的时间片不多<br>从而实现高并发</p></blockquote><ol start="4"><li>解释Nginx如何处理HTTP请求</li></ol><blockquote><p>Nginx使用反应器模式。主事件循环等待操作系统发出准备事件的信号，这样数据就可以从套接字读取，在该实例中读取到缓冲区并进行处理。单个线程可以提供数万个并发连接。</p></blockquote><ol start="5"><li>反应器模式</li></ol><blockquote><p>当一个主体发生改变时，所有依属体都得到通知。不过，观察者模式与单个事件源关联，而反应器模式则与多个事件源关联</p></blockquote><p>同步和异步区别：有无通知（是否轮询）<br>堵塞和非堵塞区别：操作结果是否等待（是否马上有返回值），只是设计方式的不同</p><ol start="6"><li>在Nginx中，如何使用未定义的服务器名称来阻止处理请求?</li></ol><blockquote><p>server_name设置为一个空字符串，它将在没有“主机”头字段的情况下匹配请求，而一个特殊的Nginx的非标准代码444被返回，从而终止连接</p></blockquote><ol start="7"><li>使用&quot;反向代理服务器&quot;的优点是什么</li></ol><blockquote><p>安全：反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时</p></blockquote><ol start="8"><li>请列举Nginx服务器的最佳用途</li></ol><blockquote><p>正向:做缓存,加快速度;j静态网站展示;转发请求<br>反向代理:安全;负载均衡</p></blockquote><ol start="9"><li>请解释Nginx服务器上的Master和Worker进程分别是什么</li></ol><blockquote><p>Master进程：读取及评估配置和维持<br>Worker进程：处理请求</p></blockquote><ol start="10"><li>请解释是否有可能将Nginx的错误替换为502错误、503?</li></ol><blockquote><p>502 =错误网关 503 =服务器超载 有可能，但是您可以确保fastcgi_intercept_errors被设置为ON，并使用错误页面指令。</p></blockquote><ol start="11"><li>在Nginx中，解释如何在URL中保留双斜线?</li></ol><blockquote><p>要在URL中保留双斜线，就必须使用merge_slashes_off;默认on</p></blockquote><ol start="12"><li>ngx_http_upstream_module的作用是什么</li></ol><blockquote><p>ngx_http_upstream_module用于定义可通过fastcgi传递、proxy传递、uwsgi传递、memcached传递和scgi传递指令来引用的服务器组。</p></blockquote><ol start="13"><li>请解释什么是C10K问题?</li></ol><blockquote><p>C10K问题是指无法同时处理大量客户端(10,000)的网络套接字</p></blockquote><ol start="14"><li>在Nginx中，请说明Rewrite模块里break和last的区别。</li></ol><blockquote><p>last：停止执行当前这一轮的ngx_http_rewrite_module指令集，包括后续的rewrite 和 return,然后查找匹配改变后URI的新location<br>break：停止执行当前这一轮的ngx_http_rewrite_module指令集；包括 后续的rewrite和return,继续执行剩余的命令比如echo<br>temporary 302  return 302 更新url<br>permant  301 return 301    更新url</p></blockquote><ol start="15"><li>为什么不使用多线程？</li></ol><blockquote><p>Apache: 创建多个进程或线程，而每个进程或线程都会为其分配cpu和内存（线程要比进程小的多，所以worker支持比perfork高的并发），并发过大会榨干服务器资源。<br>Nginx: 采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量）(epoll)，不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换。所以才使得Nginx支持更高的并发。一般进程数设置为cpu核数</p></blockquote><ol start="16"><li>Nginx是如何处理一个请求的呢？</li></ol><blockquote><p>首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址，然后在nginx的master进程里面<br>先初始化好这个监控的socket，再进行listen<br>然后再fork出多个子进程出来, 子进程会竞争accept新的连接。<br>此时，客户端就可以向nginx发起连接了。当客户端与nginx进行三次握手，与nginx建立好一个连接后<br>此时，某一个子进程会accept成功，然后创建nginx对连接的封装，即ngx_connection_t结构体<br>接着，根据事件调用相应的事件处理模块，如http模块与客户端进行数据的交换。<br>最后，nginx或客户端来主动关掉连接，到此，一个连接就寿终正寝了</p></blockquote><ol start="17"><li>为什么要做动静分离？</li></ol><blockquote><p>在日常开发中，前端请求静态文件比如图片资源是不需要经过后端服务器的，但是调用API这些类型的就需要后端进行处理请求，所以为了提高对资源文件的响应速度，我们应该使用动静分离的策略去做架构。我们可以将静态文件放到Nginx中，将动态资源的请求转发到后端服务器去进行进一步的处理</p></blockquote><ol start="18"><li>Session不同步如何处理？</li></ol><blockquote><p>载均衡方式使用ip_hash方式，如果用户已经访问过某个后端器，则再次访问时会将这个请求的ip地址进行哈希算法转换，自动定位到该服务器。当然也可以通过redis缓存用户session，一样可以处理session不同步的问题。</p></blockquote><ol start="19"><li>负载均衡算法</li></ol><blockquote><p>轮询,ip hash ,url hash ,fair(返回时间),weight(加权轮询,即按比例平滑排列 abcadca)</p></blockquote><ol><li>LVS（4层与7层）原理</li></ol><blockquote><p>LVS:Linux Virtual Server<br>使用LVS架设的服务器集群系统有三个部分组成：最前端的负载均衡层（Loader Balancer），中间的服务器群组层，用Server Array表示，最底层的数据共享存储层，用Shared Storage表示</p></blockquote><ol start="2"><li>Nginx 双机备份</li></ol><ul><li>主从模式</li></ul><blockquote><p>nginx进程基于Master+Slave(worker)多进程模型，自身具有非常稳定的子进程管理功能。在Master进程分配模式下，Master进程永远不进行业务处理，只是进行任务分发，从而达到Master进程的存活高可靠性，Slave(worker)进程所有的业务信号都 由主进程发出，Slave(worker)进程所有的超时任务都会被Master中止，属于非阻塞式任务模型。<br>Keepalived是Linux下面实现VRRP备份路由的高可靠性运行件。基于Keepalived设计的服务模式能够真正做到主服务器和备份服务器故障时IP瞬间无缝交接。二者结合，可以构架出比较稳定的软件LB方案<br>VRRP:Virtual Router Redundancy Protocol虚拟路由冗余协议;将N台提供相同功能的路由器组成一个路由器组(Router Group)，这个组里面有一个master和多个backup，但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip，也就是路由器所在局域网内其他机器的默认路由），占有这个IP的master实际负责ARP相应和转发IP数据包，组中的其它路由器作为备份的角色处于待命状态。master会发组播消息，当backup在超时时间内收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。</p></blockquote><ul><li>主主模式</li></ul><blockquote><p>即前端使用两台负载均衡服务器，互为主备，且都处于活动状态，同时各自绑定一个公网虚拟IP，提供负载均衡服务；当其中一台发生故障时，另一台接管发生故障服务器的公网虚拟IP（这时由非故障机器一台负担所有的请求）。这种方案，经济实惠，非常适合于当前架构环境。</p></blockquote><ol start="3"><li>虚拟主机</li></ol><blockquote><p>虚拟主机是一种特殊的软硬件技术，它可以将网络上的每一台计算机分成多个虚拟主机，每个虚拟主机可以独立对外提供 www 服务，这样就可以实现一台主机对外提供多个 web 服务，每个虚拟主机之间是独立的，互不影响的<br>虚拟主机可以对应配置文件中的server<br>虚拟主机具体可以分为基于IP,port,域名(host文件)的配置</p></blockquote><ol start="4"><li>命令</li></ol><ul><li>server :</li><li>listen</li><li>location : 匹配 url</li><li>root 虚拟主机目录</li><li>index 首页</li><li>server_name</li><li>upstream ：负载均衡</li><li>keepalive_timeout</li><li>work_process</li><li>work_connection</li><li>sendfile on</li><li>proxy 命令</li></ul><ol start="5"><li>Nginx 优化</li></ol><blockquote><p>利用 location expire 缓存静态文件<br>keepalive_imeout<br>调整worker_processes指定Nginx需要创建的worker进程数量，刚才有提到worker进程数一般设置为和CPU核心数一致。<br>调整worker_connections设置Nginx最多可以同时服务的客户端数。结合worker_processes配置可以获得每秒可以服务的最大客户端数。<br>启动gzip压缩，可以对文件大小进行压缩，减少了客户端http的传输带宽，可以大幅度提高页面的加载速度。<br>启用缓存，如果请求静态资源，启用缓存是可以大幅度提升性能的。</p></blockquote><ol start="6"><li></li><li>Linux 命令</li></ol><blockquote><p>crontab</p></blockquote><p>LVS VS NGINX<br><a href="https://www.cnblogs.com/zhoading/p/11037708.html" target="_blank" rel="noopener">浅谈 Nginx和LVS的各种优缺点</a></p><p>Nginx 实现热部署</p><blockquote><p>当通知 ngnix 重读配置文件的时候，master 进程会进行语法错误的判断。如果存在语法错误的话，返回错误，不进行装载；如果配置文件没有语法错误，那么 ngnix 也不会将新的配置调整到所有 worker 中。而是，先不改变已经建立连接的 worker，等待 worker 将所有请求结束之后，将原先在旧的配置下启动的 worker 杀死，然后使用新的配置创建新的 worker<br>修改配置文件nginx.conf后，重新生成新的worker进程，当然会以新的配置进行处理请求，而且新的请求必须都交给新的worker进程，至于老的worker进程，等把那些以前的请求处理完毕后，kill掉即可</p></blockquote><p>301 VS 302</p><blockquote><p>重定向指将网络请求重新确定方向到新的位置<br>场景</p></blockquote><ul><li>网站调整(页面调整)或者页面变化,避免旧用户返回404;临时则用302,永久则用301(在开发里发现浏览器会记住301重定向)</li></ul><blockquote><p>301 永久重定向 302 临时重定向(可以返回原来的地址)</p></blockquote><h3 id="pid-file">pid file</h3><p>每个后台程序都会在/var/run目录下产生一个<name>.pid file 里面存储了程序pid的file<br>nginx.pid 中存储了master进程的file</name></p><h3 id="文件锁">文件锁</h3><p>nginx进程之间的通信机制包括 信号 信号量 文件锁<br>信号：SIGHUP<br>信号量：用来保证两个或多个代码段不被并发访问，是一种保证共享资源有序访问的工具<br>文件锁：<br>互斥锁</p><h2 id="源码解析">源码解析</h2><h3 id="配置文件解析">配置文件解析</h3><p>配置块(’}‘结尾)和配置项(’;'结尾)</p><p>分词之后,使用key-value对的方式解析存储配置项,而非语法分析的方式构建语法树<br>http配置文件为有3个组成部分;不同级别对应的配置项范围向下延伸</p><ul><li>void **main_conf:可包含多个server字段</li><li>void **server_conf:包含多个loc字段</li><li>void **loc_conf:loc字段可嵌套,最终合并为一层</li></ul><p>在解析到http模块时,会调用create_main_conf create_srv_conf  create_loc_conf 方法创建3组结构体,已在各模块存储其感兴趣的main级别配置项;同样解析server模块会调用create_srv_conf  create_loc_conf 相应结构体,存储server级别配置项</p><h4 id="其他">其他</h4><p>include 指令</p><blockquote><p>可以降低多个server字段的耦合程度,涉及递归调用parse函数</p></blockquote><p>location 嵌套</p><blockquote><p>server模块下可能有多个location块,而location块下可以嵌套存储location<br>loc结构体下有队列成员变量存储其他嵌套队列</p></blockquote><p>上下文继承</p><h3 id="event模块">event模块</h3><h3 id="mail-模块">mail 模块</h3><h3 id="http-模块">http 模块</h3><h4 id="数据存储结构">数据存储结构</h4><p>在nginx运行过程中，有一个全局配置结构体ngx_cycle_t，其有一个属性conf_ctx，这个属性是存储nginx所有模块配置的一个数组，这个数组的长度与nginx模块的个数相同。不过需要注意的是，conf_ctx数组的第一维只会存储核心模块的配置，而其他模块对应的位置处的数组元素其实是为NULL。在conf_ctx中，各个核心模块配置结构体的存储位置与该模块在所有模块（包括非核心模块）中的相对位置是一致的，如下图所示为nginx存储核心模块的一个结构示意图<br>全局配置结构体ngx_cycle_t 下有 conf_ctx记录配置文件的信息<br>ngx_cycle_t-&gt;conf_ctx</p><ul><li>void **main_conf;   // http</li><li>void **srv_conf;   // server</li><li>void **loc_conf;   //location</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MyBatis</title>
      <link href="/2020/09/04/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/MyBatis/"/>
      <url>/2020/09/04/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/MyBatis/</url>
      
        <content type="html"><![CDATA[<p>MyBatis 是 一个常用的 Java 持久层框架</p><h2 id="什么是-mybatis">什么是 MyBatis</h2><p><a href="https://mybatis.org/mybatis-3/zh/index.html" target="_blank" rel="noopener">MyBatis 官网</a><br>MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。</p><p>相对于 Spring Data JPA 差不多可以不用写 SQL 的框架而言，MyBatis 在于开发者可以灵活的编写 SQL<br>MyBatis 可以通过使用注解来减少相关的配置文件</p><h4 id="注解方式的-mapper-接口">注解方式的 Mapper 接口</h4><p>@Insert，@Select，@Update, @Delete 分别注解 SQL 的 insert，select，update，delete 语句。<br>@Options<br>@Results：实现结果的映射<br>PageHelper.startPage(page, size); 调用此方法后，随后的查询讲自动使用分页模式。<br>PageInfo.of(sysUserMapper.selectAllOnXml())； 讲查询返回某一页的信息使用 PageInfo 打包</p><ol><li>什么是Mybatis？</li></ol><blockquote><p>Mybatis是一个半ORM（对象关系映射）框架，它内部封装了JDBC，开发时只需要关注SQL语句本身，不需要花费精力去处理加载驱动、创建连接、创建statement等繁杂的过程。程序员直接编写原生态sql，可以严格控制sql执行性能，灵活度高。<br>MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。<br>通过xml 文件或注解的方式将要执行的各种 statement 配置起来，并通过java对象和 statement中sql的动态参数进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射为java对象并返回。（从执行sql到返回result的过程）。</p></blockquote><ul><li>是什么?基于JDBC,实现对于数据库的增删改查操作架构</li><li>自动管理数据库连接的创建和释放,操作者只需要写sql</li><li>利用配置文件或者mapper 定义 对象 映射 数据库的记录和返回结果;</li><li>解耦sql与应用程序,统一管理和复用;通过动态sql降低 拼接sql的难度</li></ul><ol start="2"><li>Mybaits的优点：</li></ol><blockquote><p>基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在XML里，解除sql与程序代码的耦合，便于统一管理；提供XML标签，支持编写动态SQL语句，并可重用。<br>与JDBC相比，减少了50%以上的代码量，消除了JDBC大量冗余的代码，不需要手动开关连接；<br>很好的与各种数据库兼容（因为MyBatis使用JDBC来连接数据库，所以只要JDBC支持的数据库MyBatis都支持）。<br>能够与Spring很好的集成</p></blockquote><ol start="3"><li>MyBatis框架的缺点</li></ol><blockquote><p>SQL语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写SQL语句的功底有一定要求。- 利用自动化生成工具<br>SQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。</p></blockquote><ol start="4"><li>MyBatis框架适用场合</li></ol><blockquote><p>MyBatis专注于SQL本身，是一个足够灵活的DAO层解决方案<br>对性能的要求很高，或者需求变化较多的项目，如互联网项目，MyBatis将是不错的选择。</p></blockquote><ol start="5"><li>#{}和${}的区别是什么？</li></ol><blockquote><p>#{}是预编译处理，${}是字符串替换。<br>Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值(在处理是会对输入做转义处理)<br>Mybatis在处理${}时，就是把${}替换成变量的值。<br>使用#{}可以有效的防止SQL注入，提高系统安全性。</p></blockquote><ol start="6"><li>Mybatis是如何进行分页的？分页插件的原理是什么？</li></ol><blockquote><p>Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页。可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。<br>分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。</p></blockquote><ol start="7"><li>Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式？</li></ol><blockquote><p>resultMap</p></blockquote><ol start="8"><li>如何获取自动生成的(主)键值?</li></ol><blockquote><p>insert 方法总是返回一个int值 ，这个值代表的是插入的行数。</p></blockquote><ol start="9"><li>Mybatis动态sql有什么用？执行原理？有哪些动态sql？</li></ol><blockquote><p>Mybatis动态sql可以在Xml映射文件内，以标签的形式编写动态sql，执行原理是根据表达式的值 完成逻辑判断并动态拼接sql的功能。<br>Mybatis提供了9种动态sql标签：trim | where | set | foreach | if | choose | when | otherwise | bind。</p></blockquote><ol start="10"><li>复杂查询</li></ol><blockquote><p>基于examople 配合条件查询</p></blockquote><ol start="11"><li>Dao接口的工作原理是什么?</li></ol><blockquote><p>Mapper 接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，转而执行MapperStatement所代表的sql，然后将sql执行结果返回</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Spring Boot 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>源码解析</title>
      <link href="/2020/09/03/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
      <url>/2020/09/03/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h4 id="override-的-jvm-实现">Override 的 JVM 实现</h4><blockquote><p>背景：在代码中子类Son继承父类Father,并使用Override注解 对于父类方法Test的重写<br><img src="/images/Override-test-java.png" alt="test1.java test2.java"><br>JVM 加载子类Son.class,递归的向上加载父类的class 文件即Father.class :class文件保存为表示类型信息的结构体中,只包含本类特有的，或者是重写的方法信息，没有父类的方法信息。<br><img src="/images/Override-testclass.png" alt="class文件在方法区的结构"><br>JVM会根据class 文件信息生成 方法表(是实现多态的关键),方法表中保存该类的所有的包括继承的方法(不包含私有方法),以及指向实例方法的指针<br><img src="/images/Override-method-table.png" alt="方法表"><br>其中子类Son的Test方法指针指向Son.class在中的实例方法(这里需要注意的一点是，当Child类的方法表产生指向Parent类中的方法的引用时，会有一个指向eat方法的引用，最后产生指向本类的方法的引用时，也有一个指向eat的引用，这时候，新的数据会覆盖原有的数据，也就是说原来指向Parent.eat的那个引用会被替换成指向Child.eat的引用(占据原来表中的位置)<br>堆中存储类的方法表索引以及字段变量<br>当执行test方法时,虽然类型是Father,实际执行的是Son的方法表中指向的Son重写的方法</p></blockquote><p>参考：</p><ul><li><a href="https://blog.csdn.net/wonderful_life_mrchi/article/details/78048698" target="_blank" rel="noopener">jvm视角看java继承和多态</a></li><li><a href="https://blog.csdn.net/u011069294/article/details/107415210" target="_blank" rel="noopener">JVM方法区的内部结构</a></li><li><a href="https://www.iteye.com/blog/hxraid-676235" target="_blank" rel="noopener">Java 虚拟机体系结构</a></li><li><a href="https://zhuanlan.zhihu.com/p/24317613" target="_blank" rel="noopener">Java动态绑定机制的内幕</a></li><li><a href="https://blog.csdn.net/fan2012huan/article/details/51007517" target="_blank" rel="noopener">java方法调用之动态调用多态（重写override）的实现原理——方法表（三）</a></li></ul><h4 id="synchronize-vs-lock">synchronize VS lock</h4><p><a href="https://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html" target="_blank" rel="noopener">Chapter 17. Threads and Locks</a><br><a href="https://www.cnblogs.com/tiancai/p/9371655.html" target="_blank" rel="noopener">java的锁池和等待池</a><br><a href="https://segmentfault.com/a/1190000017134827" target="_blank" rel="noopener">synchronize - 线程同步机制</a><br>synchronize支持同步的机制是monitor(monitorEnter monitorExit),支持两种同步机制 互斥和协作<br>每个对象维持两个队列 waitSet 和 EntrySet<br>waitSet :</p><ul><li>操作方法:wait(释放锁,进入队列) 和 notify LockSupport.pack/unpack</li><li>需要注意的是notify方法,notify锁唤醒的线程会竞争锁,当该线程竞争成功之后才会将值从wait队列中除去(避免不必要的队列操作,如果要移动到entrySet,那么notifyAll会涉及大量的操作,浪费时间)<br>EntrySet：所有想获取锁但未获得的线程</li><li>当线程synchronize获取锁失败后进入entrySet 而 当获得锁的进程放弃锁之后,从该队列中唤醒一个线程</li></ul><h4 id="cyclicbarrier-vs-countdownlatch-vs-semaphore">CyclicBarrier  VS CountDownLatch VS Semaphore</h4><p>CountDownLatch利用state记录次数,用于同步多个runnable任务执行完之后执行主线程其余操作</p><ul><li>await: 重写tryAcquireShared 方法:如果state为0则获取成功可以运行,否则调用doAcquireSharedInterruptibly阻塞该线程;(可用于主线程阻塞自己,等待其他线程完成操作)</li><li>countDown: 重写 releaseShared(1) 降低state值,将为0时执行doReleaseShared唤醒所有休眠线程,否则仅降低state值</li></ul><p>Semaphore 限制state数量的线程可以进入Semaphore.acquire() 和 realease() 修饰的代码</p><ul><li>auquire():重写tryAcquireShared 方法,当state数量小于等于0时,调用doAcquireShared阻塞线程,否则成功返回</li><li>release():重写tryReleaseShared 方法,for循环 中CAS操作增加state 成功则跳出循环</li></ul><p>CyclicBarrier:可循环栅栏(可以用于多次同步动作,比如聚餐的两个同步点,所有到达餐厅开始吃饭,所有人吃完开始离开)<br>CyclicBarrier内部维持了ReenterLock对象 在基于此生成condition对象,此外包含内部类Generation,每次循环使用新的generation,Runnable变量barrierCommand即线程的队形,count同步计数变量</p><ul><li>await:利用lock.lock/unlock 维持降低count值,当降低到0 调用nextGenation/BrokenBarrier 方法唤醒休眠线程,重初始化,继续执行,否则阻塞之</li><li>reset:重置barrier为初始状态,那些仍等待barrier的线程会返回一个BrokenBarrierException</li></ul><h4 id="synchronize-和-aqs">synchronize 和 AQS</h4><ul><li>后者需要显示的获得和释放锁</li><li>前者有系统支持,后者是软件层级的锁,前者的锁进入的队列是entry队列,后者是wait队列</li><li>前者是悲观锁,后者基于CAS乐观锁</li><li>前者的锁等待,不能感知中断/不支持显示处理, 后者 可以通过设置允许中断的标志位 来允许其他线程中断自己 并加以处理</li></ul><p>AQS的实现类 sync 可以调用lockInterruptly() 会在获得锁失败后,调用LockSupport.park(),从阻塞中被唤醒(被调用LockSupport.unpark())之后,会判断是否是被中断而唤醒的,如果是那么抛出interruptExcetion ,线程可以针对的处理 避免死锁,<br>当其他线程调用Thread.intrerrupt() 时,会设置终终中断的标志位,线程<br>object.wait() 方法会检测到 检测中断</p><p>stop()方法停止线程非常的暴力，人家线程运行的好好的，突然就把人家杀死了，线程占用的锁被强制释放，极易导致数据的不一致.</p><h4 id="abstractqueuedsynchronizer">AbstractQueuedSynchronizer</h4><p>private transient volatile Node head;<br>private transient volatile Node tail;<br>//在独占式里,标识占据lock的线程,从0到1 的变化通过CAS操作完成,大于1时标识多次重入,直接setState完成<br>private volatile int state;</p><p>lock.lock() 获得锁的运行(更新state为1),没有获得锁的进入双向队列<br>condition.await() 获得锁的线程可以运行该函数,新建Node添加进condition等待单向队列;更新state,并唤醒lock的队列首的后续节点,并调用LockSupport.pack()阻塞自己<br>condition.signal()  获取锁的线程,唤醒一个从condition阻塞队列的节点,将之移动到sync同步等待队列,</p><p>lock.unlock() 放弃锁,更新state 唤醒等待队列首,阻塞自己</p><h5 id="class-node">class Node</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Node nextWaiter;</span><br><span class="line">volatile Thread thread;</span><br><span class="line">volatile Node next;</span><br><span class="line">volatile Node prev;</span><br><span class="line">volatile int waitStatus;</span><br><span class="line">static final Node SHARED = new Node();</span><br><span class="line">/** Marker to indicate a node is waiting in exclusive mode */</span><br><span class="line">static final Node EXCLUSIVE = null;</span><br><span class="line"></span><br><span class="line">/** waitStatus value to indicate thread has cancelled */</span><br><span class="line">static final int CANCELLED =  1;</span><br><span class="line">/** waitStatus value to indicate successor&apos;s thread needs unparking */</span><br><span class="line">static final int SIGNAL    = -1;</span><br><span class="line">/** waitStatus value to indicate thread is waiting on condition */</span><br><span class="line">static final int CONDITION = -2;</span><br><span class="line">/**</span><br><span class="line">* waitStatus value to indicate the next acquireShared should</span><br><span class="line">* unconditionally propagate</span><br><span class="line">*/</span><br><span class="line">static final int PROPAGATE = -3;</span><br></pre></td></tr></table></figure><h6 id="节点状态">节点状态</h6><ul><li>CANCELLED:值为1，由于超时或中断，该节点被取消。 节点进入该状态将不再变化。特别是具有取消节点的线程永远不会再次阻塞</li><li>INITIAL:值为0，初始状态,非四种状态</li><li>SIGNAL:值为-1，后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，那么就会通知后继节点，让后继节点的线程能够运行</li><li>CONDITION:值为-2，Condition的等待队列,不过当其他的线程对Condition调用了signal()方法后，该节点就会从等待队列转移到同步队列(sync)中，然后开始尝试对同步状态的获取</li><li>PROPAGATE:值为-3，只对head节点设置,表示下一次的releaseShared状态获取将会无条件的被传播下去</li></ul><h5 id="conditionsignal">condition.signal</h5><p>首先判断是否是持有锁者在调用释放<br>获取锁的线程,唤醒一个从condition阻塞队列的节点,将之移动到sync同步等待队列</p><h5 id="doacquireshared-获取锁">doAcquireShared 获取锁</h5><p><a href="https://juejin.im/post/6844903997438951437" target="_blank" rel="noopener">参考0</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">* Acquires in shared uninterruptible mode.</span><br><span class="line">* @param arg the acquire argument</span><br><span class="line">*/</span><br><span class="line">private void doAcquireShared(int arg) &#123;</span><br><span class="line">    //将该线程添加到阻塞队列的队尾,涉及CAS设置tail,并返回tail</span><br><span class="line">    final Node node = addWaiter(Node.SHARED);</span><br><span class="line">    boolean failed = true;</span><br><span class="line">    try &#123;</span><br><span class="line">        boolean interrupted = false;</span><br><span class="line">        for (;;) &#123;</span><br><span class="line">            final Node p = node.predecessor();</span><br><span class="line">            //head 标识 当前阻塞队列中获取锁的线程,那么之后其后继者才有可能获得锁</span><br><span class="line">            if (p == head) &#123;</span><br><span class="line">                int r = tryAcquireShared(arg);</span><br><span class="line">                if (r &gt;= 0) &#123;</span><br><span class="line">                    //设置当前node为head而且沿着阻塞队列向后传播</span><br><span class="line">                    setHeadAndPropagate(node, r);</span><br><span class="line">                    p.next = null; // help GC</span><br><span class="line">                    if (interrupted)</span><br><span class="line">                        selfInterrupt();//??中断后执行finally然后在阻塞队列中删除该节点??</span><br><span class="line">                    failed = false;</span><br><span class="line">                    return;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            //判断线程是否应该阻塞,以及调用LockSupport.park(this) 将线程阻塞并返回是否成功</span><br><span class="line">            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;</span><br><span class="line">                parkAndCheckInterrupt())</span><br><span class="line">                interrupted = true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        if (failed)//取消对于读锁的获取,在阻塞队列里删除该节点</span><br><span class="line">            cancelAcquire(node);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="addwaiter">addWaiter</h5><h4 id="reentrantlockreadwritelock">ReentrantLockReadWriteLock</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">//state&gt;&gt;16 获得读锁的线程数;state&amp;(1&lt;&lt;16) 写锁的重入次数</span><br><span class="line">final volatile int state;</span><br><span class="line"></span><br><span class="line">private static final long serialVersionUID = -6992448646407690164L;</span><br><span class="line">//读锁</span><br><span class="line">private final ReentrantReadWriteLock.ReadLock readerLock;</span><br><span class="line">//写锁</span><br><span class="line">private final ReentrantReadWriteLock.WriteLock writerLock;</span><br><span class="line">//同步机制的操作对象</span><br><span class="line">final Sync sync;</span><br><span class="line">//transient 标识序列化时不序列化该元素;firstReader标识获取读锁的第一个线程(最近把读锁计数从0变为1的线程),而firstReaderHoldCount标识该线程持有的锁的数量</span><br><span class="line">private transient Thread firstReader = null;</span><br><span class="line">private transient int firstReaderHoldCount;</span><br><span class="line"></span><br><span class="line">//标识当前线程所持有的读锁的数目(THreadLocal变量)</span><br><span class="line">private transient ThreadLocalHoldCounter readHolds;</span><br><span class="line">//标识最后获得读锁的线程持有的读锁数</span><br><span class="line">private transient HoldCounter cachedHoldCounter;</span><br></pre></td></tr></table></figure><p>获取锁的过程</p><ul><li>lock()</li><li>acquireShared(1) ;tryAcquireShared(1)失败后,说明有写锁, -&gt; fullTryAcquireShared(在没有写锁的前提下,死锁循环获取读锁)</li><li>fullTryAcquireShared 失败后(失败意味着在获取读锁的期间有线程获得读锁或者读锁数量超过限制,否则继续死循环) doAcquireShared(1)</li></ul><p>释放锁的过程</p><ul><li>unlock()</li><li>sync.releaseShared(1)</li><li>tryReleaseShared 成功后 doReleaseShared</li></ul><h5 id="tryacquireshared">tryAcquireShared</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">//获取共享锁</span><br><span class="line">protected final int tryAcquireShared(int unused) &#123;</span><br><span class="line">    /*</span><br><span class="line">        * Walkthrough:</span><br><span class="line">        * 1. If write lock held by another thread, fail.</span><br><span class="line">        * 2. Otherwise, this thread is eligible for</span><br><span class="line">        *    lock wrt state, so ask if it should block</span><br><span class="line">        *    because of queue policy. If not, try</span><br><span class="line">        *    to grant by CASing state and updating count.</span><br><span class="line">        *    Note that step does not check for reentrant</span><br><span class="line">        *    acquires, which is postponed to full version</span><br><span class="line">        *    to avoid having to check hold count in</span><br><span class="line">        *    the more typical non-reentrant case.</span><br><span class="line">        * 3. If step 2 fails either because thread</span><br><span class="line">        *    apparently not eligible or CAS fails or count</span><br><span class="line">        *    saturated, chain to version with full retry loop.</span><br><span class="line">        */</span><br><span class="line">    Thread current = Thread.currentThread();</span><br><span class="line">    int c = getState();</span><br><span class="line">    //如果已经有进程占有写锁,且不是当前进程,那么不可获得读锁(获得写锁的进程也能获得读锁)</span><br><span class="line">    if (exclusiveCount(c) != 0 &amp;&amp;</span><br><span class="line">        getExclusiveOwnerThread() != current)</span><br><span class="line">        return -1;</span><br><span class="line">    //获得读锁的线程数</span><br><span class="line">    int r = sharedCount(c);</span><br><span class="line">    //如果不应该阻塞(阻塞队列为空或者队首是自己) 且 当前获得锁的线程数量小于最大值  且 CAS 操作成功 ,那么执行</span><br><span class="line">    if (!readerShouldBlock() &amp;&amp;</span><br><span class="line">        r &lt; MAX_COUNT &amp;&amp;</span><br><span class="line">        compareAndSetState(c, c + SHARED_UNIT)) &#123;</span><br><span class="line">        //如果这是第一获得读锁的进程 赋值firstReader 和 firstReaderHoldCount</span><br><span class="line">        if (r == 0) &#123;</span><br><span class="line">            firstReader = current;</span><br><span class="line">            firstReaderHoldCount = 1;</span><br><span class="line">        &#125; else if (firstReader == current) &#123;//或者第一个获得读锁的人是自己,那么增加计数即可</span><br><span class="line">            firstReaderHoldCount++;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            //如果最后一个线程计数器是null或不是自己那么新建 HoldCounter,否则 不是null并且是自己此时如果count为0,则</span><br><span class="line">            HoldCounter rh = cachedHoldCounter;</span><br><span class="line">            if (rh == null || rh.tid != getThreadId(current))</span><br><span class="line">                cachedHoldCounter = rh = readHolds.get();</span><br><span class="line">            else if (rh.count == 0)</span><br><span class="line">                readHolds.set(rh);</span><br><span class="line">            rh.count++;</span><br><span class="line">        &#125;</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line">    return fullTryAcquireShared(current);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="fulltryacquireshared"><a href="https://ifeve.com/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B-%E8%AF%BB%E9%94%81%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E8%A7%A3%E9%87%8A%E5%85%B3%E4%BA%8E%E9%94%81%E9%99%8D%E7%BA%A7%E7%9A%84%E4%BA%89/" target="_blank" rel="noopener">fullTryAcquireShared</a></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">//死循环获取读锁。包含锁降级策略</span><br><span class="line">final int fullTryAcquireShared(Thread current) &#123;</span><br><span class="line">    /*</span><br><span class="line">        * This code is in part redundant with that in</span><br><span class="line">        * tryAcquireShared but is simpler overall by not</span><br><span class="line">        * complicating tryAcquireShared with interactions between</span><br><span class="line">        * retries and lazily reading hold counts.</span><br><span class="line">        */</span><br><span class="line">    HoldCounter rh = null;</span><br><span class="line">    for (;;) &#123;</span><br><span class="line">        int c = getState();</span><br><span class="line">        //获取读锁之前,确保没有写锁,首先这是读写锁的目标 同时避免获取写锁的线程  之后获取读锁 从而陷入死锁</span><br><span class="line">        if (exclusiveCount(c) != 0) &#123;</span><br><span class="line">            if (getExclusiveOwnerThread() != current)</span><br><span class="line">                return -1;</span><br><span class="line">            // else we hold the exclusive lock; blocking here</span><br><span class="line">            // would cause deadlock.</span><br><span class="line">            //readerShouldBlock 判断 阻塞队列是否有线程,或者阻塞队列首是否是自己,如果是则返回false,不应该阻塞,不要重复获取读锁,写锁的持有线程可以获得读锁</span><br><span class="line">        &#125; else if (readerShouldBlock()) &#123;</span><br><span class="line">            // Make sure we&apos;re not acquiring read lock reentrantly</span><br><span class="line">            if (firstReader == current) &#123;</span><br><span class="line">                // assert firstReaderHoldCount &gt; 0;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                if (rh == null) &#123;</span><br><span class="line">                    rh = cachedHoldCounter;</span><br><span class="line">                    if (rh == null || rh.tid != getThreadId(current)) &#123;</span><br><span class="line">                        rh = readHolds.get();</span><br><span class="line">                        if (rh.count == 0)</span><br><span class="line">                            readHolds.remove();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                if (rh.count == 0)</span><br><span class="line">                    return -1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        //如果读锁的数量达到限制,报错</span><br><span class="line">        if (sharedCount(c) == MAX_COUNT)</span><br><span class="line">            throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">        if (compareAndSetState(c, c + SHARED_UNIT)) &#123;//尝试获得锁</span><br><span class="line">            //获得成功,如果是第一个获得读锁的线程,更新相关值</span><br><span class="line">            if (sharedCount(c) == 0) &#123;</span><br><span class="line">                firstReader = current;</span><br><span class="line">                firstReaderHoldCount = 1;</span><br><span class="line">            &#125; else if (firstReader == current) &#123;//如果是第一个读者,更新相关值</span><br><span class="line">                firstReaderHoldCount++;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                if (rh == null)</span><br><span class="line">                    rh = cachedHoldCounter;</span><br><span class="line">                //如果rh为空或者rh不为当前线程,那么新建 HoldCounter</span><br><span class="line">                if (rh == null || rh.tid != getThreadId(current))</span><br><span class="line">                    rh = readHolds.get();</span><br><span class="line">                else if (rh.count == 0) //否则即rh为当前线程,且count为0,则更新</span><br><span class="line">                    readHolds.set(rh);</span><br><span class="line">                rh.count++;</span><br><span class="line">                cachedHoldCounter = rh; // cache for release</span><br><span class="line">            &#125;</span><br><span class="line">            return 1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">    * Performs tryLock for write, enabling barging in both modes.</span><br><span class="line">    * This is identical in effect to tryAcquire except for lack</span><br><span class="line">    * of calls to writerShouldBlock.</span><br><span class="line">    */</span><br></pre></td></tr></table></figure><h5 id="shouldparkafterfailedacquire">shouldParkAfterFailedAcquire</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">//如果线程获取读锁失败,那么是否阻塞之,并且修改其在队列中的状态</span><br><span class="line">private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;</span><br><span class="line">    int ws = pred.waitStatus;</span><br><span class="line">    //如果前继节点的状态是SIGNAL那么可以阻塞该线程</span><br><span class="line">    if (ws == Node.SIGNAL)</span><br><span class="line">        /*</span><br><span class="line">            * This node has already set status asking a release</span><br><span class="line">            * to signal it, so it can safely park.</span><br><span class="line">            */</span><br><span class="line">        return true;</span><br><span class="line">    if (ws &gt; 0) &#123;</span><br><span class="line">        //前继节点处于CANCEL的状态,所以锁的最新情况不能通过前继节点传递给他,所以需要删除这样的节点.</span><br><span class="line">        /*</span><br><span class="line">            * Predecessor was cancelled. Skip over predecessors and</span><br><span class="line">            * indicate retry.</span><br><span class="line">            */</span><br><span class="line">        do &#123;</span><br><span class="line">            node.prev = pred = pred.prev;</span><br><span class="line">        &#125; while (pred.waitStatus &gt; 0);</span><br><span class="line">        pred.next = node;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        //前继节点处于CONDITION 或者 PROPAGATE 状态,那么 修改状态为 SINGAL</span><br><span class="line">        /*</span><br><span class="line">            * waitStatus must be 0 or PROPAGATE.  Indicate that we</span><br><span class="line">            * need a signal, but don&apos;t park yet.  Caller will need to</span><br><span class="line">            * retry to make sure it cannot acquire before parking.</span><br><span class="line">            */</span><br><span class="line">        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="shouldparkafterfailedacquire">shouldParkAfterFailedAcquire</h5><p>判断已获取读锁失败的线程是否应该阻塞</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;</span><br><span class="line">    int ws = pred.waitStatus;</span><br><span class="line">    if (ws == Node.SIGNAL)</span><br><span class="line">        /*</span><br><span class="line">            * This node has already set status asking a release</span><br><span class="line">            * to signal it, so it can safely park.</span><br><span class="line">            */</span><br><span class="line">        return true;</span><br><span class="line">    if (ws &gt; 0) &#123;</span><br><span class="line">        /*</span><br><span class="line">            * Predecessor was cancelled. Skip over predecessors and</span><br><span class="line">            * indicate retry.</span><br><span class="line">            */</span><br><span class="line">        do &#123;</span><br><span class="line">            node.prev = pred = pred.prev;</span><br><span class="line">        &#125; while (pred.waitStatus &gt; 0);</span><br><span class="line">        pred.next = node;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        /*</span><br><span class="line">            * waitStatus must be 0 or PROPAGATE.  Indicate that we</span><br><span class="line">            * need a signal, but don&apos;t park yet.  Caller will need to</span><br><span class="line">            * retry to make sure it cannot acquire before parking.</span><br><span class="line">            */</span><br><span class="line">        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="tryreleaseshared">tryReleaseShared</h5><p>释放该线程的读锁,count-1</p><ol><li>是否是firstReader<ul><li>是否 count = 1</li></ul></li><li>是否是最后一个Reader</li><li>死循环CAS更新所有读锁的count,成功后退出</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">protected final boolean tryReleaseShared(int unused) &#123;</span><br><span class="line">    Thread current = Thread.currentThread();</span><br><span class="line">    if (firstReader == current) &#123;</span><br><span class="line">        // assert firstReaderHoldCount &gt; 0;</span><br><span class="line">        if (firstReaderHoldCount == 1)</span><br><span class="line">            firstReader = null;</span><br><span class="line">        else</span><br><span class="line">            firstReaderHoldCount--;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        HoldCounter rh = cachedHoldCounter;</span><br><span class="line">        if (rh == null || rh.tid != getThreadId(current))</span><br><span class="line">            rh = readHolds.get();</span><br><span class="line">        int count = rh.count;</span><br><span class="line">        if (count &lt;= 1) &#123;</span><br><span class="line">            readHolds.remove();</span><br><span class="line">            if (count &lt;= 0)</span><br><span class="line">                throw unmatchedUnlockException();</span><br><span class="line">        &#125;</span><br><span class="line">        --rh.count;</span><br><span class="line">    &#125;</span><br><span class="line">    for (;;) &#123;</span><br><span class="line">        int c = getState();</span><br><span class="line">        int nextc = c - SHARED_UNIT;</span><br><span class="line">        if (compareAndSetState(c, nextc))</span><br><span class="line">            // Releasing the read lock has no effect on readers,</span><br><span class="line">            // but it may allow waiting writers to proceed if</span><br><span class="line">            // both read and write locks are now free.</span><br><span class="line">            return nextc == 0;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="doreleaseshared">doReleaseShared</h5><p>该节点释放锁之后,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">private void doReleaseShared() &#123;</span><br><span class="line">    /*</span><br><span class="line">        * Ensure that a release propagates, even if there are other</span><br><span class="line">        * in-progress acquires/releases.  This proceeds in the usual</span><br><span class="line">        * way of trying to unparkSuccessor of head if it needs</span><br><span class="line">        * signal. But if it does not, status is set to PROPAGATE to</span><br><span class="line">        * ensure that upon release, propagation continues.</span><br><span class="line">        * Additionally, we must loop in case a new node is added</span><br><span class="line">        * while we are doing this. Also, unlike other uses of</span><br><span class="line">        * unparkSuccessor, we need to know if CAS to reset status</span><br><span class="line">        * fails, if so rechecking.</span><br><span class="line">        */</span><br><span class="line">    for (;;) &#123;</span><br><span class="line">        Node h = head;</span><br><span class="line">        if (h != null &amp;&amp; h != tail) &#123;</span><br><span class="line">            int ws = h.waitStatus;</span><br><span class="line">            if (ws == Node.SIGNAL) &#123;</span><br><span class="line">                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))</span><br><span class="line">                    continue;            // loop to recheck cases</span><br><span class="line">                //如果更新成功,解锁后继节点</span><br><span class="line">                unparkSuccessor(h);</span><br><span class="line">            &#125;</span><br><span class="line">            else if (ws == 0 &amp;&amp;</span><br><span class="line">                        !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))</span><br><span class="line">                continue;                // loop on failed CAS</span><br><span class="line">        &#125;</span><br><span class="line">        if (h == head)                   // loop if head changed</span><br><span class="line">            break;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="threadlocal">ThreadLocal</h4><p>通过继承ThreadLocal 重写 initialValue,获得默认值<br>Thread 类中包含ThreadLocalMap  和 InheritThreadLocalMap<br>ThreadLocalMap 是一个 Entry数组,一个 Entry 定义时包含对于ThreadLocal的弱引用,利用Object(value)存储保存的值</p><h5 id="get">get</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//多线程共享进程的变量threadLocal,以该变量为key值去获取线程私有变量中的相关值,不涉及对于全局变量的修改,不会线程不安全,利用这种方法可以实现多变量的线程间共享,而且不必要放入参数中传进去</span><br><span class="line">public T get() &#123;</span><br><span class="line">        Thread t = Thread.currentThread();</span><br><span class="line">        ThreadLocalMap map = getMap(t);</span><br><span class="line">        if (map != null) &#123;</span><br><span class="line">            ThreadLocalMap.Entry e = map.getEntry(this);</span><br><span class="line">            if (e != null) &#123;</span><br><span class="line">                @SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">                T result = (T)e.value;</span><br><span class="line">                return result;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return setInitialValue();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="sleep">sleep</h4><p><a href="https://www.jianshu.com/p/0964124ae822" target="_blank" rel="noopener">Java线程源码解析之yield和sleep</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>资源收集</title>
      <link href="/2020/09/02/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E8%B5%84%E6%BA%90%E6%94%B6%E9%9B%86/"/>
      <url>/2020/09/02/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E8%B5%84%E6%BA%90%E6%94%B6%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/Snailclimb/" target="_blank" rel="noopener">https://github.com/Snailclimb/JavaGuide</a></p><p>JavaGuide<br>多线程文章推荐</p><ul><li><a href="https://github.com/RedSpider1/concurrent" target="_blank" rel="noopener">深入浅出Java多线程</a> , <a href="https://redspider.gitbook.io/concurrent" target="_blank" rel="noopener">网页浏览</a></li></ul><p>Spring Boot</p><ul><li><a href="https://juejin.im/post/6844904024286691335#heading-80" target="_blank" rel="noopener">SpringBoot 就这一篇全搞定</a></li><li><a href="https://github.com/dyc87112/SpringBoot-Learning/tree/master/2.1.x" target="_blank" rel="noopener">Spring Boot基础教程（2.x版本）</a></li><li><a href="https://github.com/zhshuixian/learn-spring-boot-2" target="_blank" rel="noopener">Spring Boot 2.X 实战</a> <a href="https://github.com/zhshuixian/learn-spring-boot-2" target="_blank" rel="noopener">在线阅读</a></li></ul><p>Nginx</p><ul><li><a href="https://juejin.im/post/6844904021552005127" target="_blank" rel="noopener">Nginx通关攻略</a></li></ul><p>Mysql</p><ul><li><a href="https://juejin.im/post/6850037271233331208" target="_blank" rel="noopener">Mysql</a></li></ul><p>文件资料</p><ul><li><a href="D:%5CDownload%5CBaiduNetdisk%5Cbat%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB" target="_blank" rel="noopener">Local</a></li></ul><p><a href="https://github.com/yttsam/interview_internal_reference" target="_blank" rel="noopener">面试问题收集</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程</title>
      <link href="/2020/09/02/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
      <url>/2020/09/02/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p><a href="https://redspider.gitbook.io/concurrent/" target="_blank" rel="noopener">《深入浅出多线程》 阅读笔记</a><br>创建线程</p><ul><li>继承 Thread 类,重写run方法</li><li>继承 Runnable接口,实现run方法</li></ul><blockquote><p>上面的两种方法run方法没有返回值</p></blockquote><ul><li>重写callable 和future 接口,继承 futureTask类(继承了runable 和 future 接口)<ul><li>使用futureTask 需事先 call 接口</li></ul></li><li>使用Excutor创建线程池</li></ul><p>线程的状态</p><blockquote><p>创建 就绪 运行 阻塞 终止</p></blockquote><p>守护线程</p><blockquote><p>当没有任何用户线程,只有守护线程时,JVM虚拟机才可以正常退出;<br>守护线程被强制终止,不会产生永久性的严重后果<br>守护线程做一些系统级的事情,比如垃圾回收等,需要注意的是可以设置用户线程为守护线程,但是注意 该线程不要涉及 io磁盘网络操作,否则被终止可能达不到效果</p></blockquote><h2 id="基础篇">基础篇</h2><h3 id="java线程间的通信">Java线程间的通信</h3><h4 id="锁与同步">锁与同步</h4><blockquote><p>java中锁的概念都是基于对象,又称之为对象锁,为了实现同步(使线程按照一定的顺序执行)</p></blockquote><h4 id="等待通知机制">等待/通知机制</h4><blockquote><p>不断的尝试 获得锁,会消耗计算资源 ,等待/通知机制 是另一种机制,是对于同一个对象锁的wait和notify,其是基于Object类的wait()方法和notify(),notifyAll()方法实现(notify()会随机叫醒一个等待的线程,而notifyAll()会叫醒所有等待的线程)</p></blockquote><h4 id="信号量">信号量</h4><blockquote><p>JDK提供了一个类似于“信号量”功能的类Semaphore,可以控制进入 关键区的线程数目<br>volatile 关键字能够保证内存的可见性，如果用volitile关键字声明了一个变量，在一个线程里面改变了这个变量的值，那其它线程是立马可见更改后的值的</p></blockquote><h4 id="管道">管道</h4><blockquote><p>管道是基于&quot;管道流&quot;的通信方式.JDK提供了PipedReader,PipedWriter,PipedInputStream,PipedOutputStream;前者的两个是基于字符的,后面的两者 基于字节流.<br>应用场景:使用管道多半与I/O流相关。当我们一个线程需要先另一个线程发送一个信息（比如字符串）或者文件等时，就需要使用管道通信了</p></blockquote><h4 id="其他通信相关">其他通信相关</h4><h5 id="join方法">join方法</h5><blockquote><p>thread.join()方法是Thread类的一个实例方法,他的作用是使调用thread.join()的方法改程陷入&quot;等待状态&quot;(调用wait(0)实现),等join 所属的这个线程执行完,会notify_all();<a href="https://juejin.im/post/6844903997472505864" target="_blank" rel="noopener">join 详细流程</a></p></blockquote><h5 id="sleep方法">sleep方法</h5><blockquote><p>sleep 方法是Thread类的一个静态方法,其作用是使当前线程睡眠一段时间<br>sleep VS wait</p><ul><li>wait释放cpu资源，同时释放锁；sleep释放cpu资源，但是不释放锁，所以易死锁。</li><li>wait可以不指定时间,sleep 必须指定时间</li><li>wait必须放在同步块或同步方法中 将同步块涉及的对象锁释放(否则可能导致Lost wake-up problem即正常的顺序应该是a等b完成,不加synchronize可能出现 线程a经过判,即将wait,此时线程b执行了notify,但是a没有沉睡,所以无效,之后睡眠无人唤醒)，而sleep可以再任意位置</li></ul></blockquote><h5 id="threadlocal类">ThreadLocal类</h5><blockquote><p>ThreadLocal是一个本地线程副本变量工具类,配合线程的ThreadLocalMap类使用<br>ThreadLocal类并不属于多线程间的通信,而是让每个线程有自己”独立“的变量，线程之间互不影响。它为每个线程都创建一个副本，每个线程可以访问自己内部的副本变量<a href="https://www.zhihu.com/question/341005993/answer/791673856" target="_blank" rel="noopener">ThreadLocal详解</a><br>最常见的ThreadLocal使用场景为用来解决数据库连接、Session管理等<br>todo</p></blockquote><h5 id="inheritablethreadlocal">InheritableThreadLocal</h5><blockquote><p>它不仅仅是当前线程可以存取副本值,而且它的子线程也可以存取这个副本值<br>todo</p></blockquote><h2 id="原理篇">原理篇</h2><h4 id="java内存模型基础知识">Java内存模型基础知识</h4><h5 id="并发编程模型的两个关键问题">并发编程模型的两个关键问题</h5><ul><li>线程如何通信(以何种机制交换信息)：</li><li>如何同步(如何控制不同线程之间的相对执行顺序)：</li></ul><p>有两个并发模型可以解决这两个问题</p><ul><li>消息传递并发模型<ul><li>线程之间没有公共状态,线程之间的通信必须通过发送消息来显示的通信</li><li>消息传递天然同步,必然是会先发送消息,然后接收消息,是隐式同步</li></ul></li><li>共享内存并发模型<ul><li>线程之间有公共内存,可以通过读写公共内存中状态来实现隐式通信</li><li>必须 显示的指定某段代码需要线程之间互斥执行来显示同步</li></ul></li></ul><p>Java中使用的是共享内存并发模型</p><h4 id="java内存模型的抽象结构">Java内存模型的抽象结构</h4><h5 id="运行时内存的划分">运行时内存的划分</h5><p>栈(虚拟机栈,本地方法栈) 堆 方法区 PC<br>其中栈是私有的,堆是共享的</p><h5 id="既然堆是共享的为什么在堆中会有内存不可见问题">既然堆是共享的，为什么在堆中会有内存不可见问题?</h5><blockquote><p>线程之间的共享变量存在主内存中，每个线程都有一个私有的本地内存，存储了该线程以读、写共享变量的副本。本地内存是Java内存模型的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器等。<br>JMM通过控制主内存与每个线程的本地内存之间的交互，来提供内存可见性保证。</p></blockquote><h5 id="jmm与java内存区域划分的区别与联系">JMM与Java内存区域划分的区别与联系</h5><p>JMM和Java运行时内存区域的划分，这两者既有差别又有联系</p><ul><li>区别:两者是不同的概念层次。JMM是抽象的，他是用来描述一组规则，通过这个规则来控制各个变量的访问方式，围绕原子性、有序性、可见性等展开的。而Java运行时内存的划分是具体的，是JVM运行Java程序时，必要的内存划分。</li><li>联系:都存在私有数据区域和共享数据区域。一般来说，JMM中的主内存属于共享数据区域，他是包含了堆和方法区；同样，JMM中的本地内存属于私有数据区域，包含了程序计数器、本地方法栈、虚拟机栈。</li></ul><h4 id="重排序与happens-before">重排序与happens-before</h4><h5 id="什么是重排序">什么是重排序？</h5><p>计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排</p><blockquote><p>流水线技术使得指令可以并发执行,但这种技术下中断的后果严重,执行重排可以减少中断发生</p></blockquote><h5 id="顺序一致性模型与jmm的保证">顺序一致性模型与JMM的保证</h5><h5 id="happens-before">happens-before</h5><p>happens-before规则定义一些禁止编译优化的场景，保证并发编程的正确性</p><h4 id="volatitle">volatitle</h4><p>涉及概念</p><blockquote><p>内存可见性:指的是线程之间的可见性，当一个线程修改了共享变量时，另一个线程可以读取到这个修改后的值<br>重排序:为优化程序性能，对原有的指令执行顺序进行优化重新排序。重排序可能发生在多个阶段，比如编译重排序、CPU重排序等<br>happens-before规则:只要程序员在写代码的时候遵循happens-before规则，JVM就能保证指令在多线程之间的顺序性符合程序员的预期</p></blockquote><h5 id="volatile的内存语义">volatile的内存语义</h5><p>volatile主要有以下两个功能</p><ul><li>保证变量的内存可见性</li><li>禁止volatile变量与普通变量重排序</li></ul><h5 id="volatile的用途">volatile的用途</h5><h3 id="synchronized与锁">synchronized与锁</h3><blockquote><p>Java多线程的锁都是基于对象的，Java中的每一个对象都可以作为一个锁。<br>类锁其实也是对象锁,Java类只有一个Class对象（可以有多个实例对象，多个实例共享这个Class对象），而Class对象也是特殊的Java对象。所以我们常说的类锁，其实就是Class对象的锁</p></blockquote><h4 id="synchronized关键字">Synchronized关键字</h4><h4 id="几种锁">几种锁</h4><blockquote><p>Java 6 为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁“。在Java 6 以前，所有的锁都是”重量级“锁。所以在Java 6 及其以后，一个对象其实有四种锁状态，它们级别由低到高依次是</p></blockquote><ul><li>无锁状态(锁标志位 01) 记录对象的hashcode</li><li>偏向锁状态(01):偏向于第⼀个访问锁的线程(竞争出现才释放锁)：记录持有锁的线程ID和epoach</li><li>轻量级锁状态(00):多个线程在不同时段获取同⼀把锁，即不存在锁竞争的情况，也就没有线程阻塞,轻量级锁来避免线程的阻塞与唤醒 =&gt; 自旋锁: 指向栈中锁记录的指针</li><li>重量级锁状态(10):指向</li></ul><blockquote><p>几种锁会随着竞争情况逐渐升级，锁的升级很容易发生，但是锁降级发生的条件会比较苛刻，锁降级发生在Stop The World期间，当JVM进入安全点的时候，会检查是否有闲置的锁，然后进行降级</p></blockquote><h5 id="java对象头">Java对象头</h5><ul><li>Mark Word:记录了对象和锁有关的信息，当这个对象被synchronized关键字当成同步锁时，围绕这个锁的一系列操作都和Mark Word有关</li><li>指向类的指针</li><li>数组长度（只有数组对象才有）</li></ul><h3 id="cas与原子操作-乐观锁和悲观锁">CAS与原子操作 / 乐观锁和悲观锁</h3><h4 id="乐观锁与悲观锁的概念">乐观锁与悲观锁的概念</h4><blockquote><p>悲观锁:悲观锁就是我们常说的锁。对于悲观锁来说，它总是认为每次访问共享资源时会发生冲突，所以必须对每次数据操作加上锁，以保证临界区的程序同一时间只能有一个线程在执行。<br>乐观锁:乐观锁又称为“无锁”，顾名思义，它是乐观派。乐观锁总是假设对共享资源的访问没有冲突，线程可以不停地执行，无需加锁也无需等待。而一旦多个线程发生冲突，乐观锁通常是使用一种称为CAS的技术来保证线程执行的安全性</p></blockquote><blockquote><p>乐观锁多用于“读多写少“的环境，避免频繁加锁影响性能；而悲观锁多用于”写多读少“的环境，避免频繁失败和重试影响性能。</p></blockquote><h4 id="cas的概念">CAS的概念</h4><p>比较并交换（Compare And Swap）,CAS 中有三个值</p><ul><li>V：要更新的变量(var)</li><li>E：预期值(expected)</li><li>N：新值(new)</li></ul><p>比较并交换的过程如下：</p><blockquote><p>判断V是否等于E，如果等于，将V的值设置为N；如果不等，说明已经有其它线程更新了V，则当前线程放弃更新，什么都不做。<br>因为CAS是一种原子操作，它是一种系统原语，是一条CPU的原子指令，从CPU层面保证它的原子性<br>当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作</p></blockquote><h4 id="java实现cas的原理-unsafe类">Java实现CAS的原理 - Unsafe类</h4><h4 id="原子操作-atomicinteger类源码简析">原子操作-AtomicInteger类源码简析</h4><h3 id="aqs">AQS</h3><h4 id="aqs简介">AQS简介</h4><p>AQS是AbstractQueuedSynchronizer的简称，即抽象队列同步器<br>AQS:让线程使用CAS操作 volatile修饰的state变量,获取成功的可以获得锁,失败的进入 CLH实现的等待队列,等待唤醒<br>锁的类型有共享的(tryRelease,信号量),有独占的(ReentrantLock)<br>tryAcquire<br>tryRelease</p><h2 id="jdk工具篇">JDK工具篇</h2><h3 id="线程池原理">线程池原理</h3><h4 id="为什么要使用线程池">为什么要使用线程池</h4><p>使用线程池主要有以下三个原因</p><ul><li>创建/销毁线程需要消耗系统资源，线程池可以复用已创建的线程</li><li>控制并发的数量。并发数量过多，可能会导致资源消耗过多，从而造成服务器崩溃。（主要原因）</li><li>可以对线程做统一管理，定时执行、定期执行等</li></ul><h4 id="线程池的原理">线程池的原理</h4><blockquote><p>Java中的线程池顶层接口是Executor接口，ThreadPoolExecutor是这个接口的实现类</p></blockquote><h5 id="threadpoolexecutor提供的构造方法">ThreadPoolExecutor提供的构造方法</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">// 五个参数的构造函数</span><br><span class="line">public ThreadPoolExecutor(int corePoolSize,</span><br><span class="line">                          int maximumPoolSize,</span><br><span class="line">                          long keepAliveTime,</span><br><span class="line">                          TimeUnit unit,</span><br><span class="line">                          BlockingQueue&lt;Runnable&gt; workQueue)</span><br><span class="line">// 六个参数的构造函数-1</span><br><span class="line">public ThreadPoolExecutor(int corePoolSize,</span><br><span class="line">                          int maximumPoolSize,</span><br><span class="line">                          long keepAliveTime,</span><br><span class="line">                          TimeUnit unit,</span><br><span class="line">                          BlockingQueue&lt;Runnable&gt; workQueue,</span><br><span class="line">                          ThreadFactory threadFactory)</span><br><span class="line">// 六个参数的构造函数-2</span><br><span class="line">public ThreadPoolExecutor(int corePoolSize,</span><br><span class="line">                          int maximumPoolSize,</span><br><span class="line">                          long keepAliveTime,</span><br><span class="line">                          TimeUnit unit,</span><br><span class="line">                          BlockingQueue&lt;Runnable&gt; workQueue,</span><br><span class="line">                          RejectedExecutionHandler handler)</span><br><span class="line">// 七个参数的构造函数</span><br><span class="line">public ThreadPoolExecutor(int corePoolSize,</span><br><span class="line">                          int maximumPoolSize,</span><br><span class="line">                          long keepAliveTime,</span><br><span class="line">                          TimeUnit unit,</span><br><span class="line">                          BlockingQueue&lt;Runnable&gt; workQueue,</span><br><span class="line">                          ThreadFactory threadFactory,</span><br><span class="line">                          RejectedExecutionHandler handler)</span><br></pre></td></tr></table></figure><blockquote><p>四种构造方法都涉及五个参数</p><ul><li>int corePoolSize:核心线程的最大数量(核心线程会默认存在于线程池,而非核心线程闲置超时会被销毁)<a href="https://blog.csdn.net/MingHuang2017/article/details/79571529" target="_blank" rel="noopener">核心线程的复用</a></li><li>int maximumPoolSize:线程总数的上限</li><li>long keepAliveTime: 非核心线程闲置时长(如果设置allowCoreThreadTimeOut(true)，则会也作用于核心线程)</li><li>TimeUnit unit：keepAliveTime的单位</li><li>BlockingQueue workQueue:阻塞队列,维护着等待执行的Runnable任务对象<ul><li>LinkedBlockingQueue:链式阻塞队列,底层是链表,默认大小是Integer.MAX_VALUE,也可指定</li><li>ArrayBlockingQueue:数组阻塞队列,基于数组实现,需指定队列大小</li><li>SynchronousQueue:同步队列,内部容量为0,每个put操作必须等待一个take操作</li><li>DelayQueue：延迟队列,队列中的元素必须等待其指定的延迟时间,才能取到其元素</li></ul></li></ul></blockquote><blockquote><p>两个非必须参数</p><ul><li>ThreadFactory threadFactory:创建线程的工厂 ，用于批量创建线程，统一在创建线程时设置一些参数，如是否守护线程、线程的优先级等。如果不指定，会新建一个默认的线程工厂。</li><li>RejectedExecutionHandler handler:拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为<ul><li>ThreadPoolExecutor.AbortPolicy:默认拒绝处理策略，丢弃任务并抛出RejectedExecutionException异常</li><li>ThreadPoolExecutor.DiscardPolicy:丢弃新来的任务，但是不抛出异常</li><li>ThreadPoolExecutor.DiscardOldestPolicy:丢弃队列头部（最旧的）的任务，然后重新尝试执行程序（如果再次失败，重复此过程）</li><li>ThreadPoolExecutor.CallerRunsPolicy:由调用线程处理该任务 阻塞主线程</li></ul></li></ul></blockquote><h5 id="threadpoolexecutor的策略">ThreadPoolExecutor的策略</h5><blockquote><p>线程池本身有一个调度线程,这个线程就是用于管理布控整个线程池里的各种任务和事务，例如创建线程、销毁线程、任务队列管理、线程队列管理等等<br>ThreadPoolExecutor类中定义了一个volatile int变量runState来表示线程池的状态 ，分别为RUNNING、SHURDOWN、STOP、TIDYING 、TERMINATED</p></blockquote><ul><li>线程池创建之后处于Runnig状态</li><li>调用shutdown之后处于SHUTDOWN状态,线程池不能接受新的任务,同时销毁空闲的work线程,等待阻塞队列的任务完成</li><li>调用shutDownNow 之后处于 Stop 状态,不接受新任务,中断所有线程(线程执行完任务,根据状态是否中断),阻塞队列中所有没有执行的任务丢弃,此时poolsize=0,阻塞队列大小为0</li><li>当所有任务终止时,ctl记录的&quot;当前线程&quot;为0,线程池变为TIDYING状态,接着执行terminated 函数</li><li>线程池处在TIDYING状态时，执行完terminated()方法之后，就会由 TIDYING -&gt; TERMINATED， 线程池被设置为TERMINATED状态</li></ul><h5 id="线程池主要的任务处理流程">线程池主要的任务处理流程</h5><ul><li>线程总数量小于corePoolSize,无论线程是否空闲,都会新建一个核心线程执行任务(让核心线程数量快速达到corePoolSize，在核心线程数量 &lt; corePoolSize时) 注意，在addWork核心部门 需要获得全局锁</li><li>线程总数量 &gt;= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的核心线程会依次去缓存队列中取任务来执行（体现了线程复用）</li><li>线程总数量 &gt;= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的核心线程会依次去缓存队列中取任务来执行（体现了线程复用）</li><li>线程总数量 &gt;= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的核心线程会依次去缓存队列中取任务来执行（体现了线程复用）</li></ul><h5 id="threadpoolexecutor如何做到线程复用的">ThreadPoolExecutor如何做到线程复用的</h5><blockquote><p>ThreadPoolExecutor在创建线程时，会将线程封装成工作线程worker,并放入工作线程组中，然后这个worker反复从阻塞队列中拿任务去执行</p></blockquote><h5 id="其他">其他</h5><blockquote><p>ctl类型为AtomicInteger，那用一个基础如何表示以上五种状态以及线程池工作线程数量呢？int型变量占用4字节，共32位，因此采用位表示，可以解决上述问题。5种状态使用5种数值进行表示，需要占用3位，余下的29位就可以用来表示线程数。因此，高三位表示进程状态，低29位为线程数量</p></blockquote><h4 id="四种常见的线程池">四种常见的线程池</h4><blockquote><p>Executors类中提供的几个静态方法来创建线程池,实际上通过ThreadPoolExecutor 构造</p><ul><li>newCachedThreadPool：ThreadPoolExecutor(0, Integer.MAX_VALUE,60L, TimeUnit.SECONDS,new SynchronousQueue<runnable>());运行流程如下:<ul><li>提交任务进线程池</li><li>由于corePoolSize为0,不创建核心线程</li><li>将任务添加进SynchronousQueue 队列;如果队列中已有任务,该操作会阻塞,否则添加成功,创建非核心线程,从队列中拉取任务并执行<br>当执行很多短时间的任务时,newCacheThreadPool的复用效率比较高,可以显著提高性能;60s保证了空闲线程不会占据资源太长时间</li></ul></runnable></li><li>newFixedThreadPool：new ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<runnable>());<ul><li>核心线程数量和总线程数量相等，都是传入的参数nThreads，所以只能创建核心线程，不能创建非核心线程.</li><li>如果核心线程空闲,则交给核心线程处理;否则进入队列(长队默认INT_MAX_VVALUE)等待 核心线程空闲</li><li>对比<ul><li>newFixedThreadPool 只创建核心线程 且 核心线程创建后不会被回收 即使没有任务也会占用很多资源</li><li>都几乎不会触发拒绝策略，但是原理不同：newCacheThreadPool 由于 非线程 数量 几乎没有限制,所以基本不会 拒绝;而newFixedThreadPool 由于阻塞队列长度很大 也几乎不会触发拒绝策略</li></ul></li></ul></runnable></li><li>newSingleThreadPool:ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<runnable>())<ul><li>有且仅有一个核心线程按照先入先出的顺序执行任务;其阻塞队列 LinkedBlockingQueue 容量很大</li></ul></runnable></li><li>newScheduledThreadPool:(corePoolSize, Integer.MAX_VALUE,DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,new DelayedWorkQueue())<br>- 创建一个定长线程池(DEFAULT_KEEPALIVE_MILLIS为0)，配合DelayedWorkQueue 支持定时及周期性任务执行</li></ul></blockquote><h3 id="阻塞队列">阻塞队列</h3><h4 id="阻塞队列的由来">阻塞队列的由来</h4><blockquote><p>对生产者-消费者模式的实现能够简化开发流程,解耦生产消费数据的过程,同时简化数据的冲突问题<br>BlockingQueue是Java util.concurrent包下重要的数据结构，区别于普通的队列，BlockingQueue提供了线程安全的队列访问方式，并发包下很多高级同步类的实现都是基于BlockingQueue实现的。BlockingQueue就是存放元素的容器。</p></blockquote><p>阻塞队列提供了四组不同的方法用于插入、移除、检查元素</p><table><thead><tr><th>方法\处理方式</th><th style="text-align:center">抛出异常</th><th style="text-align:center">返回特殊值</th><th style="text-align:center">一直阻塞</th><th style="text-align:right">超时退出</th></tr></thead><tbody><tr><td>插入方法</td><td style="text-align:center">add(e)</td><td style="text-align:center">offer(2)</td><td style="text-align:center">put(e)</td><td style="text-align:right">offer(e,time,unit)</td></tr><tr><td>移除方法</td><td style="text-align:center">remove()</td><td style="text-align:center">poll()</td><td style="text-align:center">take(e)</td><td style="text-align:right">poll(time,unit)</td></tr><tr><td>移除方法</td><td style="text-align:center">element()</td><td style="text-align:center">peek</td><td style="text-align:center">-</td><td style="text-align:right">-</td></tr></tbody></table><h4 id="blockingqueue的实现类">BlockingQueue的实现类</h4><h5 id="arrayblockingqueue">ArrayBlockingQueue</h5><p>由数组结构组成的有界阻塞队列。内部结构是数组，故具有数组的特性<br>可以初始化队列大小， 且一旦初始化不能改变。构造方法中的fair表示控制对象的内部锁是否采用公平锁，默认是非公平锁</p><h5 id="linkedblockingqueue">LinkedBlockingQueue</h5><p>由链表结构组成的有界阻塞队列。内部结构是链表，具有链表的特性。默认队列的大小是Integer.MAX_VALUE，也可以指定大小。此队列按照先进先出的原则对元素进行排序。</p><h5 id="delayqueue">DelayQueue</h5><p>该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素 。注入其中的元素必须实现 java.util.concurrent.Delayed 接口。<br>DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。</p><h5 id="priorityblockingqueue">PriorityBlockingQueue</h5><p>基于优先级的无界阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），内部控制线程同步的锁采用的是公平锁。</p><h5 id="synchronousqueue">SynchronousQueue</h5><p>这个队列比较特殊，没有任何内部容量(利用基于数组的最小二叉堆实现，初始容量为11会自动扩容)，甚至连一个队列的容量都没有。并且每个 put 必须等待一个 take，反之亦然。</p><h4 id="阻塞队列的原理">阻塞队列的原理</h4><blockquote><p>阻塞队列利用 锁的多条件Condition 阻塞控制实现(类似Object的wait notify)<br>对于同一个 ReentrantLock 锁 初始化两个监视器 NotFull NotEmpty<br>这两个监视器的作用目前可以简单理解为标记分组，当该线程是put操作时，给他加上监视器notFull,标记这个线程是一个生产者；当线程是take操作时，给他加上监视器notEmpty，标记这个线程是消费者。 利用 Condition的wait notify 实现 消费者和生产者之间的互动<br>需要注意的是ArrayBlockingQueue 只有一个锁,而LinkedBlockingQueue 有take,put 两个锁,各自初始化 notEmpty notFull</p></blockquote><h3 id="锁接口和类">锁接口和类</h3><blockquote><p>Java原生的锁——基于对象的锁，它一般是配合synchronized关键字来使用的;不足之处</p><ul><li>如果临界区是只读操作，其实可以多线程一起执行，但使用synchronized的话，同一时间只能有一个线程执行。</li><li>synchronized无法知道线程有没有成功获取到锁</li><li>使用synchronized，如果临界区因为IO或者sleep方法等原因阻塞了，而当前线程又没有释放锁，就会导致所有线程等待</li></ul></blockquote><h4 id="锁的几种分类">锁的几种分类</h4><h5 id="可重入锁和非可重入锁">可重入锁和非可重入锁</h5><p>重入锁:顾名思义。就是支持重新进入的锁，也就是说这个锁支持一个线程对同一个资源重复加锁<br>实现：每一个锁关联一个线程持有者和计数器，当计数器为 0 时表示该锁没有被任何线程持有，那么任何线程都可能获得该锁而调用相应的方法；当某一线程请求成功后，JVM会记下锁的持有线程，并且将计数器置为 1；此时其它线程请求该锁，则必须等待；而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增；当线程退出同步代码块时，计数器会递减，如果计数器为 0，则释放该锁。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">// 演示可重入锁是什么意思，可重入，就是可以重复获取相同的锁，synchronized和ReentrantLock都是可重入的</span><br><span class="line">// 可重入降低了编程复杂性</span><br><span class="line">public class WhatReentrant &#123;</span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">new Thread(new Runnable() &#123;</span><br><span class="line">@Override</span><br><span class="line">public void run() &#123;</span><br><span class="line">synchronized (this) &#123;</span><br><span class="line">System.out.println(&quot;第1次获取锁，这个锁是：&quot; + this);</span><br><span class="line">int index = 1;</span><br><span class="line">this.reenter();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;).start();</span><br><span class="line">&#125;</span><br><span class="line">    public static void reenter()&#123;</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            synchronized (this) &#123;</span><br><span class="line">                System.out.println(&quot;第&quot; + (++index) + &quot;次获取锁，这个锁是：&quot; + this);</span><br><span class="line">            &#125;</span><br><span class="line">            if (index == 10) &#123;</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="公平锁与非公平锁">公平锁与非公平锁</h4><p>公平锁:就是&quot;先来后到&quot;，也就是FIFO。如果对一个锁来说，先对锁获取请求的线程一定会先被满足，后对锁获取请求的线程后被满足，那这个锁就是公平的。反之，那就是不公平的<br>一般情况下，非公平锁能提升一定的效率。但是非公平锁可能会发生线程饥饿（有一些线程长时间得不到锁）的情况。所以要根据实际的需求来选择非公平锁和公平锁。<br>ReentrantLock支持非公平锁和公平锁两种<br>非公平锁性能高于公平锁性能。首先，在恢复一个被挂起的线程与该线程真正运行之间存在着严重的延迟。而且，非公平锁能更充分的利用cpu的时间片，尽量的减少cpu空闲的状态时间</p><h4 id="读写锁和排它锁">读写锁和排它锁</h4><p>synchronized用的锁和ReentrantLock，其实都是“排它锁”。也就是说，这些锁在同一时刻只允许一个线程进行访问。<br>读写锁可以再同一时刻允许多个读线程访问。Java提供了ReentrantReadWriteLock类作为读写锁的默认实现，内部维护了两个锁：一个读锁，一个写锁。通过分离读锁和写锁，使得在“读多写少”的环境下，大大地提高了性能。</p><h3 id="jdk中有关锁的一些接口和类">JDK中有关锁的一些接口和类</h3><h4 id="抽象类aqsaqlsaos">抽象类AQS/AQLS/AOS</h4><h4 id="接口conditionlockreadwritelock">接口Condition/Lock/ReadWriteLock</h4><p>每个对象都可以用继承自Object的wait/notify方法来实现等待/通知机制。而Condition接口也提供了类似Object监视器的方法，通过与Lock配合来实现等待/通知模式</p><h4 id="reentrantlock">ReentrantLock</h4><h4 id="reentrantreadwritelock">ReentrantReadWriteLock</h4><p>ReadWriteLock接口的JDK默认实现。它与ReentrantLock的功能类似，同样是可重入的，支持非公平锁和公平锁。不同的是，它还支持”读写锁“。</p><h3 id="并发集合容器简介">并发集合容器简介</h3><h4 id="同步容器与并发容器">同步容器与并发容器</h4><p>java.util包下提供了一些容器类，而Vector和HashTable是线程安全的容器类，但是这些容器实现同步的方式是通过对方法加锁(sychronized)方式实现的，这样读写均需要锁操作，导致性能低下。<br>并发容器是Java 5 提供的在多线程编程下用于代替同步容器，针对不同的应用场景进行设计，提高容器的并发访问性，同时定义了线程安全的复合操作。</p><h4 id="并发容器类介绍">并发容器类介绍</h4><p>BlockingQueue CopyOnWrite</p><h5 id="并发map">并发Map</h5><h6 id="concurrentmap接口">ConcurrentMap接口</h6><p>ConcurrentHashMap类</p><blockquote><p>ConcurrentHashMap同HashMap一样也是基于散列表的map，但是它提供了一种与HashTable完全不同的加锁策略提供更高效的并发性和伸缩性。<br>ConcurrentHashMap提供了一种粒度更细的加锁机制来实现在多线程下更高的性能，这种机制叫分段锁(Lock Striping)。<br>提供的优点是：在并发环境下将实现更高的吞吐量，而在单线程环境下只损失非常小的性能。<br>可以这样理解分段锁，就是将数据分段，对每一段数据分配一把锁。当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问<br>有些方法需要跨段，比如size()、isEmpty()、containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁<br>ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，HashEntry则用于存储键值对数据。</p></blockquote><p><a href="https://my.oschina.net/pingpangkuangmo/blog/817973" target="_blank" rel="noopener">1.8版</a><br><a href="https://zhuanlan.zhihu.com/p/151419617" target="_blank" rel="noopener">参考2</a><br>更改为 数组+单链表/红黑树的结构(由于segment的存在反而加大了锁的冲突,1.8的锁基于首节点)<br>读操作无需加锁:val next元素 使用volatile修饰,保证能够读到最新的的数据,对数组引用的修饰保证数组扩容的可见性(比hashmap更高效)<br>put操作时 当节点首尾null时首先尝试利用CAS操作更新,否则加锁更新</p><p>ConcurrentNavigableMap接口与ConcurrentSkipListMap类</p><h5 id="并发queue">并发Queue</h5><p>JDK并没有提供线程安全的List类，因为对List来说，很难去开发一个通用并且没有并发瓶颈的线程安全的List。因为即使简单的读操作，拿contains() 这样一个操作来说，很难搜索的时候如何避免锁住整个list。<br>DK提供了对队列和双端队列的线程安全的类：ConcurrentLinkedDeque和ConcurrentLinkedQueue;这两个类是使用CAS来实现线程安全的</p><h5 id="并发set">并发Set</h5><p>ConcurrentSkipListSet，是线程安全的有序的集合。底层是使用ConcurrentSkipListMap实现</p><h1 id="问题">问题</h1><h3 id="多线程基础">多线程基础</h3><p>什么是线程和进程? 线程与进程的关系,区别及优缺点？</p><blockquote><p>区别：</p><ul><li>进程是一个独立的运行环境，而线程是在进程中执行的一个任务。他们两个本质的区别是是否单独占有内存地址空间及其它系统资源（比如I/O）</li><li>进程是操作系统进行资源分配的基本单位，而线程是操作系统进行调度的基本单位，即CPU分配时间的单位<br>进程让操作系统的并发性成为了可能，而线程让进程的内部并发成为了可能<br>上下文是指某一时间点 CPU 寄存器和程序计数器的内容。<br>上下文切换通常是计算密集型的，意味着此操作会消耗大量的 CPU 时间，故线程也不是越多越好</li></ul></blockquote><p>区别,优缺点：</p><blockquote><p>多线程 VS 多进程 ：多线程 能够充分利用 多核CPU的资源,降低了进程上下文切换的消耗 但是多线程的资源共享也可能出现竞争冲突,死锁等</p></blockquote><p>说说并发与并行的区别?</p><blockquote><p>并发指一段时间内多个任务的同时存在,逻辑上同时,对于于线性执行,对于AB任务的执行,在完成部分A切换到完成B(时间片轮转调度)<br>并行指多个任务的同时存在,时间上同时,并行是并发的一个子集,人脑就是并行的,左半脑控制运动的同时,右半脑可以思考</p></blockquote><p>为什么要使用多线程呢?</p><blockquote><p>多进程方式确实可以实现并发，但使用多线程，有以下几个好处</p><ul><li>进程间的通信比较复杂，而线程间的通信比较简单，通常情况下，我们需要使用共享资源，这些资源在线程间的通信比较容易。<ul><li>进程：管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams</li><li>线程：锁,等待通知机制(wait notify),信号量,管道 其他(join sleep threadLocal)</li></ul></li><li>进程是重量级的，而线程是轻量级的，故多线程方式的系统开销更小</li></ul></blockquote><p>使用多线程可能带来什么问题?（内存泄漏、死锁、线程不安全等等）</p><blockquote><p>通知等待机制 导致的死锁;共享变量导致的线程不安全;大量线程导致的OOM;内存泄漏(就是该被释放的对象没有释放，一直被某个或某些实例所持有却不再被使用导致 GC 不能回收例如ThreadLocal中的value);</p></blockquote><p>创建线程有哪几种方式？（a.继承 Thread 类;b.实现 Runnable 接口;c. 使用 Executor 框架;d.使用 FutureTask）</p><blockquote><p>实现Runable接口;继承Thread类;实现callable 接口或使用futureTask ;使用Executor 创建多线程</p></blockquote><p>说说线程的生命周期和状态?</p><blockquote><p>新建-就绪-运行-阻塞-waitting-timeWaitting-死亡</p></blockquote><p>什么是上下文切换?</p><blockquote><p>上下文指某一时间点 cpu 和程序计数器的内容;进程之间 通过 时间片轮转算法 来获取时间片运行,上下文是休眠进程恢复运行的需要数据;上下文切换指进程的上下文的保存与恢复</p></blockquote><p>什么是线程死锁?如何避免死锁?</p><blockquote><p>指两个或两个以上的线程互相持有对方需要的资源<br>死锁产生的必要条件: 请求和保持,不可剥脱,环形等待,资源互斥<br>避免:加锁顺序：线程按照相同的顺序加锁 ;加锁时限，线程获取锁的过程中限制一定的时间(jps 查进程;jstack + id 查线程)</p></blockquote><p>说说 sleep() 方法和 wait() 方法区别和共同点?</p><blockquote><p>共同点:都使得线程处于休眠状态<br>区别：</p><ul><li>sleep 仅释放CPU资源,而wait释放CPU和锁资源</li><li>sleep是线程方法(最终调用本地方法实现),wait属于Object方法</li><li>wait需要被动唤醒</li><li>sleep方法不依赖于同步器synchronized，但是wait需要依赖synchronized关键字</li></ul></blockquote><p>为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？如果多次调用start方法会发生什么？</p><blockquote><p>线程状态(NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED 0-5 )<br>线程 start时,会判断线程状态是否是0/NEW,是才可以运行否则 报IllegalThreadStateException;然后会将 线程加入 main 线程组,调用<a href="https://www.linuxidc.com/Linux/2016-03/128997.htm" target="_blank" rel="noopener">start0</a>方法然后真正创建线程,然后 等待调度器调用<br>直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作<br>start()方法不能多次调用，否则抛出java.lang.IllegalStateException；而，run()方法可以进行多次调用，因为它只是一种正常的方法调用<br>在java中，每次程序运行至少启动两个线程，一个是main线程，一个是垃圾回收线程</p></blockquote><p>阻塞的情况分三种</p><p>什么情况下使用join()？</p><p>yield方法，使当前线程让出cpu占用权，进入执行队列,不可能使较低较低优先权的线程获得cpu占有权，而sleep可以在没有锁的情况下，sleep()可以使低优先级的线程得到执行的机会</p><h3 id="多线程知识进阶">多线程知识进阶</h3><h4 id="线程池提交任务的方式">线程池提交任务的方式</h4><p><a href="https://blog.csdn.net/weixin_44053668/article/details/102155732" target="_blank" rel="noopener">两种方式</a></p><ul><li>execute :在执行完runnable任务之后没有返回值</li><li>submit：运行完任务之后有返回值,可以通过实现Callable接口,封装为futureTask,get获取任务结果<br>FutureTask多用于耗时的计算，并行执行耗时任务,主线程可以在完成自己的任务后，再去获取结果；取消因需求资源而长期等待的任务;利用CocurrentHashMap 和 FutureTask 使得 同时只有一个线程在执行任务<a href="https://zhuanlan.zhihu.com/p/34004674" target="_blank" rel="noopener">如何构建一个高效且可伸缩的缓存</a></li></ul><h4 id="为什么不直接使用thread-使用runable">为什么不直接使用Thread 使用runable</h4><blockquote><p>实现接口,多继承<br>重复使用runable接口</p></blockquote><h4 id="executorservice-submit之后发生了什么">executorService submit之后发生了什么?</h4><blockquote><p>submit 之后返回Future 的泛型,可以调用get阻塞获取执行结果而execute 无法得到结果<br>todo 需要注意的是 submit 中产生的以上会被setException 吸取,无法显示抛出异常<br>源码解析：todo</p></blockquote><h4 id="completablefuture-completableservice">CompletableFuture CompletableService</h4><h4 id="volatile-关键字">volatile 关键字</h4><p>Java 内存模型（JMM）</p><blockquote><p>Java内存区域:PC+堆+本地方法栈+线程栈+方法区<br>JMM:线程 和线程私有的工作内存(栈) 通过缓存一致性协议 实现对主内存的读写<br><img src="/images/JMM.png" alt="JMM"></p></blockquote><p>重排序与 happens-before 原则了解吗?</p><blockquote></blockquote><p>volatile 关键字的作用</p><blockquote><p>保证可见性和有序性(禁止指令重排序:涉及volatile变量的指令顺序不可优化),但不能保证原子性,因而线程不安全</p></blockquote><p>说说 synchronized 关键字和 volatile 关键字的区别</p><blockquote><p>volatile 实质上在 告诉JVM当前值 不确定,要求 读写最新值;而synchronize锁定当前变量,不允许其他线程访问</p><ul><li>能够保证可见性,但不能保证原子性;synchronize 保证原子性和修改可见性</li><li>volatile 只能应用在 变量;而synchronize则可以对象方法和类(但都是对象锁)</li><li>volatile 不会导致线程的的阻塞;</li><li>volatile 修饰的变量不会被编译器优化</li></ul></blockquote><h4 id="threadlocal">ThreadLocal</h4><p><a href="https://zhuanlan.zhihu.com/p/205174552" target="_blank" rel="noopener">为了进阿里，死磕了ThreadLocal内存泄露原因</a><br><a href="https://zhuanlan.zhihu.com/p/192873419" target="_blank" rel="noopener">ThreadLocal面试六连问，你能Hold住吗？</a><br><a href="https://www.cnblogs.com/nullzx/p/7553538.html" target="_blank" rel="noopener">ThreadLocal原理及使用示例</a></p><p>有啥用（解决了什么问题）？怎么用？</p><blockquote><p>ThreadLocal是一个线程本地变量副本工具类，内部用一个弱引用的Map维护<br>高并发的时候，我们在调用一些公有的对象资源的时候，会有线程安全问题或者加锁 阻塞问题;利用ThreadLocal 可以解决多线程变量共享问题(重写initialValue);在数据库连接池里使用ThreadLocal 限制 多线程使用的conection为同一个,保持处于同一个事物<br><a href="https://www.jianshu.com/p/3ab5f9145ca2" target="_blank" rel="noopener">案例分析</a><br>多线程下SimpleDateFormat 不安全,由于多个线程之间共享并修改变量calendar,导致不安全(解决 1.局部变量 2.加锁共享 3.ThreadLocal )</p></blockquote><p>原理了解吗？</p><blockquote><p>Thread 维护一个 threadLocalMap，实质上是一个Entry(WeekReference&lt;ThreadLocalMap&lt;?&gt;作为Entry的key&gt;)数组;threadLocal 的实例 是 线程的共享变量,其实例的弱引用作为 Entry的key ,以threadLocal实例哈希值作为 数组的index,然后存取变量;<br>在开始get时,默认是从当前线程(this只当前对象,this.currentThread指调用这段代码的线程) 获取map,以threadLocal做index获取Entry,然后获取value;<br>多线程 线程复用</p></blockquote><p>内存泄露问题了解吗？</p><blockquote><p>由于ThreadLocalMap的Entry中对ThreadLocal是弱引用,如果 指向其的强引用不在指向它(改为null或者其他),那么在gc中 可能导致 清除 ThreadLocal对象,而thread-&gt;threadLocalMap-&gt;value 是强引用不会清除,但value已经无法访问<br>解决方法: 每次在使用完之后remove ; 用 static(所有实例共享) final(无法修改执行) 修饰 ; THreadLocal本身在getEntry方法中也会主动清除Entry为null的key和value<br>其本质原因是由于ThreadLocalMap与线程的生命周期一致,所以当ThreadLocalMap无效时,无法清除(但是多线程里通过复用线程来提高性能， 所以currentThread一般不会处于终止状态);利用弱引用相当于告诉JVM 去清除(另类的通知机制) 而如果是强引用,那么即使ThreadLocal无人在使用,只要有一个线程还在运行/休眠阻塞,那么它就无法清除</p></blockquote><p>InheritableThreadLocal?</p><blockquote><p>子线程可以访问父线程的ThreadLocal对象,通过重写 getchildValue，getMap(返回inheritlocals) createMap(赋值inheThreadlocals) 实现<br>Thread类构造函数中:子线程在实例化过程中，会查看当前执行线程（可以理解为父线程）的inheritableThreadLocals是否为null，如果不为null，则将该变量赋值给子线程的inheritableThreadLocals</p></blockquote><p>手动释放ThreadLocal遗留存储?你怎么去设计/实现？</p><blockquote><p>包装其父类remove方法为静态方法在强引用的析构函数里清除;如果是spring项目， 可以借助于bean的声明周期， 在拦截器的afterCompletion阶段进行调用</p></blockquote><p>Thread和ThreadLocal有什么联系呢</p><blockquote><p>Thread和ThreadLocal是绑定的， ThreadLocal依赖于Thread去执行， Thread将需要隔离的数据存放到ThreadLocal(准确的讲是ThreadLocalMap)中, 来实现多线程处理</p></blockquote><p>Spring如何处理Bean多线程下的并发问题</p><blockquote><p>ThreadLocal天生为解决相同变量的访问冲突问题， 所以这个对于spring的默认单例bean的多线程访问是一个完美的解决方案。spring也确实是用了ThreadLocal来处理多线程下相同变量并发的线程安全问题。<br>spring 如何保证数据库事务在同一个连接下执行的<br>DataSourceTransactionManager 是spring的数据源事务管理器， 它会在你调用getConnection()的时候从数据库连接池中获取一个connection， 然后将其与ThreadLocal绑定， 事务完成后解除绑定。这样就保证了事务在同一连接下完成。</p></blockquote><h4 id="线程池">线程池</h4><p>为什么要用线程池？</p><blockquote><p>线程的新建和消耗系统资源,可以利用线程池复用线程;控制并发数量,避免耗尽系统资源;统一管理线程</p></blockquote><p>你会使用线程池吗？</p><blockquote><p>腾讯项目使用过线程池,利用futureTask获取结果</p></blockquote><p>如何创建线程池比较好？ （推荐使用 ThreadPoolExecutor 构造函数创建线程池）</p><blockquote><p>Java中的线程池顶层接口是Executor接口，ThreadPoolExecutor是这个接口的实现类,可以使用ThreadPoolExecutor 构建函数创建线程池</p></blockquote><p>ThreadPoolExecutor 类的重要参数了解吗？ThreadPoolExecutor 饱和策略了解吗？</p><blockquote><p>ThreadPoolExcecutor 有四个构造函数,其中都包含 核心线程数,最大线程数,非核心线程闲置时间,限制时间单位,阻塞队列,还有两个参数分别是 线程工厂 和  饱和拒绝策略<br>饱和拒绝策略具体可以分为四种</p><ul><li>Abort 抛弃任务并抛出异常</li><li>Discard 仅抛弃任务</li><li>抛弃最先进入队列的任务</li><li>由调用者执行该任务</li></ul></blockquote><p>线程池原理了解吗？</p><blockquote><p>线城池里的线程在运行后会不断的从阻塞队列中获取任务,新建线程或者复用空闲线程,执行,直到getTask 返回null,此时确定是否准备销毁线程</p></blockquote><p>几种常见的线程池了解吗？为什么不推荐使用FixedThreadPool？</p><blockquote><p>newCacheThreadPool(0,MAX),newFixedThreadPool,newSIngleThreadPool(单核心线程),newScheduledThreadPool(size,MAX,定时线程)<br>因为newFixedThreadPool 只要核心线程,而核心线程即使空闲也默认不会被回收,空占资源<br>之所以建议使用ThreadPool 自己配置参与和策略是因为 提供的方法有些参数默认是Max_VALUE,对于数量过大的任务,可能出现线程数量过多或者阻塞队列太长消耗完资源的情况</p></blockquote><p>如何设置线程池的大小？</p><blockquote><p>coreSize allsize</p></blockquote><p>线程池的运行状态?</p><blockquote><p>Runnning:线程池新建之后处于该状态<br>ShutDown:不接受任务,等现有阻塞任务完成；销毁空闲线程<br>Stop:中断任务<br>TIDYING:目前运行的线程为0<br>TERMINATE：</p></blockquote><h4 id="aqs">AQS</h4><p>简介<br>原理<br>AQS 常用组件。<br>Semaphore(信号量)-允许多个线程同时访问<br>CountDownLatch （倒计时器）-CountDownLatch 允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。<br>CyclicBarrier(循环栅栏)-CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。<br>ReentrantLock 和 ReentrantReadWriteLock</p><h4 id="锁">锁</h4><p>锁的常见分类</p><ul><li>可重入锁和非可重入锁</li><li>公平锁与非公平锁</li><li>读写锁和排它锁<br>synchronized 关键字</li><li>说一说自己对于 synchronized 关键字的了解；</li><li>说说自己是怎么使用 synchronized 关键字，在项目中用到了吗;</li><li>讲一下 synchronized 关键字的底层原理；</li><li>说说 JDK1.6 之后的 synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗</li><li>谈谈 synchronized 和 ReentrantLock 的区别</li></ul><blockquote><p>都是</p></blockquote><h4 id="atomic-与-cas">Atomic 与 CAS</h4><h5 id="cas">CAS:</h5><p>介绍<br>原理</p><h5 id="atomic-原子类">Atomic 原子类：</h5><p>介绍一下 Atomic 原子类；<br>JUC 包中的原子类是哪 4 类?；</p><ul><li>基本类型：AtomicInteger, AtomicLong, AtomicBoolean</li><li>数组类型： AtomicIntegerArray, AtomicLongArray, AtomicReferenceArray</li><li>引用类型：AtomicReference, AtomicStampedRerence, AtomicMarkableReference</li><li>对象的属性修改类型：AtomicIntegerFieldUpdater, AtomicLongFieldUpdater, AtomicReferenceFieldUpdater<br>讲讲 AtomicInteger 的使用；i++<br>能不能给我简单介绍一下 AtomicInteger 类的原理。<br>ABA 问题</li></ul><blockquote><p>如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA”问题。Java并发包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。因此，在使用CAS前要考虑清楚“ABA”问题是否会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。<br>AtomicStampedReference对应的数值被修改时，除了更新数据本身外，还必须要更新时间戳。当AtomicStampedReference设置对象值时，对象值以及时间戳都必须满足期望值，写入才会成功。因此，即使对象值被反复读写，写回原值，只要时间戳发生变化，就能防止不恰当的写入</p></blockquote><h3 id="并发容器">并发容器</h3><p>JDK 提供的这些容器大部分在 java.util.concurrent 包中。</p><ul><li>ConcurrentHashMap: 线程安全的 HashMap</li><li>CopyOnWriteArrayList: 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector.</li><li>ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。</li><li>BlockingQueue: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。</li><li>ConcurrentSkipListMap: 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。</li></ul><h4 id="future-和-completablefuture">Future 和 CompletableFuture</h4><h3 id="自旋锁">自旋锁</h3><blockquote><p>自旋锁一般适用于短时间占用锁的场合,因为自旋锁的实现是不断的循环试图获得锁,修改数据;<br>自旋锁一般不会涉及线程的切换,只会不断的尝试获得锁 空耗CPU时间等待另一个线程释放锁(多核线程),所以一般自旋锁应用于短时间占用锁的场合</p></blockquote><h3 id="condition">condition</h3><p>condition 必须和锁 关联</p><h3 id="synchronize的原理">synchronize的原理</h3><blockquote><p>任何java对象都有一个monitor与之关联，当一个monitor被持有后，对象就处于锁定状态。</p></blockquote><h3 id="semaphore">Semaphore</h3><p>可以定义进入 某段代码的线程的个数(多个锁)</p><h3 id="executor框架">Executor框架</h3><h3 id="jvm-引用">JVM 引用</h3><p>单纯的GC算法不足以应对复杂场景下垃圾回收</p><ul><li>强引用: 在无标注的情况下, 所创建的对象引用都是强引用;一般情况下,GC不会回收它,内存不足时会抛出OOM;</li><li>软引用: 内存空间不足时,会回收它指向的对象;适用于缓存</li><li>弱引用: 只有当垃圾回收器扫描到弱引用指向的对象时，才会回收它。生命周期比软引用更短。ThreadLocal使用了弱引用</li><li>虚引用: 在任何时候都可能被垃圾回收器回收，必须与引用队列关联使用</li></ul><p>配置线程的考虑因素</p><blockquote><p>从任务类型(io密集还是cpu密集)</p><ul><li>CPU密集:创建的线程数 不应该超过物理核数</li><li>IO密集:所使用的的资源类型(这些系统资源包括了内存（堆栈）、打开的文件句柄、打开的TCP连接),限制数据避免耗尽资源<br>实际执行需求;压测获取分析</li></ul></blockquote><p><a href="https://www.zhihu.com/question/19732473" target="_blank" rel="noopener">怎样理解阻塞非阻塞与同步异步的区别</a><br>在线程等待资源就绪以及传输资源进入内存时,线程可以做其他事情;<br>NIO 基于channel 和 buffer操作,数据在channel和buffer 之间流动<br>selector 与channel 相互配合,将Channel注册到Selector 上,selector会监控Channel的四种状态,Connect-&gt;Accept-&gt;Read-&gt;Write 当监控到Channel的某一状态时,才允许Channel对相应的状态</p><ul><li>Connect：怎样理解阻塞非阻塞与同步异步的区别</li><li>Accept：准备好进行连接</li><li>Read：可读</li><li>Write：可写</li></ul><p><a href="https://blog.csdn.net/qq_34337272/article/details/81252853" target="_blank" rel="noopener">面试必备之深入理解自旋锁</a></p><p>CAS:<br><a href="https://mp.weixin.qq.com/s?__biz=MzI3NDA4ODY4MA==&amp;mid=2653334228&amp;idx=1&amp;sn=8a106aed154ded89283146ddb6a02cf8&amp;chksm=f0cb5d53c7bcd445704592eb7c06407f1b18f1bf94bed3d33345d2443454b15f9c859b64371c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">无锁队列详细分解——Lock与Cache，到底有没有锁？</a></p><blockquote><p>其实现是多核在竞争对于内存的写的权利,ring bus的总线仲裁协议 裁决哪个赢得胜利 失败者 将自己的缓存中的值设置为失效然后获取新值</p></blockquote><p><a href="https://www.cnblogs.com/yanlong300/p/8986041.html" target="_blank" rel="noopener">MESI协议</a></p><blockquote><p>多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI<br>核心思想：CPU写数据时，如果发现操作的变量是共享变量，即在其他 CPU 中也存在该变量的副本，会发出信号通知其他 CPU 将该变量的缓存行置为无效状态，因此当其他 CPU 需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取</p></blockquote><ul><li>M 修改 (Modified):<ul><li>含义：该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。</li><li>监听任务：缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。</li></ul></li><li>E 独享、互斥 (Exclusive):<ul><li>含义：该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中</li><li>监听任务：缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。</li></ul></li><li>S 共享 (Shared):<ul><li>含义：该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中</li><li>监听任务：缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。</li></ul></li><li>I 无效 (Invalid):效<ul><li>含义：该Cache line无</li><li>监听任务：无</li></ul></li></ul><p>AQS：AbstractQueuedSynchronizer</p><blockquote><p><a href="https://blog.csdn.net/claram/article/details/83828768" target="_blank" rel="noopener">背景</a><br><a href="http://www.ideabuffer.cn/2017/03/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3AbstractQueuedSynchronizer%EF%BC%88%E4%B8%80%EF%BC%89/" target="_blank" rel="noopener">深入理解AbstractQueuedSynchronizer</a><br>AQS关键成员变量：head tail state exclusiveOwnerThread<br>关联 类 :ConditionObject LockSupport<br>继承类：Sync(FairSync UnFairSync) ReentrantLock</p></blockquote><p>CLH 双向链表：接本节点为Node(pre,next,Thread,state)</p><blockquote><p>lock.lock 调用sync.lock(sync.acquire(1)),试图获得锁,然后设置自己为锁的拥有线程(fair锁会在不存在等待队列前提下尝试获取锁,失败进入阻塞链表;非fair锁会尝试获取锁,失败后加入队列) ;同样利用CAS操作增加新节点<br>lock.unlock() 调用sync.release(1), 当前进程释放<br>condition.await() 将线程添加进链表,然后调用LockSupport.pack<br>condition.notify notifyAll 遍历链表 轮流 调用LockSupport.unpack 释放</p></blockquote><p>CAS 设置state 队尾<br>CountDownLatch ReentrantReadWriteLock</p><p>JUC下的类</p><p>serialization  transient<br>序列化过程中是把对象保存为一连串字节流,只保存了对象实例的变量部分,用处</p><ul><li>对象持久化</li><li>复制(本地多副本)</li><li>传输</li></ul><blockquote><p>serialization提供了一个非常棒的存储对象状态的机制，说白了serialization就是把对象的状态存储到硬盘上 去，等需要的时候就可以再把它读出来使用,可以在网络中传输;<br>而在于某些场合一些字段不希望在序列化,只保证在内存里,添加transient</p></blockquote><p>synchronized VS ReentrantLock</p><p>LockSupport是JDK中比较底层的类，用来创建锁和其他同步工具类的基本线程阻塞原语。java锁和同步器框架的核心AQS:AbstractQueuedSynchronizer，就是通过调用LockSupport.park()和LockSupport.unpark()实现线程的阻塞和唤醒的</p><p>ABA问题</p><p><a href="https://juejin.im/post/6844903903188746247" target="_blank" rel="noopener">AQS解析与实战</a></p><ul><li>state 状态的维护。</li><li>CLH队列</li><li>ConditionObject通知</li><li>模板方法设计模式</li><li>独占与共享模式。</li><li>自定义同步器。</li><li>AQS全家桶的一些延伸，如：ReentrantLock等</li></ul><p><a href="https://www.jianshu.com/p/fc51be7e5bc0" target="_blank" rel="noopener">thread join的使用和原理</a></p><p>泛型的类型擦除</p><p>AQS 定义了两种资源共享方式：</p><ol><li>Exclusive：独占，只有一个线程能执行，如ReentrantLock()</li><li>Share：共享，多个线程可以同时执行，如Semaphore、CountDownLatch、ReadWriteLock，CyclicBarrier</li></ol><p>AQS 原理</p><blockquote><p>双向队列</p></blockquote><p>节点状态<br>SIGNAL值为-1，后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，那么就会通知后继节点，让后继节点的线程能够运行<br>CONDITION值为-2，节点在等待队列中，节点线程等待在Condition上，不过当其他的线程对Condition调用了signal()方法后，该节点就会从等待队列转移到同步队列中，然后开始尝试对同步状态的获取<br>PROPAGATE值为-3，表示下一次的共享式同步状态获取将会无条件的被传播下去<br>CANCELLED值为1，由于超时或中断，该节点被取消。 节点进入该状态将不再变化。特别是具有取消节点的线程永远不会再次阻塞<br>INITIAL值为0，初始状态</p><p>condition  配合 lock 因为condition 的await 和 singal不是线程 安全的</p>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目</title>
      <link href="/2020/08/31/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E9%A1%B9%E7%9B%AE/"/>
      <url>/2020/08/31/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="nginx">Nginx</h2><p>主从模式<br>负载均衡</p><h2 id="kong-网关">Kong 网关</h2><h3 id="限流">限流</h3><p>目前 Kong网关 可以通过安装插件 基于 内存操作或者 redis 实现限流,但是不能实现集群内的分布式限流<br><a href="http://moguhu.com/article/detail?articleId=73" target="_blank" rel="noopener">分布式限流 参考1</a></p><ul><li>限流算法: 计数器,令牌桶算法,漏桶算法</li></ul><table><thead><tr><th>限流算法</th><th style="text-align:center">算法思想</th><th style="text-align:right">速率限制</th></tr></thead><tbody><tr><td>令牌桶</td><td style="text-align:center">以固定速率产生令牌,按照请求的字节数消耗令牌数,如果令牌不足,缓存或者拒绝请求</td><td style="text-align:right">限制了平均流入速度,允许一定程度的突发请求</td></tr><tr><td>漏桶</td><td style="text-align:center">以固定的速率流出水滴,按照请求的字节数增加水滴数,如果水滴数超过桶的容量,会导致请求拒绝</td><td style="text-align:right">限制了流出速度,可以用于平衡突发请求</td></tr></tbody></table><ul><li>限流方式: 限制总并发数(数据库连接池,线程池),限制瞬时并发数(Nginx 的limit_conn),限制总接口访问量,限制调用速率</li><li>分布式限流 : <a href="https://github.com/all4you/sentinel-tutorial" target="_blank" rel="noopener">Sentinel</a> 集群限流工具</li></ul><h2 id="oauth2认证和jwt机制">OAuth2认证和jwt机制</h2><ol start="7"><li><p>网关的作用：请求异步化</p></li><li><p>网格计算<br>分布式计算的一种,将计算任务分发到多个有计算资源的机器上,然后将他们计算的结果统一整理</p></li><li><p>mysql uuid 和自增id</p></li></ol><blockquote><p>在插入式 按照b+树,自增id 的插入是顺序,告诉快捷;而uuid是乱序的,可能需要从磁盘加载到缓存 产生随机IO,可能导致频繁的页分裂(以为新的行分配空间)<br>自增id的缺点:不安全,id有规律;高并发时涉及自增锁的争夺,影响效率;</p></blockquote><ol start="10"><li>LVS(linux virtual server)</li></ol><blockquote><p>LVS集群采用三层结构，其主要组成部分为：</p><ul><li>负载均衡调度器(load balancer)，它是整个集群对外面的前端机，负责将客户的请求发送到一组服务器上执行，而客户认为服务是来自一个IP地址(我们可称之为虚拟IP地址)上的。</li><li>服务器池(server pool)，是一组真正执行客户请求的服务器，执行的服务有WEB、MAIL、FTP和DNS等。</li><li>共享存储(shared storage)，它为服务器池提供一个共享的存储区，这样很容易使得服务器池拥有相同的内容，提供相同的服务。</li></ul></blockquote><p>分布式事务</p><blockquote><p>应用 微服务架构</p></blockquote><ul><li>2PC：Two-Phase Commit</li><li>3PC：Three-Phase Commit</li><li>TCC</li></ul><h3 id="2pc">2PC</h3><blockquote><p>两段式提交协议：将事务分为两个阶段来处理：准备阶段和提交阶段;<br>其中事务的发起者称之为协调者,事务的执行者称之为参与者<br>准备阶段：</p></blockquote><ul><li>事务询问：向各参与者发送事务预处理请求,等待回应</li><li>事务执行：各参与者在本地执行事物,写入undo和redo日志,但不会执行,并向协调者回复是否可以提交事务</li><li>协调者接收到各参与者回复,如果全是yes,那么事务可以执行,如果有一个no那么就无法执行事务<br>提交/执行阶段：</li><li>所有参与者返回YES<ul><li>协调者向所有参与者发送commit请求</li><li>事务提交：参与者收到commit请求,提交本地事务,并释放资源</li></ul></li><li>参与者至少有一个返回No,或者等待超时<ul><li>协调者向所有参与者发送滚回请求</li><li>事务回滚：各参与者接收到请求,回滚本地事务</li></ul></li></ul><p>不足</p><ul><li>性能问题:在第一第二阶段参与者协调者的资源都是锁住的,长时间得不到释放</li><li>单点故障:<ul><li>协调者正常,参与者宕机:<ul><li>后果：在第一阶段导致 协调者 阻塞,其他参与者无法释放资源;第二阶段 导致数据不一致</li><li>解决方案：针对第一个情况,在协调者端引入超时机制,超时则终止</li></ul></li><li>协调者宕机,参与者正常：<ul><li>后果：所有参与者执行事务单位提交,陷入阻塞;</li><li>解决：引入协调者备份,备份需要同步协调者记录;检测到宕机之后,取代协调者,继续操作;参与者引入超时机制,回滚业务并通知协调者</li></ul></li><li>协调者宕机和参与者部分宕机<ul><li>第一阶段:协调者备份检测超时并发出回滚指令</li><li>第二阶段未发送：协调者备份继续操作</li><li>第二阶段已发送：数据不一致</li></ul></li></ul></li></ul><h3 id="3pc">3PC</h3><blockquote><p>三阶段提交协议主要是为了解决二阶段的问题,主要有两个改进点</p><ul><li>在协调者和参与者中都引入超时机制：使得参与者可以在超时时释放自己的资源</li><li>增加canCommit阶段,确保段之前的个各参与者状态一致：<br>三阶段分为 canCommit preCommit doCommit</li></ul></blockquote><ul><li>canCommit:获取数据库脸解锁<ul><li>事务问询：协调者向参与者发送canCommit请求,询问是否可以提交事务</li><li>相应反馈：参与者接收到canCommit请求之后,认为自己可以执行事务则返回yes,否则no</li></ul></li><li>preCommit:都返回yes之后进入到类似2pc的准备阶段,但参与者引入了超时机制<ul><li>协调者向所有参与者发送事务预处理请求,等待回应</li><li>参与者接收到预处理请求,执行事务,并写入undo和redo日志,但未提交,并返回执行结果</li></ul></li><li>doCommit：都成功之后进入到类似于阶段3,否则发送回滚指令<ul><li>协调者向所有参与者发送commit请求</li><li>参与者接收到请求,提交事务,并返回ACK</li><li>协调者如果在时限内不能接收到所有参与者的ACK或返回No,那么向所有参与者发送abort指令要求回滚,参与者收到后执行并反馈</li></ul></li></ul><p>2PC VS 3PC</p><ul><li>优点:增加canComit和超时机制,降低阻塞的可能性;在最后阶段,避免了协调者单点故障,超时等待之后,会提交事务</li><li>缺点:在最后阶段,可能出现参与者不能接收到协调者的回滚指令而超时提交事务,导致 数据不一致</li></ul><p><a href="https://www.cnblogs.com/xybaby/p/7153755.html" target="_blank" rel="noopener">带着问题学习分布式系统之中心化复制集</a><br><a href="https://www.cnblogs.com/xybaby/p/10124083.html" target="_blank" rel="noopener">一文搞懂Raft算法</a></p><h3 id="raft">Raft</h3><p>raft是基于leader的共识算法,其目的在于提高分布式系统的容错性<br>raft协议主要有两个问题 集群选举以及日志复制问题</p><h4 id="集群选举">集群选举</h4><p>raft协议中,任意一个节点处于三种状态之一(leader,follower,candidate)<br>所有节点在最开始时都处于follower状态;在一段时间内没有收到leader的心跳,认为leader掉线,就会转换状态为candidate,开启选举</p><blockquote><p>选举开始条件:如果follower在election timeout时间内没有接到leader的心跳(leader 真挂了,leader follower之间网络断开,选举已经开始,还未选出leader),则主动发起选举</p></blockquote><ul><li>增加节点本地的current term,切换到candidate状态</li><li>投自己一票</li><li>发送给其他节点requestVote Rpcs,等其他节点回复<br>可能有3种结果</li><li>收到majority的票,赢得选举,成为leader</li><li>被告知别人已经当选,自动切换到follower</li><li>一段时间内没有收到majority的票,也没有收到别人当选的消息,则重新发起选举<br>作为投票者有以下约束：</li><li>在任一任期,只能投一次票且FCFS</li><li>被投票的节点知道的信息不能比投票者少(即日志更新)</li></ul><h4 id="日志复制">日志复制</h4><p>客户端的一切请求都发送到leader,leader调节这些请求的顺序,把这些请求和执行顺序告知follower,leader和follower以相同的顺序执行,保证状态一致性。</p><h3 id="paxos">Paxos:</h3><h3 id="mapreduce-过程">MapReduce 过程</h3><ul><li>提交任务 JobSubmitter.java</li><li>Jobtracker根据输入文件的大小,根据splitsize(128M)分割为若干个split,调度相应的task,由taskTracker监控和报告给jobtracker</li><li>每个split对应一个map任务,map.run函数会反复读取键值对 并根据key值获得&lt;key,value,partion&gt;写入缓冲区,缓冲区满则会触发spill,将缓冲区内的数据按照partition key sort 然后combiner 之后输出到磁盘<ul><li>默认对Key进行哈希运算后，再以ReduceTask数量取模(这样分配可能导致某个partition 数据较多的情况,可以随s个split间隔/随机/采样 n 个key,然后按照key排序,把可以分为n份,获得partition的分区依据<a href="http://bigdatadecode.club/MapReduce%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90--TotalOrderPartitioner.html" target="_blank" rel="noopener">TotalOrderPartitioner</a>)</li><li>环形缓冲区,输出起点-溢出点-下次输出点,一般溢出点占据80%</li><li>对应wordcount 就是每个单词对应一个key,value是1,之后快排(首先比较partition 然后比较key),然后相同key值合并,再输出到磁盘</li><li>当所有文件都输出到磁盘时,会触发merge,按照partition 和 key值排序 归并排序</li></ul></li><li>reduce端 与 AM(ApplicationMaster) 进行心跳通信获得map的数量和位置,通过fetch网络传输数据到缓存(看文件大小)或本地磁盘(缓存满之后出发spill写入磁盘);</li><li>所有数据到达后首先进行归并排序,然后调用combine 将相同key值的value合并,最终获得该partition 中key值的有序排列<ul><li>如果内存足够直接在内存中merge然后输出到磁盘</li><li>在写到磁盘之前可能会插入combine的过程,即对缓存内的数据提前进行combine减少后面的计算(在map端很多地方可以插入combine以减少之后输入的文件大小以及网络传输的数据大小);</li></ul></li><li>如果有多个reduce任务,这几个reducer任务还需要进行一次mapReduce<ul><li>由于这里的partition是hash然后求余,所以多个任务的reducer结果不一定是全局有序的;</li><li>所以对于分布比较均匀的key值,可以考虑类似哈希一致性算法的方法分配,在这里可以针对wordcount可以根据字符串的单位来分配partition,比如A-C属于partition0,需要把该规则告知全部map端 ;</li><li>对于不均匀分布的key值,这种仍然可能出现数据倾斜的问题,所以可以考虑采样的方法 最大程度获得整体数据的分布情况;</li></ul></li></ul><p>TCC：Try-Confirm-Cancel<br>JTA<br>RPC<br>代理模式<br>反射</p><p>微服务整体架构描述</p><p>Zab协议:Zookeeper Atomic Broadcast</p><blockquote></blockquote><p>Paxos 协议<br><a href="https://www.zhihu.com/question/19787937/answer/82340987" target="_blank" rel="noopener">参考1</a></p><blockquote><p>节点通信存在两种模型：共享内存(Shared memory)和消息传递(Messages passing)。Paxos算法就是一种基于消息传递模型的一致性算法<br>为什么要超过一半节点?保证两次事务一定有交叠<br>为什么第一阶段里提议者接收到已经accept的消息 会更改自己的提议值为该值,为了保持一致性<br>每个节点有三种角色,可以同时扮演多个角色</p><ul><li>Proposor:倡议者,可以提出倡议,以供表决</li><li>Acceptor:接受者,可以对按照一定规则对于倡议者提出的提议表决,有过半接受者接受的投票win</li><li>Learner:学习者无投票权,只能从Proposor获知那个提议被选中</li></ul></blockquote><p>目标：</p><ul><li>多个节点可以提出提议</li><li>系统必须针对多个提议中的某个达成一致,且最多只有一个</li><li>只要超过半数的节点存活且可以相互通信,那么整个系统一定能达成一致,即选择一个确定提议</li></ul><p>分为两个阶段<br>prepare 阶段</p><ul><li>proposor 向所有节点发送proposal,携带有当前 递增的prepareTimeStamp(PT) ,等待一半的节点回复(加上自己超过一半)<ul><li>前提:节点 本身保存三个参数 lastPrepareTimestamp(LPT),lastAcceptedTimeStamp(LAT),lastAcceptValue(LAV)</li><li>情况1:节点没有收到任何提议,即LPT为空,则设置该PT为LPT并response,同时不会再返回任何PT小于等于该LPT的提议</li><li>情况2:节点存在LPT,且LPT &gt;= PT,那么节点不回复(等待超时即可)</li><li>情况3:节点存在LPT且LPT &lt; PT,那么节点更新LPT,返回 之前的LPT 和LAT LAV</li></ul></li><li>proposor没有收到过半的回复,那么结束,收到则进行下一阶段</li></ul><p>accept 阶段</p><ul><li>节点收到了过半的回复,但是其中可能多个回复同时携带 LPT LAT LAV<ul><li>情况1:不存在回复携带LPT LAT LAV,那么该节点赢得胜利,可以向所有节点发送下一步(是上一次的节点)的值</li><li>情况2:存在回复带有 LPT LAT LAV ,那么从中找到LPT最大的那么的LAV作为自己的AV,然后广播</li></ul></li><li>如果接收到过半的回复,那么成功提交,告知学习者学习</li></ul><p>理解1：</p><blockquote><p>该协议的场景是多个平等节点间同时对一个值发起更改之后,需要确保值的一致性<br>可以确保值的一致性,但不能保证同一区间内的操作满足时间顺序</p></blockquote><p>PAXOS 活锁问题</p><blockquote><p>两个proposor在prepare阶段有交集,而他们反复抢夺交集的归属权,导致尝试-失败-尝试的循环<br>解决:在失败过后引入随机等待时间</p></blockquote><p>BASIC PAXOS<br>推导过程 详见参考1<br>首先起码分为两步走,第一步用于确认有一半以上的节点同意,其次才处于执行阶段</p><ol><li>单proposor 没有任何问题</li><li>2 proposor:可能会出现一个acceptor 接受了两个proposor的情况,所以要么阻止多个proposor发出,要么阻止acceptor接受<ul><li>阻止发出:那么必须需要通知到每个节点,要求比较高,难以保证每个节点都可以接收到;而且难以保证及时性</li><li>阻止接受:可以限定必须接收到一半以上的acceptor回复,那么必然两个 proposor 的acceptor 必然有交集,可以进一步限制只能接受一个proposor,同时需要保证第一步不能写入数据,否则会出现数据不一致的现象(类似于二阶段提交协议)<ul><li>首先限定proposor的占有规则,对于任何一个节点<ul><li>FCFS: 但是如果accept本身也是提议者即3个proposor,那么将永远达不成一致<ul><li>任何情况下的单纯一次性确定都会导致 2个以上proposor存在时,很大可能达不成一致 =&gt; 可修改</li><li>决定负责不应该包含局部的特性,不然无法比较,由全局的特性决定,使得节点能够加以区分和比较,保证全局最终结果的一致性 =&gt; 使用全局自增ID(或者 ip+本地时间)来比较</li></ul></li><li>最大者/最近者优先: 可能导致波动,对于ID_A &lt; ID_B 是否接受与到达顺序相关<ul><li>首先接收到ID_B 可以拒接ID_A</li><li>但可能出现节点依次接受并返回,导致出现在两个proposor那出现该节点同时同意的情况;即使在接受更大的之后,节点转而通知之前的节点,也不能保证一定到达以及在其进行第二阶段时到达</li></ul></li><li>最小者/最先者优先: 网络原因导致波动<ul><li>由于网络原因导致较小的慢到达,同样出现上述情况</li></ul></li><li>对于后两种情况,可能出现节点无法拒绝任何一个proposal的情况,所以可以协调两个proposal表现一致来达到一致性 =&gt; 最大者优先 + FCFS =&gt; <code>对于后来的预提案,只有其id大于已有ID才可以占有之,也不会接受小于该id 的提案,而且会反馈预提案拥有者 之前已接收的提案内容</code></li></ul></li><li>协调意味着两proposal只能选择一个proposal,更改一个proposal的值(如何更改?主动询问所有节点,耗时且增加环节带来的错误情况处理 或者 由该节点通知,即使收不到也被proposal视为不同意 无不良后果), 如何协调 ID_A &lt; ID_B 顺序访问情况下值的一直</li><li>定义占有规则:<code>对于节点,如果其首先接受了预提案,后续的预提案如果id小于现有的id,那么拒绝该提议,也拒绝小于该id的提案,如果大于它,那么接受该提议,同时告诉该提议者自己已经接受了的提案的信息(包括id以及value),而提议者接收到该信息会更新自己的value为反馈的proposal中 id 最大的那个的value; 这样可以保证新的提案与已经被接受的旧提案保持一致,需要证明的是为何选择最大的可以保证一致性</code><ul><li>证明：对于两个存在proposal A B到达执行阶段,那么那个交集的点必然是 小的ID先到,然后ID较大的到,所以较大的ID的提议者会修改自己value,保持最终值的一致性</li><li>如果超过3个proposal,假设对于反馈中的proposalA 和 proposalB 其中 IDA &lt; IDB,而两个提案都存在意味着两者在预提案阶段都接受到超过半数的同意反馈,那么两者必然有交集,对于交集中的节点S,其预提案的到来顺序必然是IDA IDB,如果到达时该节点接受提案,那么该节点会更新自己的id,拒绝后续较小的IDA的提案,如果已经接受,IDB发出的节点必然修改了自己的value为IDA的值,所以最终会保持一致性</li></ul></li><li>如果接受到大部分的acceptor,那么向这些acceptor发送提案,对于每个节点,如果接受的提案&gt;=本身的预提案id,那么可以接受它,同时更新该节点接受的id,并反馈</li><li>如果接受到了超过半数的acceptor回复,那么就说明该次提议完成并会发布消息到learner,告知学习(在论文中没有具体提及其角色,可以猜测起作用:广播禁止下一次对该key的proposal;更新其他节点的值)</li></ul></li><li>活锁(livelock)问题:不断有新的proposal在怕热proposal阶段 抢占节点,导致一直无法达成协议</li><li>多数读/写/<a href="https://blog.csdn.net/tb3039450/article/details/80249664" target="_blank" rel="noopener">Quorum机制</a>:写时节点的数+读时节点的数&gt;总节点的数,可以保证读到最新值;而设置写节点的数目为超过半数可以保证半数的节点宕机也可以保证服务的可用性</li></ul></li></ol><p><a href="http://oceanbase.org.cn/?p=111" target="_blank" rel="noopener">使用Multi-Paxos协议的日志同步与恢复</a><br>MUTLI PAXOS</p><ul><li>通过一轮 basic paxos 获得leader ,所以不需要pre阶段的一次rpc 因为 无人竞争<ul><li>由leader发布proposal 避免了活锁问题;</li><li>每个leader时期的proposalID是不变的,但是instanceId是变化的,由于每次只要求写入半数的节点可能导致空洞的出现</li></ul></li><li>由于网络等原因可以出现多leader的情况</li></ul><p><a href="http://blog.itpub.net/31509949/viewspace-2218253/" target="_blank" rel="noopener">ZAB</a></p><blockquote></blockquote><p><a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/Zab+vs.+Paxos" target="_blank" rel="noopener">ZAB VS PAXOS</a><br>相同点：</p><ul><li>由leader发布提案 follower接受,然后等待法定人数的认可之后通知learner</li><li>同一个leader的提案共享一个proposalID但是instanceID不同(标识该leader提议的key值次数)</li></ul><p>不同：ZAB目的在于实现高可用的分布式数据库(主从模式),而paxos目的在于构建一个分布式一致的状态机系统</p><ul><li>multi-PAXOS有两个阶段选举和执行事务,而ZAB在两个阶段之间插入恢复阶段,目的在于使follower节点与leader节点的数据保持一致</li></ul><h2 id="tencent-data-wire">Tencent Data Wire</h2><p>TDW是腾讯最大的离线数据处理平台<br>TDW 是基于Hadoop和Spark 构建,<br><a href="http://www.ha97.com/5665.html" target="_blank" rel="noopener">参考1</a><br><a href="https://cloud.tencent.com/developer/article/1029640" target="_blank" rel="noopener">参考2</a></p><h3 id="反射">反射</h3><p>反射允许动态的根据类名去获取class对象,并且实例化并调用其方法和对象(甚至更改对象的访问权限)<br>其原理是根据class对象的读取,javac编译后 的文件包括 构造函数以及成员函数成员变量<br>class.forName 默认由所在类的加载器去加载该class<br>getConstructor<br>getMethod(变量类型)<br>method.invoke(instance,参数)</p><p>为什么反射会比new慢</p><ul><li>method.invoke 的参数是可变参数(编译时会将参数封装进object数组,涉及赋值操作)</li><li>object数组中不能存储基本变量,涉及自动装箱机制</li></ul><h3 id="rpc">RPC</h3><h4 id="rpc-vs-http">RPC VS HTTP</h4><p>优点：</p><ol><li>传输效率高(二进制传输效率)</li><li>调用方向调用本地方法一样调用,无需关心实现<br>缺点：</li></ol><ul><li>通用性不如HTTP好(因而rpc一般用于内部服务之间的通信调用,http一般用于跨服务的调用)</li></ul><p>过程：</p><ol><li>客户端(client)以本地调用的方法发起调用</li><li>客户端桩(client stub) 收到调用,负责 将调用的方法参数等必要信息序列化(压缩打包)传输,将之发送给服务端</li><li>服务端桩(server stub) 接收到网络数据,反序列化,获取方法名和参数等必要信息</li><li>服务器桩根据方法名和参数进行本地调用</li><li>服务端执行调用返回结果给服务器桩</li><li>服务器桩接收到结果,序列化,传输给客户端</li><li>客户端桩接收到信息,反序列化,解析返回给客户端</li><li>客户端获得调用结果</li></ol><p>核心：</p><ol><li>消息协议(以下是RPC 二进制协议中的,http中包括XML和Json)<ul><li>Protobuf</li><li>Avro</li></ul></li><li>传输机制：基于tcp协议的可靠性,使用tcp传输数据<ul><li>服务端 建立socket 监听</li><li>客户端 建立socket 连接服务端,通过3次TCP握手建立连接,然后可以传输数据</li></ul></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>后端</title>
      <link href="/2020/08/31/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E5%90%8E%E7%AB%AF/"/>
      <url>/2020/08/31/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E5%90%8E%E7%AB%AF/</url>
      
        <content type="html"><![CDATA[<ol><li>后端优化的路径</li></ol><ul><li>服务器 硬件资源升级</li><li>缓存化</li><li>sql优化(分库分表),逻辑优化</li><li>服务化(拆分服务)</li><li>异步化请求</li></ul><ol start="2"><li>HTTP</li></ol><ul><li>GET: 获取信息,幂等操作</li><li>POST：修改资源,非幂等操作</li><li>PUT：新建资源,幂等操作,重复操作直接替换资源</li><li>DELETE：删除资源</li></ul><ol start="3"><li>LRU算法的实现</li></ol><ul><li>链表操作:新建以及再访问 移动到 头部</li><li>基于时间戳的比较</li></ul><ol start="4"><li>CPU 私用率过高</li></ol><ul><li>io使用率？内存利用率？<ul><li>文件操作 频繁GC? jstat -gc 进程ID 间隔时间  java -XX:+PrintGCDeatils</li></ul></li><li>纯后端服务还是Web服务<ul><li>是否陷入计算部分</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>腾讯 求职</title>
      <link href="/2020/08/30/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E8%85%BE%E8%AE%AF/"/>
      <url>/2020/08/30/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E8%85%BE%E8%AE%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="后台面试参考流程-上">后台面试参考流程-上</h1><h2 id="编程语言">编程语言</h2><ul><li><p>C++</p><ol><li>static 关键字有哪些用法？</li><li>继承层次中,为什么基类析构函数是虚函数？</li><li>重载overload、覆盖重写override、隐藏重定义overwrite 的区别：</li></ol><blockquote><p>overload：同名 不同参数的函数,多态<br>override: 重写父类的方法<br>overwrite：实现abstract 方法或者接口</p></blockquote><ol start="4"><li>多态和泛型的实现原理？<a href="https://developer.aliyun.com/article/138749" target="_blank" rel="noopener">参考</a></li></ol><blockquote><p>泛型:其本质是参数化类型,多态:模糊子类和父类的关联,是的同一个行为有不同的表现<br>泛型的应用:<code>Map&lt;String,String&gt;等</code>,保证 类型安全,消除强制类型转换<br>实现原理:泛型是在编译 阶段进行 将泛型,替换成实际类型,而多态是在实际运行阶段 实现类型替换</p></blockquote><ol start="5"><li>stl的 map/vector 实现场景,迭代器 失效场景?</li></ol></li></ul><h2 id="linux-开发">Linux 开发</h2><ol><li>程序出问题时的解决思路?使用哪些调试工具? 比如gdb/valgrind/strace/tcpdump</li></ol><blockquote><p>整体思路：问题类型单个接口错误(查询log),普遍接口错误(全局配置/公共模块问题,权限问题),服务崩溃(服务器问题,资源不足？),延迟大(的确资源不足,死循环)<br>日志,/proc 下 或top命令 观察进程的内存延迟CPU等资源的使用情况,或者可以使用gdb工具调试c++程序</p></blockquote><ol start="2"><li>有哪些工具可以找到性能瓶颈?</li></ol><blockquote><p>Jmeter 压测机 发出请求<br>工具1:Java Mission Control,其核心 是 Java Flight 记录器,一个内置在 JDK 中的监测和事件收集框架。收集的事件包括：磁盘 IO、GC、线程 sleep、线程 wait、Socket read/write 等,可以从不同角度更好分析当前进程运行情况<br>工具2:Tprofiler,淘宝开源工具,在 JVM 启动时把时间采集程序注入到字节码中,整个过程无需修改应用源码，可以配置采样评率去降低影响</p></blockquote><ol start="3"><li>了解vmstat/iostat/netstat/mpstat吗？用来作什么？</li></ol><blockquote><p>top:能够实时监控系统的运行状态，并且可以按照cpu、内存和执行时间进行排序,也可以显示整个系统的资源现状<br>free:监控系统内存最常用的命令,包含 总内存大小,已用,共享内存大小,磁盘缓存大小等<br>ps： 查询进程信息,启动者,父进程,启动命令,启动时长等信息<br>vmstat:监控操作系统的进程状态、内存、虚拟内存、磁盘IO、上下文、CPU的信息。<br>iostat:是对系统磁盘IO操作进行监控，它的输出主要显示磁盘的读写操作的统计信息<br>netstat:用于显示本机网络链接、运行端口、路由表等信息<br>mpstat可以监控到cpu的一些统计信息，在多核cpu的系统里不但能够查看所有cpu的平均状况信息，而且能够查看特定的cpu的信息</p></blockquote><h2 id="网络">网络</h2><ol><li>select/epoll的区别？</li></ol><blockquote><p>简单理解：当进程进行IO调用时，select poll 都把该进程挂在该设备的等待队列后，然后遍历等待队列，直至发现就绪，区别在于select使用数组来存储文件描述符，因而长度有限，而poll使用链表存储，因而没有这个限制;而epoll将状态分离开来，单独分出一个就绪队列，每次遍历这个就绪队列，然后根据队列中的信息进行下一步</p></blockquote><ol start="2"><li><p>epoll 的ET 和 LT的区别？<br>边缘触发(Edge Trigger)和水平触发也叫条件触发(Level Trigger)<br>边缘触发 是指每当状态变化时发生一个io事件；<br>条件触发 是只要满足条件就发生一个io事件；<br>LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作，而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无 论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者 遇到EAGAIN错误</p></li><li><p>epoll 如何区分 connect/close/read/write 事件?</p></li><li><p>TCP 的流量控制和阻塞控制有什么区别？描述下慢启动/拥塞避免/快速恢复/快速重传?</p></li></ol><blockquote><p>流量控制的目的在于控制发送发的速率,使得接收方可以及时接收;通过确认报文照片中的窗口字段和滑动窗口机制控制发送方的速率<br>拥塞控制的目的在于防止过多的数据注入到网络中，这样可以使网络中的路由器或链路过载(拥塞会导致发送失败,失败方会重新发送,加剧了拥塞程度);拥塞控制有四种算法:慢开始,拥塞避免,快重传和快恢复算法<br>接收方总是有足够大的缓存空间，因而发送窗口的大小由网络的拥塞程度决定<br>慢开始:令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将cwnd加倍<br>拥塞避免: 当cwnd &gt;= 慢开始门限值,执行该算法,每一次ACK,cwnd+1(当网络超时时,令ssthresh=cwnd/2,同时设置拥塞窗口cwnd=1.进入慢开始算法)<br>快重传:要求接收方不要等待自己发送数据才进行捎带确认，而是立即发送确认;即使收到失序的报文段对已发送的报文段的重复确认。发送方一连收到3个重复确认就应当立即进行重传。在这种情况下，只是丢失个别报文段，而不是网络拥塞。从而执行快恢复<br>快速恢复: 发送方调整门限值ssthresh =cwnd/2，同时设置拥塞窗口cwnd=ssthresh ，并开始拥塞避免算法</p></blockquote><ol start="5"><li>TIME_WAIT,CLOSE_WAIT 产生的原因和解决方案?</li></ol><blockquote></blockquote><ol start="6"><li>HTTPS 的工作原理？</li></ol><blockquote><p><a href="http://www.httpclient.cn/archives/59.html" target="_blank" rel="noopener">参考网站1</a><br>HTTPS:Hyper Text Transfer Protocol over SecureSocket Laye<br>动机：认证正在访问的网站(CA证书);保证所传输数据的私密性和完整性<br>HTTPS 在内容传输的加密上使用的是对称加密，非对称加密只作用在证书验证阶段(非对称加密安全但是耗时)<br>工作流程:</p></blockquote><ul><li>认证服务器：浏览器内置受信任的CA机构列表以及相应机构的证书,如果认证服务端合理,就可以从 服务端或者到 <code>公钥</code></li><li>协商会话秘钥：浏览器通过公钥 和服务端 协商(非对称加密) 获取 加密 服务端-客户端 和 客户端-服务端 的两个会话秘钥(与会话相关)</li><li>加密通讯:通过对称加密 加密数据,保证安全和效率</li></ul><ol start="7"><li><p>网关的作用：请求异步化</p></li><li><p>网格计算<br>分布式计算的一种,将计算任务分发到多个有计算资源的机器上,然后将他们计算的结果统一整理</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 后台开发 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工具网站</title>
      <link href="/2020/08/29/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%B7%A5%E5%85%B7%E7%BD%91%E7%AB%99/"/>
      <url>/2020/08/29/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%B7%A5%E5%85%B7%E7%BD%91%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<p>latex：</p><ul><li><a href="https://www.overleaf.com/" target="_blank" rel="noopener">latex 在线编辑和导出</a></li><li><a href="https://www.tablesgenerator.com/latex_tables" target="_blank" rel="noopener">latex table在线编辑和转换</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>数据库</title>
      <link href="/2020/08/28/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>/2020/08/28/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<h1 id="数据库">数据库</h1><h2 id="reids">Reids</h2><p><a href="http://redisbook.com/preview/dict/incremental_rehashing.html" target="_blank" rel="noopener">参考1</a><br><a href="https://zhuanlan.zhihu.com/p/112944545" target="_blank" rel="noopener">参考2</a></p><h3 id="基础数据类型">基础数据类型：</h3><blockquote><p>string，hash，list，set及有序集合（每个元素都关联一个分数，通过分数排序）</p></blockquote><ul><li>string(len,free,char[]):用于计数</li><li>list：双向链表,随机定位性能较弱，首尾插入删除性能较优</li><li>hash:数组+单链表 hash扩容时使用渐进式的rehash(一个hash结构有两个hash表ht[0]ht[1] ht[1]用于渐进式rehashAB类似于GC里的两个survivor区):较小时使用ziplist 较多采用hashmap<ul><li>在出现哈希冲突时,使用链地址法解决;处于效率考虑,新节点的加入使用头插法</li><li>扩容A,首先分配rehash之后的空间结构B,其每次对于</li></ul></li><li>set:无序集合</li><li>sortset:链表(value score 的Node)+跳表(log2级索引;二分查找) 对于范围查询，跳表更加高效</li></ul><p>intset</p><h4 id="实现原理">实现原理</h4><p>dict实现原理</p><blockquote><p>基于哈希表的算法，采用拉链法解决冲突，并在装载因子超过预定值时自动扩展，引发重哈希</p></blockquote><p>SDS:Simple Dynamic String</p><blockquote><p>string(len,free,char[])</p></blockquote><p><a href="https://blog.liexing.me/2019/12/28/from-ziplist-linkedlist-to-quicklist/" target="_blank" rel="noopener">ziplist linkedList quickList</a></p><ul><li>ziplist充分利用空间,将list数据相邻的存储,利用数据结构实现前后节点的遍历(因为是紧挨着所以需要很多字段能够准备读后前后街店的值 对于任何一个可变字段都需要增加标记他长度的字段),但是插入删除的时间消耗比较大,所以一般用于比较少的list数据</li><li>对于较长的数据使用linkedlist,删除成本低但是空间碎片多</li><li>quickList把ziplist封装为其Node,然后以此为节点,构建LinkedList,综合linkedList和zilist的节约内存以及删除数据高效的特点(quickList配合有压缩和解压缩的能力,删除时进行解压缩和压缩;新插入节点也会如此判断,否则重新创建Node)</li></ul><p><a href="https://www.cyningsun.com/06-18-2018/skiplist.html#%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E5%B1%82%E6%95%B0%EF%BC%9F" target="_blank" rel="noopener">skipList</a></p><ul><li>定义基于单链表,在Node的结构中增加Node指针的数组,其长度可以称为层数;有越Log(N)的效率</li><li>层数：其范围[1-maxvalue],当每次获取的random值大于p时,层数+1,并继续,否则层数确定(这样确保了高层数的分布不会很高)</li><li>插入：例如插入E,按照已有跳表查询,在查询中所有经过A-B-C-D找到F节点大于E,那么判断中间经历的所有节点ABCD的value如果小于它且其层数小于等于他,那么就需要指向它,同时他的更高层也要更新指向</li><li>删除：例如删除E,同样先经过跳表查询,可以获得E每层的下一个Node,更新遍历过程中相应的节点</li><li>为什么不使用红黑树<ol><li>内存不敏感,可以通过降低P来降低内存需求</li><li>可以用于范围查询</li><li>容易实现(相比较于b+树等,无需负责的平衡操作就可以实现LOGN的复杂度)</li></ol></li></ul><p>hash 当容量和值比较小时使用ziplist,节省空间;增大时改用dict</p><h3 id="redis持久化">Redis持久化：</h3><blockquote><p>持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失<br>两种持久化方式:RDB（Redis DataBase；默认；定期备份；把内存中数据写到磁盘以及把文件读到内存；制定的时间间隔生成数据集的快） 和AOF(Append-only file;写入保存两个步骤；WRITE：根据条件，将 aof_buf 中的缓存写入到 AOF 文件 ；SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。持久化记录服务器执行的所有写命令到日志文件，并在服务器重启时，重新执行这些命令来恢复数据)</p><blockquote><p>两种区别就是，一个是平时写操作的时候不触发写，只有手动提交save命令，或者是关闭命令时，才触发备份操作。一个是持续的用日志记录写操作，crash后利用日志恢复；<br>选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。</p></blockquote></blockquote><blockquote><p>快照的设置:设置redis.conf save 900 1(900秒内 1个key被修改 快照);  dbfilename dump.rdb; dir /opt/redis;  appendonly no</p></blockquote><h3 id="过期策略定期删除惰性删除内存淘汰机制">过期策略：定期删除+惰性删除+内存淘汰机制</h3><blockquote><p>定期删除：redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除<br>惰性删除：当访问key时，检测key是否过期，过期则不返回<br>内存淘汰机制：当内存不足以写入新数据时，什么都不做，写入报错/移除随机key/移除最近最少使用的key/随机（或者选择最先过期 ）移除有过期时间的key/移除有过期的key中最近最少使用的/</p></blockquote><h3 id="redis的架构模式">Redis的架构模式</h3><blockquote><p>单机版（存储，处理有限，无法高可用）<br>主从复制（读写分离；更新同步；但是master写的压力存在，高可用不行）<br>哨兵（监控主从模式，遇到故障自动迁移；解决高可用，但master写仍存在）<br>集群（proxy 型）：利用哈希进行数据分布，分布到多个主从集群+哨兵<br>集群（直连型）：</p><blockquote><p>集群（直连型）:<a href="https://blog.csdn.net/z15732621582/article/details/79121213" target="_blank" rel="noopener">简介</a>  和 <a href="https://www.cnblogs.com/lpfuture/p/5796398.html" target="_blank" rel="noopener">一致性Hash算法</a><br>Redis集群预分好16384个桶，当需要在 Redis 集群中放置一个 key-value 时，根据 CRC16(key) mod 16384的值，决定将一个key放到哪个桶中<br>节点的fail是通过集群中超过半数的节点检测失效时才生效</p></blockquote></blockquote><h3 id="相关概念">相关概念</h3><h4 id="缓存雪崩">缓存雪崩</h4><blockquote><p>描述：大量相同过期时间的缓存，同时失效，导致大量的并发访问失败并访问磁盘；<br>解决：使用加锁（ 最多的解决方案）或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写</p></blockquote><h4 id="缓存穿透">缓存穿透</h4><blockquote><p>描述：用户在查询一个持久层数据库也没有的数据时，会出现缓存未命中，且访问持久层无果的情况，大量这种类型的访问会给持久层数据库带来很大压力<br>解决：利用布隆过滤器判断对象是否一定不存在；缓存空对象</p></blockquote><h4 id="缓存击穿">缓存击穿</h4><blockquote><p>描述；指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞<br>解决：定时更新;多级缓存;失效时使用互斥锁,限制对于数据库的访问</p></blockquote><h4 id="缓存预热">缓存预热</h4><blockquote><p>描述：相关的缓存数据直接加载到缓存系</p></blockquote><h4 id="缓存更新">缓存更新</h4><blockquote><p>除了缓存失效策略（定义失效时间）外，还有定时去清理过期的缓存策略（判断是否失效）以及访问时才判断是否失效</p></blockquote><h4 id="缓存降级">缓存降级</h4><blockquote><p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级，保证核心服务可用</p></blockquote><h4 id="热点数据和冷数据">热点数据和冷数据：</h4><blockquote><p>频繁访问修改的数据称之为热点数据；冷数据指访问间隔很长的数据（出现只访问一次，就被挤出内存的情况）</p></blockquote><h4 id="单线程的redis为什么这么快">单线程的redis为什么这么快</h4><blockquote><p>纯内存操作<br>单线程操作，避免了频繁的上下文切换<br>采用了非阻塞I/O多路复用机制 epoll</p></blockquote><h4 id="redis到底是多线程还是单线程">Redis到底是多线程还是单线程</h4><blockquote><p>单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程,基于IO多路复用</p></blockquote><h4 id="redis关于线程安全问题">Redis关于线程安全问题</h4><blockquote><p>Redis实际上是采用了线程封闭的观念，把任务封闭在一个线程，自然避免了线程安全问题，不过对于需要依赖多个redis操作的复合操作来说，依然需要锁，而且有可能是分布式锁。</p></blockquote><h4 id="redis-内部实现">Redis 内部实现</h4><blockquote><p>内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间 这3个条件不是相互独立的，特别是第一条，如果请求都是耗时的，采用单线程吞吐量及性能可想而知了。应该说redis为特殊的场景选择了合适的技术方案。</p></blockquote><h4 id="memcache-vs-redis">Memcache VS Redis</h4><blockquote><p>(1)存储方式 ：Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，redis可以持久化其数据<br><br>(2)数据支持类型 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 ，提供list，set，zset，hash等数据结构的存储<br><br>(3)使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。<br><br>(4)value 值大小不同：Redis 最大可以达到 512M；memcache 只有 1mb。<br><br>(5)redis的速度比memcached快很多<br><br>(6)Redis支持数据的备份，即master-slave模式的数据备份。<br><br>Redis key和value的大小限制：512MB</p></blockquote><h4 id="redis数据库的数据一致性">Redis数据库的数据一致性</h4><blockquote><p>主从同步：从服务器启动，会向主服务器发起sync命令；主服务器收到后会在后台保存快照（RDB操作），并缓存保存期间的命令；结束后，会将快照和缓存命令传递给从数据库，从数据库接收到后，会载入快照并执行缓存命令；</p><p>哈希槽算法：与一致性哈希算法相似，一个节点根据其存储量，分为若干个槽<br>一致性哈希算法：在0-2^32-1的哈希环,将已有的机器根据ip等因素hash到某个位置,把哈希环 分割成好几块,每个机器负责一块的数据,这样机器数量的变化(宕机或者新增只会影响一部分数据),同时可以是用虚拟主机的方法,解决数据倾向存储在某一个机器的问题.<br>全量复制，增量复制，异步复制</p></blockquote><h4 id="哨兵模式"><a href="https://blog.csdn.net/sz85850597/article/details/86751215" target="_blank" rel="noopener">哨兵模式</a></h4><blockquote><p>主观下线-&gt;客观下线<br>sential leader 选举：当每一个发现redis master 的sential节点都可以向其他节点发送选举信号，每个接收到该信号的节点如果没有投票，可以投它，当达到最低票数时，正式成为sential leader；否则进行下一轮；<br>redis master 选举：由 sential leader 选择redis集群中的某个节点作为master</p><blockquote><p>a.排除故障节点</p></blockquote><blockquote><p>b.选择节点中slave-priority最大的从节点作为主节点</p></blockquote><blockquote><p>c.选择择复制偏移量（数据写入量的字节，记录写了多少数据。主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步）最大的从节点作为主节点</p></blockquote><blockquote><p>d.选择runid（redis每次启动的时候生成随机的runid作为redis的标识）最小的从节点作为主节点</p></blockquote></blockquote><h4 id="redis-集群选举">redis <a href="https://www.cnblogs.com/nijunyang/p/12508098.html" target="_blank" rel="noopener">集群选举</a></h4><blockquote><p>背景：利用hash桶算法进行数据的分隔布置到多个主从模式服务器去<br>选举：slave发现master Fail之后，就尝试选举</p><blockquote><p>a.增加currentEpoch加1，并广播FAILOVER_AUTH_REQUEST信息</p></blockquote><blockquote><p>b.收到信息的Master节点会判断请求者的合法性，并发&gt;送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack</p></blockquote><blockquote><p>c.尝试failover的slave收集FAILOVER_AUTH_ACK;超过半数后变成新Master;广播Pong通知其他集群节点</p></blockquote></blockquote><h2 id="mysql">Mysql</h2><h3 id="事务的基本要素">事务的基本要素</h3><blockquote><p>原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。<br><br>一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏。<br><br>隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。<br><br>持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚</p></blockquote><h3 id="事务的并发问题">事务的并发问题</h3><blockquote><p>脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据<br><br>不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。<br><br>丢失修改：两个事务AB修改顺序颠倒,A后发先修改,A的修改被B的修改覆盖,导致修改丢失<br><br>幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读.<br><br>小结：不可重复读和脏读是由于读取了未提交事务的修改的数据,一读一写;丢失修改和幻读则是修改了事务间的共同数据,双写;<br><br>不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。<br><br>解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表<br></p></blockquote><h3 id="事物隔离级别">事物隔离级别</h3><p>| 事务隔离级别  | 脏读  | 不可重复  | 幻读 |方法<br>| :----- | -----: | -----: | -----: |<br>|   读未提交（read-uncommitted）    | 是      |  是     | 是      |<br>|    读已提交（read-committed）   |   否    | 是     | 是 |<br>|    可重复读（默认，repeatable-read）   | 否  |否 | 是 |<br>|    串行化（serializable）    |   否    | 否 |否 |   每个事务依次提交(SELECT变成SELECT … LOCK IN SHARE MODE)</p><h3 id="存储引擎">存储引擎</h3><blockquote><p><a href="https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10409517059295814828%22%7D&amp;n_type=1&amp;p_from=4" target="_blank" rel="noopener">参考</a><br>存储引擎是数据库管理系统用来从数据库创建、读取和更新数据的软件模块<br>mysql5.5之后默认使用事务性存储引擎 InnoDB(这是MySQL 5.5或更高版本的默认存储引擎。它提供了事务安全(ACID兼容)表，支持外键引用完整性约束。它支持提交、回滚和紧急恢复功能来保护数据。它还支持行级锁定。当在多用户环境中使用时，它的“一致非锁定读取”提高了性能。它将数据存储在集群索引中，从而减少了基于主键的查询的I/O)</p></blockquote><h4 id="innodb">InnoDB</h4><blockquote><p>在 InnoDB 存储引擎中，所有的数据都被逻辑地存放在表空间中，表空间（tablespace）是存储引擎中最高的存储逻辑单位，在表空间的下面又包括段（segment）、区（extent）、页（page）<br><br>MySQL 使用 InnoDB 存储表时，会将表的定义和数据索引等信息分开存储，其中前者存储在 .frm文件中，后者存储在 .ibd 文件中<br></p></blockquote><h3 id="索引">索引</h3><blockquote><p>索引优化是对查询性能优化的最有效手段<br>在关系数据库中，索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，它是某个表中一列或若干列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单<br>InnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，这是关系型数据库中查找最为常用和有效的索引</p></blockquote><blockquote><p>一张表一定包含一个聚集索引构成的 B+ 树以及若干辅助索引的构成的 B+ 树（辅助索引的存在并不会影响聚集索引，因为聚集索引构成的 B+ 树是数据实际存储的形式，而辅助索引只用于加速数据的查找，所以一张表上往往有多个辅助索引以此来提升数据库的性能。）</p></blockquote><h4 id="mysql-索引分类">mysql 索引分类</h4><p>b+树索引 hash索引</p><blockquote><p>主键索引：以唯一能够标识记录中某一行的属性或者属性组 作为唯一索引,不为空<br>唯一索引：唯一索引的值必须唯一,但允许有空值(NULL代表未知,不违反唯一性约束);对于组合索引,组合必须唯一<br>普通索引：普通的索引用于加快访问速度,其根节点指向主键<br>全文索引：某些字符串类型字段的倒排索引(映射单词和所在文档的位置)<a href="https://www.cnblogs.com/wxzhe/p/9955534.html" target="_blank" rel="noopener">全文索引的原理及定义</a></p></blockquote><p>主键索引 VS 唯一索引</p><blockquote><p>主键索引必然是唯一索引,唯一索引不一定是主键索引;<br>主键不允许空,唯一索引允许<br>主键可以作为外键存在,而唯一索引不行<br>对于一张表来说,主键索引只有一个,唯一索引可以有多个</p></blockquote><p>主键索引的插入和删除可能会造成页的分裂和合并,进而导致索引的更改,所以一般建议使用自增ID作为主键</p><p>唯一索引的用处:</p><blockquote><p>确保属性值唯一,比如对于网站而言,利用手机号,邮箱注册账号,必然希望其唯一<br>唯一索引在插入时会检验是否出现重复,仍然基于B+树实现判断,但是对于NULL值特殊处理直接返回false</p></blockquote><h4 id="冗余索引">冗余索引</h4><blockquote><p>冗余索引指索引的功能相同,两者都可以被命中, 比如索引<a>与<a b> 冗余</a></a></p></blockquote><h4 id="聚集索引-和-辅助索引-聚簇索引-和非聚簇索引">聚集索引  和  辅助索引 /聚簇索引 和非聚簇索引</h4><blockquote><p>聚合索引可以理解为基于主键的索引，数据行的物理顺序与列值（一般是主键的那一列）的逻辑顺序相同，一个表中只能拥有一个聚集索引,其叶子节点是数据节点；而附注索引是对于其他键的索引，最终叶子节点内容为指向数据块的引；<br><br>主键(指定主键或者选择费控的合适键或者隐藏键uuid)<br>聚簇索引即值按照表的主键构建一颗b+树,同时叶子节点中存放的是id和表的行记录在数据页中的索引;这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引<br>Innodb通过主键聚集数据，如果没有定义主键，innodb会选择非空的唯一索引代替。如果没有这样的索引，innodb会隐式的定义一个主键来作为聚簇索引<br>聚簇索引的优点：</p></blockquote><ul><li>数据访问更快,因为聚簇索引将索引和数据保存在同一个B+树中</li><li>聚簇索引对于主键的排序查找和范围查找速度非常快<br>缺点:</li><li>插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键</li><li>更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。</li><li>二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据</li></ul><p>辅助索引：</p><blockquote><p>在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找。辅助索引叶子节点存储的不再是行的物理位置，而是主键值</p></blockquote><h4 id="回表-索引覆盖-复合索引-索引下推">回表 索引覆盖 复合索引 索引下推</h4><blockquote><p>回表查询，先定位主键值，再定位行记录，它的性能较扫一遍索引树更低<br>索引覆盖:当所需要的结果都在索引上时,就可以一次查询得到结果<br>索引下推：index condition pushdown/IPC：在使用IPC的情况下,对于某些查询只能命中索引前部分,同时涉及后部分的判断条件时,mysql server 同时会将判断条件传递给存储引擎,然后存储引擎在检索的同时判断,返回结果(比如对于SELECT * from user where  name like ‘陈%’ and age=20 能够命中索引&lt;name,age&gt;的name 部分 使用IPC可以同时传递条件)<br>两个或更多个列上的索引被称作复合索引，最左匹配原则，键&gt;=2</p></blockquote><h3 id="数据库主从同步">数据库主从同步</h3><blockquote><p><a href="https://www.cnblogs.com/syncnavigator/p/10189597.html" target="_blank" rel="noopener">流程参考</a><br>首先必须打开master端的binlog (mysql-bin.xxxxxx)日志功能，否则无法实现mysql的主从复制。因为mysql的整个主从复制过程实际上就是：slave端从 master端获取binlog日志，然后再在自己身上完全顺序的执行该日志中所记录的各种SQL操作</p><ol><li>master在执行sql之后,将数据改变记录二进制log文件(bin-log)</li><li>Slave 的IO进程连接上master,并请求同步指定的日志文件的指定位置之后的记录</li></ol><ul><li>master 端接受到io请求后,负责复制的io进程会返回数据给slave的io进程,也包含binlog的位置以及本次数据其中的位置,方便下次继续</li><li>slave接受到数据后会追加到slave的relay log末端,并记录master端binlog文件的路径和文件内位置记录到master_info中,已便下次可以清晰告知master从哪里开始</li></ul><ol start="3"><li>slave端 的sql进程检测到relay文件的变动会解析文件执行master端已经执行的操作</li></ol><blockquote><p>2.slave连接master，并从master获取binlog，存于本地relay-log中，然后从上次记住的位置起执行SQL语句，一旦遇到错误则停止同步。</p></blockquote></blockquote><h3 id="数据一致性">数据一致性</h3><p><a href="https://www.jianshu.com/p/790a158d9eb3" target="_blank" rel="noopener">参考链接</a></p><blockquote><p>三种同步写模式：异步复制、半同步复制、全同步复制<br>异步复制:Mysql 默认同步模式,主库在执行完客户端提交的事物之后会直接将结果返回给客户端,不管 从库是否接收同步并成功处理,在这种情况下,主库如果crash掉,从库提升为主库,那么可能出现从库数据不完备的现象<br>半同步复制:在前者的基础上要求 至少一个从库同步成功,才会将保存在binlog中的操作,提交到存储引擎,返回结果给客户端<br>全同步复制:在异步复制的基础上,要求 所有从库 都同步成功,才真正执行事物，返回给客户端<br>相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。<br>半同步复制和全同步复制 可能会出现 从库执行成功而 主库 执行失败的情况，导致 数据不一致</p></blockquote><h3 id="mvcc">MVCC</h3><p><a href="https://blog.csdn.net/Waves___/article/details/105295060" target="_blank" rel="noopener">参考0</a><br><a href="https://juejin.im/post/6847902218729816071" target="_blank" rel="noopener">参考1</a><br><a href="https://blog.csdn.net/whoamiyang/article/details/51901888" target="_blank" rel="noopener">参考2</a><br><a href="https://blog.csdn.net/Oooo_mumuxi/article/details/105766335" target="_blank" rel="noopener">参考3</a><br><a href="https://blog.csdn.net/weixin_41835916/article/details/81633072" target="_blank" rel="noopener">参考博客1</a><br>基于乐观锁的思想,通过MVCC 解决了读写并发的问题的问题;<br>Innodb在行记录的添加了隐藏字段,其中包括</p><ul><li>修改记录的事务ID(DB_TRX_ID:insert/update/delete)</li><li>回滚指针：指向当前记录行的undo log(DB_ROLL_PTR),多个回滚指针行程历史数据链</li></ul><blockquote><p>Innodb 使用ReadView对象来判断事务的可见性(隔离性),Innndb在执行select 查询时创建ReadView对象,配合undo log 的版本链 查询可见数据<br>对于read commited ,每个快照读操作都有自己的ReadView,而对于repeated read ,ReadView与事务相关,事务中的读操作共享一个readView;<br>readView：trx_list(生成时正在活跃的事务列表) up_limit_id(创建时活跃的最小的事务id) low_limit_id(创建时未分配的最小的事务ID,即此时最大事物id+1) 创建readView的事务ID<br>当前事务尝试读取数据时,会执行一下判断算法判断记录的可见性</p><ol><li>把当前记录的修改事务ID赋值给变量x,用以判断是否当前记录是否可见</li><li>把 x 与 活跃事务区间进行比较<ul><li>x&lt;最小值,意味着修改的事务 在 创建readView之前已经提交,所以 可见或者x = 当前事务ID ,就是本身修改的,返回数据</li><li>x&gt;最大值,说明修改的事务是在 创建readview之后发生的,所以该记录不可见,需要沿着回滚指针指向的undo log,更新x进行下一轮的比较</li><li>x 在区间之间,意味着修改的事务可能仍在活跃中,即在readview的活跃列表中 或者 事务已提交 这样的话就需要二分判断该事务是否在列表中,在的话,意味着当前事务未结束,所以该记录不可见,所以同理沿着回滚指针进行下一轮比较;如果不在就意味着 事务在创建readView之前已经提交,那么可见,返回数据</li></ul></li></ol></blockquote><h3 id="mysql-log">Mysql lOG</h3><blockquote><p>binlog:用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步(用于数据库的基于时间点的还原)<br>undo log:为了实现事务的原子性,在innodb中与MVCC 配合实现<br>redo log:目标在于确保事务的持久性;对于innodb的任何修改操作都会首先在buffer pool 缓存页中进行,这样的页可以被标注为dirty然后由专门的purge线程写到磁盘,这样可以避免每次都写的随机IO,直接访问缓存降低了访问的时延,但是可能出现脏页在为写入磁盘时,系统崩溃,修改丢失,所以innodb将所有修改操作写入redo log文件(可覆盖写),在数据库启动时进行恢复操作<br>errorlog:错误日志记录着mysqld启动和停止,以及服务器在运行过程中发生的错误的相关信息。在默认情况下，系统记录错误日志的功能是关闭的，错误信息被输出到标准错误输出(在开启死锁日志的打印之后，所有的死锁日志都会打印在error log中)<br>slow query log：通过 记录执行超过一定时间的SQL语句以及没有使用索引的查询语句<br>general log：记录所以执行的sql,用于排查sql性能,但会增加系统负担,常短期开启分析.<br>relay log：用于复制中接收方复制binlog<br>undo log:Innodb引擎的undo日志是记录在表空间中单独的回滚段中。 当mysql做update和delete操作的时候，实际的后台都是先把旧记录“删”了，如果是update和insert再把新记录“插入”进去</p></blockquote><p>log buffer</p><ul><li>redo log buffer</li><li>undo log buffer</li></ul><p>binlog VS redolog</p><ul><li>binglog是服务层的记录sql语句，不或缺,redolog是存储引擎innodb这一层的记录的是物理操作(页的变更操作),并不是所有引擎都有</li><li>binlog可用于同步,redolog和binlog配合用于奔溃恢复</li><li>binlog是累加的提交事务时写入磁盘,redolog是固定大小的，复写的</li></ul><p>binlog的刷盘时机 sync_binlog</p><ul><li>0:不做要求,系统判断比如缓存不足</li><li>N：没N个事务就写入磁盘</li></ul><p><a href="https://www.cnblogs.com/hi3254014978/p/12730794.html" target="_blank" rel="noopener">快照读 vs 当前读</a></p><blockquote><p>快照读(snapshot read)/一致性读：MVCC实现,普通的 select 语句(不包括 select … lock in share mode, select … for update):确保事务只能读在其之前生效或者自己修改的记录<br>当前读(current read) ：select … lock in share mode，select … for update，insert，update，delete 语句（这些语句获取的是数据库中的最新数据,加next-key锁</p></blockquote><h3 id="排序二叉树-gt-平衡二叉树-gt-b-树-gt-b树">排序二叉树 -&gt; 平衡二叉树 -&gt; B-树 -&gt; B+树</h3><blockquote><p>排序二叉树:左节点小于根节点,而右节点大于根节点<br>平衡二叉树:在排序二叉树的基础上,保证左右子树的深度相差不超过1,可以降低查询的时间<br>B-树:多路平衡二叉树,节点上可以有多个元素,也存储数据,可以有多个子树<br>B+树:在B+树的基础上,仅在叶子节点上存储数据,非叶子节点存储用于比较的index,不存储数据</p></blockquote><h3 id="最左匹配原则">最左匹配原则</h3><blockquote><p>索引建立时 是按照 字段 从左到右 排序的顺序来比较和存储 节点指针的<br>对于 已存在的索引 (a b c) :(a) (a b) (a b c) 可以使用该索引,同时mysql 存在对于检索条件的优化,使得 (c b a) 优化为(a b c) 来索引</p></blockquote><h3 id="myisam与innodb">MyISAM与InnoDB</h3><blockquote><p>1.对事务的的支持。MyISAM强调性能,每次查询都是具有原子性,执行速度更快,但不支持事务,Innodb 具有 事务(commit) 回滚(rollback) 和 崩溃恢复功能的事物安全型表<br>2.对外键(表的外键是其他表的主键,跨表之间的联系)的支持<br>3.InnoDB是聚集索引（主索引存储数据文件，辅助索引指向主键），MyISAM 是非聚集索引（主键索引和辅助索引都指向文件指针）</p><ul><li>InnoDB表必须有主键（用户没有指定的话会自己找或生产一个主键）以支持聚集索引，而Myisam可以没有(所有索引都是非聚集索引,主键索引和非主键索引都是没有区别,不使用聚集索引)<br>4.InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁<br>6.是否支持MVCC 应对高并发事物MVCC比锁更加高效(MVCC在读已提交和可重复读的连个隔离级别下工作)</li></ul></blockquote><h3 id="myisam">MyISAM</h3><blockquote><p>不支持事务和行级锁,最大的缺陷是崩溃后无法恢复<br>在某些特殊场合(不介意崩溃恢复问题),myisam适合密集读</p></blockquote><h3 id="postgresql-vs-mysql">PostgreSQL  VS MySQL</h3><blockquote><p>待完善</p></blockquote><h2 id="mysql-锁">mysql 锁</h2><p><a href="https://juejin.im/post/6844903668571963406" target="_blank" rel="noopener">全面了解mysql锁机制（InnoDB）与问题排查</a><br><a href="https://blog.csdn.net/Jack__Frost/article/details/73347688" target="_blank" rel="noopener">锁机制超详细解析（锁分类、事务并发、引擎并发控制）</a></p><blockquote><p>背景:锁是计算机用于协调多个进程或线程访问某资源的机制;事物在操作某个数据之前需要申请对其加锁,根据锁的类型不同,事物对其有不同的控制程度,在该事物释放锁之前,阻止其他事物的操作.<br>分类:</p><ul><li>按照封锁类型可以分为 排它锁和共享锁;<ul><li>排它锁又称写锁,X锁,阻止其他事物对于数据加锁,阻止其他事物读或写该数据;</li><li>共享锁,又称读锁,S锁,事物对于数据添加共享锁之后,其他事物只能对其添加共享锁,不能添加排它锁,只能读,不能写</li></ul></li><li>按照封锁的粒度分类：<ul><li>行级锁: 虽然由于粒度小,发生资源争用的概率变小,可以提高并发程度,但是因为粒度小,所以获取和释放锁的工作和消耗更多;此外容易发生死锁</li><li>表级锁: 虽然开销小,加锁快,不会出现死锁,但是锁定粒度大,发生冲突的概率大,并发程度低(一次性锁定事务所涉及到的表)</li><li>页级锁(Mysql独有): 加锁和开锁时间以及粒度介于 行级锁和表级锁之间,可能出现死锁,并发度一般</li></ul></li></ul></blockquote><blockquote><p>死锁的条件：互斥条件(排他性占有资源) 请求和保持条件(阻塞时不释放资源) 不剥夺条件(只能自己主动释放资源) 环路等待(进程-资源请求环)</p></blockquote><blockquote><p>举例 事物 <code>update t_goods set current_count = current_count - 1 where id = 1; update t_count set balance = balance - 2 where id = 1;</code> 和  <code>update t_goods set current_count = current_count - 1 where id = 1;update t_count set balance = balance - 2 where id = 1;</code> 分别获得了第一条记录的锁后,出现死锁</p></blockquote><blockquote><p>mysql 如何处理死锁：</p><ul><li>等待，直到事物超时回滚</li><li>发起死锁检测(死锁检测的原理是构建一个以事务为顶点、锁为边的有向图，判断有向图是否存在环，存在即有死锁。)，主动回滚一条事务(检测到死锁之后，选择插入更新或者删除的行数最少的事务回滚)，让其他事务继续执行</li></ul></blockquote><blockquote><p>死锁预防策略：</p><ul><li>逻辑上避免交叉操作(a-b和 b-a)</li><li>保持事物的轻量,减少涉及的表和资源,避免使用子查询,尽量使用主键,降低锁持有时间(不要在事物中加其他耗时操作)</li><li>建立索引(索引也可能导致死锁)</li></ul></blockquote><blockquote><p>其他：select update 操作是否设计锁表?可能和执行引擎相关？ todo</p></blockquote><h3 id="自增锁">自增锁</h3><blockquote><p>是MySQL一种特殊的锁，如果表中存在自增字段，MySQL便会自动维护一个自增锁。</p></blockquote><p><a href="https://zhuanlan.zhihu.com/p/29150809" target="_blank" rel="noopener">参考1</a></p><h3 id="行锁">行锁</h3><h4 id="实现方式">实现方式</h4><ol><li>Innodb 通过对索引上的索引项加锁来实现(而Oracle通过对于数据行加锁来实现) =&gt; 只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁</li><li>不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁</li><li>由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键,是会出现锁冲突的(后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁)</li></ol><h3 id="间隙锁-gap-key">间隙锁 gap key</h3><blockquote><p>当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）<br>但是间隙锁会导致对于符合条件范围的键值的插入陷入阻塞,等待锁释放;=&gt;尽量使用=而非范围<br>唯一索引没有间隙锁<br>间隙锁存在于非唯一索引中，锁定<code>开区间</code>范围内的一段间隔，它是基于临键锁实现的。(当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。)<br>gap锁不排他 可重入<br>目的</p></blockquote><ul><li>(结合MVCC)防止幻读,满足可重复读</li><li>满足恢复和复制的需要<ul><li>mysql通过BINLOG记录事务的sql语句,按照事务提交的先后顺序来记录,实现mysql的备份和主从复制;由于按照事务提交的顺序来记录所以不允许<br>利用 where between and触发 间隙锁,当范围内的记录都存在时,退化为行锁</li></ul></li></ul><h4 id="实现方式">实现方式</h4><blockquote><p>当</p></blockquote><h3 id="临键锁-next-key-lock">临键锁 next-key lock</h3><blockquote><p>Next-Key 可以理解为一种特殊的间隙锁，也可以理解为一种特殊的算法。通过临建锁可以解决幻读的问题。 每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁<br>临键锁存在于非唯一索引中，该类型的每条记录的索引上都存在这种锁，它是一种特殊的间隙锁，锁定一段<code>左开右闭</code>的索引区间</p></blockquote><h3 id="唯一索引-是否使用-间隙锁"><a href="https://zhuanlan.zhihu.com/p/48269420" target="_blank" rel="noopener">唯一索引 是否使用 间隙锁</a></h3><p>在where between and中如果列元素 是非唯一索引那么是使用间隙锁的<br>如果是唯一索引,那么</p><h3 id="常见加锁规则"><a href="https://www.aneasystone.com/archives/2017/12/solving-dead-locks-three.html" target="_blank" rel="noopener">常见加锁规则</a></h3><p>select 语句正常情况下为快照读，不加锁；<br>SELECT … LOCK IN SHARE MODE 语句为当前读，加 S 锁；<br>ELECT … FOR UPDATE 语句为当前读，加 X 锁<br>常见的 DML 语句（如 INSERT、DELETE、UPDATE）为当前读，加 X 锁；<br>常见的 DDL 语句（如 ALTER、CREATE 等）加表级锁，且这些语句为隐式提交，不能回滚；</p><p><a href="https://www.aneasystone.com/archives/2018/06/insert-locks-via-mysql-source-code.html" target="_blank" rel="noopener">insert into</a></p><blockquote><p>首先会获得插入意向锁,即会对插入所在记录的间隙的间隙锁,虽然它是一种间隙锁但是与gap锁冲突(不同事物对于同一间隙可重复加锁);<br>完成插入之后,对插入的记录添加写锁,</p></blockquote><p>为什么非唯一索引会加 GAP 锁，而唯一索引不用加 GAP 锁呢？</p><blockquote><p>原因很简单，GAP 锁的作用是为了解决幻读，防止其他事务插入相同索引值的记录，而唯一索引和主键约束都已经保证了该索引值肯定只有一条记录，所以无需加 GAP 锁。</p></blockquote><h3 id="意向锁">意向锁</h3><p>分为意向读锁和意向写锁 属于表锁<br>意向读锁与预想写锁之间是兼容的(直觉是类似可重入锁),但是意向锁与读写锁之间存在互斥(意向读锁与表写锁互斥,意向写锁与表读锁互斥)</p><h3 id="乐观锁-悲观锁">乐观锁 悲观锁</h3><p>MySQL的并发控制有两种方式，一个是 MVCC，一个是两阶段锁协议</p><blockquote><p>Multi-Version Concurrency Control,翻译为中文即 多版本并发控制<br>VCC的实现，通过保存数据在某个时间点的快照来实现的。这意味着一个事务无论运行多长时间，在同一个事务里能够看到数据一致的视图。根据事务开始的时间不同，同时也意味着在同一个时刻不同事务看到的相同表里的数据可能是不同的<br>在每一行数据中额外保存两个隐藏的列：当前行创建时的版本号和删除时的版本号（可能为空，其实还有一列称为回滚指针，用于事务回滚，不在本文范畴）</p></blockquote><h3 id="事务的三级封锁协议">事务的三级封锁协议</h3><p>2PL,两阶段加锁协议:主要用于单机事务中的一致性与隔离性。<br>一个事务里面，分为加锁(lock)阶段和解锁(unlock)阶段,也即所有的lock操作都在unlock操作之前<br>在事务中只有提交(commit)或者回滚(rollback)时才是解锁阶段，其余时间为加锁阶段。</p><blockquote><p>按照顺序或者并发量 一次加锁和解锁<br>引入2PL是为了保证事务的隔离性，保证并发调度的准确性，多个事务在并发的情况下依然是串行的。</p></blockquote><h3 id="三级封锁协议">三级封锁协议</h3><p>封锁协议：<br>运用X锁和S锁对数据对象进行加锁时约定的规则就是封锁协议。</p><p>目的是在不同程序上保证数据的一致性。</p><p>一级封锁：修改数据加x锁直到事务结束才释放。在此协议中，仅仅是读数据是不需要加锁的，所以只能解决丢失修改问题，不能解决脏读和不可重复读。<br>二级封锁：在一级封锁的基础上，加了一条：T事务在读取数据R之前必须先对其加上S锁，读完释放S锁。可以解决丢失修改和脏读（加了读锁就可以防止在读的期间其他事务进行修改，但是读完之后，事务结束之前，依然可能会其他事务进行修改，导致不可重复读）。<br>三级封锁协议：一级封锁协议加上事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放。：解决了丢失修改、脏读和不可重复读的问题。</p><h2 id="mysql-优化">mysql 优化</h2><ul><li>分表</li><li>存储过程和存储函数</li></ul><h3 id="数据库范式">数据库范式</h3><p>数据库设计对数据的存储性能，还有开发人员对数据的操作都有莫大的关系。所以建立科学的，规范的的数据库是需要满足一些规范的来优化数据数据存储方式。在关系型数据库中这些规范就可以称为范式。</p><p>第一范式：当关系模式R的所有属性都不能在分解为更基本的数据单位时，称R是满足第一范式的，简记为1NF。满足第一范式是关系模式规范化的最低要：</p><ul><li>字段不可分<br>第二范式：如果关系模式R满足第一范式，并且R得所有非主属性都完全依赖于R的每一个候选关键属性，称R满足第二范式，简记为2NF。</li><li>有主键，非主键字段完全依赖主键而非主键的一部分<br>第三范式：满足第二范式;设R是一个满足第一范式条件的关系模式，X是R的任意属性集，如果X非传递依赖于R的任意一个候选关键字，称R满足第三范式，简记为3NF.</li><li>非主键字段不能相互依赖;</li></ul><h3 id="数据库连接池-和-事物">数据库连接池 和 事物</h3><h4 id="数据库连接池">数据库连接池</h4><p>1、连接池是创建和管理一个连接的缓冲池的技术，这些连接准备好被任何需要它们的线程使用。<br>　　作用：避免频繁地创建与消毁，给服务器减压力。<br>2、数据库的弊端：<br>　　1.当用户群体少服务器可以支撑，如果群体比较大万级别服务器直接死机。数据库默认的并发访问50.<br>　　2.每一个用完数据库之后直接关闭，不能重复利用太浪费资源。<br>3、设计连接池：<br>　　1.在池子中创建出多个连接供使用。<br>　　2.当用户需要操作数据库时直接从池子中获取连接即可。<br>　　3.当用户使用完毕之后把连接归还给连接池，可以达到重复使用。<br>　　4.可以设定池子的最大容器。比如50个连接，当第51个人访问的时候，需要等待。<br>　　5.其它用户释放资源的时候，可以使用。</p><h4 id="事物">事物</h4><p>事务是指一组操作，里面包含许多单一的逻辑。只要一个逻辑没有执行成功，那么就算失败。所有的数据都回归到最初的状态（回滚）<br>A: 要么都发生,要么都不<br>C: 事物发生前后保持一致性状态<br>I: 隔离性,多个事物之间不相互干扰<br>D: 发生之手产生持久性影响</p><h4 id="数据库连接池与事物-并非一一对应">数据库连接池与事物 并非一一对应</h4><ul><li>一个连接里可以启动多次事务，比如连接池，就是最明显的连接重用。</li><li>一个事务里，可以涉及到2个甚至多个连接，也就是XA的驱动，甚至跨不同数据库的事务。</li></ul><h4 id="其他-redis">其他 redis</h4><p>scan keys</p><h4 id="sql操作">sql操作</h4><blockquote><p>groupby having<br>联合查询</p></blockquote><h4 id="mysql索引要使用b树而不是b树红黑树"><a href="https://segmentfault.com/a/1190000021488885" target="_blank" rel="noopener">mysql索引要使用B+树，而不是B树，红黑树</a></h4><ol><li>B+ vs hash</li></ol><blockquote><p>内存消耗,B+树的索引可以不一次性加载;而map需要</p></blockquote><ol start="2"><li>B  VS B+</li></ol><blockquote><p>相对于B树仅在叶子节点存储数据,所以同样的内存空间可以容纳更多的节点元素,查询的io次数更少;<br>其次主键索引的叶子节点的数据是相邻的,所以空间局部性会更好,方便范围查询<br>稳定查询,每次都必须查询到叶子节点,而b树可能中间就可以了</p></blockquote><ol start="3"><li>B+ VS 红黑树/二叉排序树</li></ol><blockquote><p>查询时间与树的高度相关,多路搜索树可以降低树的高度</p></blockquote><ol start="4"><li>既然增加树的路数可以降低树的高度，那么无限增加树的路数是不是可以有最优的查找效率？</li></ol><blockquote><p>无线增加数的高度会导致最终形成一个一层的有序数组,数据量过大无法从一次性加载 而B+树可以以较小的内存代价降低高度;</p></blockquote><ol start="5"><li>在内存中，红黑树比B树更优，但是涉及到磁盘操作B树就更优了，那么你能讲讲B+树吗？</li></ol><blockquote></blockquote><ol start="6"><li>为什么B+树要这样设计？</li></ol><blockquote><p>这个跟它的使用场景有关，B+树在数据库的索引中用得比较多，数据库中select数据，不一定只选一条，很多时候会选中多条，比如按照id进行排序后选100条。如果是多条的话，B树需要做局部的中序遍历，可能要跨层访问。而B+树由于所有数据都在叶子结点不用跨层，同时由于有链表结构，只需要找到首尾，通过链表就能把所有数据取出来了。</p></blockquote><p><a href="https://segmentfault.com/a/1190000019619667" target="_blank" rel="noopener">MySQL重要知识点/面试题总结</a></p><p>mysql 执行一条指令的过程 存储引擎 <a href="https://cloud.tencent.com/developer/article/1418795" target="_blank" rel="noopener">MySQL命令执行过程和存储引擎概述</a></p><ol><li>连接管理。 主要是负责连接的建立与信息的认证<ul><li>利用数据库连接池去管理连接实现高效复用(epoll?NIO?)</li></ul></li><li>解析与优化。 这一部分分为三个步骤处理：<ul><li>查询缓存：对于相同的命令,会优先返回缓存中 的数据,此外缓存系统会监控缓存涉及的表,有变更的话,缓存失效</li><li>语法解析：对于查询文本做分析，判断请求的语法是否正确，然后从文本中要查询的表、各种查询条件都提取出来</li><li>查询优化：使用索引 外连接转内连接 子查询转连接 表达式简化</li></ul></li><li>存储引擎:它的功能就是接收上层传下来的指令，然后对表中的数据进行提取或写入操作<ul><li>读操作：涉及读缓存池,预读策略,LRU淘汰 - 双写;</li><li>写操作：涉及写缓存(唯一索引);</li></ul></li></ol><p>视图 VIEW</p><blockquote><p>虚标：从一个表或者多个表联合导出的虚拟的表,具有普通表的结构,但不实际存储数据</p></blockquote><ul><li>单表视图：可以用于查询,也可以用于修改</li><li>多表视图：一般用于查询,一般不会修改<br>优点</li><li>逻辑独立：建立在表上的逻辑独立,隔离了实际表的影响</li><li>简化操作,可以定义常用操作为视图</li><li>安全性：首先是视图本身的虚拟性,与表结构不直接相关,可以向外暴露视图,保证数据安全</li></ul><p>缺点:</p><ul><li>修改限制</li><li>多表查询性能差</li></ul><p>存储过程 PROCEDURE</p><blockquote><p>程序化的sql语句组合; 一般是用来完成特定的数据操作（比如修改、插入数据库表或执行某些DDL语句等等)<br>经过编译优化,相对于sql语句可以加快执行速度<br>可以有参数</p></blockquote><p>函数 FUNCTION</p><blockquote><p>一般情况下是用来计算并返回一个计算结果;可以编译好使用</p></blockquote><p>函数 VS 存储过程</p><blockquote><p>是否可以独立运行,函数一般需要在配合查询操作使用<br>存储过程一般可以入口参数以及返回值比函数更丰富,存储过程可以返回参数,记录集等,函数只能返回变量或者表对象<br>存储过程一般适合复杂操作,修改等;</p></blockquote><p>光标（游标）</p><blockquote><p>查询语句可能查询出多条记录，在存储过程和函数中使用光标标来逐条读取查询结果集中的记录</p></blockquote><p>二级索引使用B+树,所以当他找到第一个符合要求的叶子节点之后,可以向后遍历判断索引是否相同,如果相同添加进返回列表,并继续下午,不同则停止遍历.</p><h4 id="mysql-innodb-3大特性-写缓冲-双写-自适应hash">mysql innodb 3大特性 写缓冲 双写 自适应hash</h4><h5 id="自适应hash">自适应hash</h5><p><a href="https://blog.csdn.net/qq_36431213/article/details/86512359" target="_blank" rel="noopener">自适应hash</a></p><blockquote><p>背景：哈希索引始终基于现有的二级索引构建,在索引树的任意长度的前缀上构建索引树(自适应:最近连续被访问三次的数据)<br>由于哈希索引根据经常访问的索引构建,如此可以加速二级索引的访问速度,但是只使用于 = 和 in 操作,对于like 和joins操作 操作无能为力,此外 由于hash索引必然涉及锁的竞争(可能更新涉及索引的变更),高并发场景也可能会有消耗</p></blockquote><h5 id="缓冲池读请求">缓冲池：读请求</h5><p><a href="https://juejin.im/post/6844904051012796424" target="_blank" rel="noopener">参考1</a><br><a href="https://juejin.im/post/6844903874172551181" target="_blank" rel="noopener">参考2</a></p><blockquote><p>缓冲可以用于存储常访问的数据,mysql对应的有缓冲池的概念,增加了读请求的速度<br>缓冲什么？缓冲池缓冲索引,和表数据(把磁盘数据加载到缓冲池),避免频繁的IO访问;</p></blockquote><p>如何管理和淘汰缓冲池？</p><blockquote><p>预读:出于局部性原理,mysql会提前预读一部分未读的数据,以期待未来访问不需要IO操作,但不命中时需要考虑淘汰策略<br><a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-performance-read_ahead.html" target="_blank" rel="noopener">预读策略</a>：<br>磁盘中的数据数据存储是以页为单位的一般4k,缓冲池是以extent为单位,包含64页,一般256K,需要满足预定条件出发异步预读</p></blockquote><ul><li>线性预读：缓冲池中当前的extent的被顺序读取的page数目&gt;=innodb_read_ahead_threshold(默认56)时会触发,对于下一个extent的异步预读</li><li>随机预读：缓缓池当前extent的数量大于13,那么该extent的其他页数据也会被预读,可以控制是否关闭该功能</li></ul><p>缓冲池中的页大小默认为 16KB(之所以不等于4K是为了提高数据的顺序读取性能,但降低了随机读取性能)</p><p><a href="https://juejin.im/post/6844904051012796424" target="_blank" rel="noopener">刷新策略</a></p><blockquote><p>通过策略将缓冲刷新磁盘保证数据的持久性,当数据库崩溃是可以通过redo log 操作</p></blockquote><ul><li>普通模式，当缓存池中的脏页比例超过innodb_max_dirty_pages_pct_lwm(低水平线默认为25%)时，启动普通模式将脏页刷新到磁盘中</li><li>aggressively flushes,当缓存池中的脏页比例超过innodb_max_dirty_pages_pct(默认为75%)时，启动更快的刷新模式，尽快的将脏页刷新到磁盘当中</li></ul><p><a href="https://juejin.im/post/6844904051012796424" target="_blank" rel="noopener">缓存池淘汰算法LRU</a></p><blockquote><p>基于LRU算法改进,避免了LRU列表被污染(避免出现只访问一次在不访问的情况,以及预读出现的缓存的污染)<br>其他的算法还包括 FIFO LFU</p></blockquote><p>LRU算法</p><blockquote><p>维护一个链表,将刚出现的页查到链表头(如果已经在队列则改变位置),随着链表的长度增长达到总长度,链表尾的数据长期未被访问而被淘汰(但是会出现污染的情况,使得命中率下降)</p></blockquote><p>LRU-K</p><blockquote><p>其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。也就是说没有到达K次访问的数据并不会被缓存，这也意味着需要对于缓存数据的访问次数进行计数，并且访问记录不能无限记录，也需要使用替换算法进行替换。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据</p></blockquote><p>使用算法:LRU变种</p><blockquote><p>利用midpoint将LRU队列分为两部分 NEW(最近被访问) OLD,默认5:3 双方各自维护head tail<br>成为OLD:用户读取的页面或者预读的页面首先插入OLD的head<br>成为NEW：用户读取的页面在OLD中,则将其转移到NEW的head<br>随着NEW和OLD的逐渐增加,页会被慢慢淘汰</p></blockquote><h5 id="写缓冲写请求">写缓冲:写请求</h5><blockquote><p>背景:insert buffer 只对insert操作有效,5.6后,改为change buffer 对于insert update操作有效<br>目的:应用于非唯一索引页(唯一索引必须加载全部索引然后判断是否唯一)不在缓冲池时对于页进行写操作,仅仅记录变更,等未来数据被读取时,再讲数据变更合并到缓冲区,目的在于降低读磁盘IO的开销(之所以读是因为避免频繁写需要频繁的IO,在内存中写快多了);</p></blockquote><p>触发写缓冲合并的操操作：</p><ul><li>写缓冲涉及的页被访问</li><li>数据库空闲或者关闭时</li><li>数据库缓冲池不够,需要更新缓冲</li><li>redo log 写满(基本不会发生)</li></ul><p>什么业务场景，适合开启InnoDB的写缓冲机制</p><ul><li>大部分索引是唯一索引</li><li>业务写多读少或者写完之后不会立刻读(流水账)</li></ul><p>参数配置：</p><ul><li>innodb_change_buffer_max_size：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%</li><li>innodb_change_buffering：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes</li></ul><h5 id="双写">双写</h5><p><a href="https://dbaplus.cn/news-11-1170-1.html" target="_blank" rel="noopener">参考1</a></p><blockquote><p>由于cache pageSize一般不是4k那么意味着对于cahce块对于磁盘的写入分为4部分,可能部分成功(比如说断电),出现 partial page write,这时 即使借助redo日志也不能恢复数据,所以需要借助双写机制 实现副本 备份<br>双写的额外存储：</p></blockquote><ul><li>double write buffer：2M =128 cache page的空间= 2簇的大小</li><li>共享表空间：磁盘上对应的2M的连续空间(128页= 120批量写脏页+8由用户发起的单个写脏页)<br>双写过程：</li><li>LRU缓冲队列中淘汰的脏页复制到dwb</li><li>将dwb同步到磁盘存储备份(由于是顺序整体写,所以速度不会慢)(分两次写到共享表空间,1次1M)</li><li>开始将dwb中数据分页写回磁盘(在此可以通过把相邻近的页相邻的写回磁盘加快速度)</li></ul><p>varchar VS  char<br><a href="https://www.cnblogs.com/zhuyeshen/p/11642211.html" target="_blank" rel="noopener">参考1</a></p><ul><li>长度<ul><li>CHAR 固定长度 最多28−1个字符，28−1个字节</li><li>VARCHAR 不定长度 最多216−1个字符，216−1个字节(前面保留1-2字节存储实际长度)</li></ul></li><li>空格处理<ul><li>char 保留末尾空格和长度</li><li>varchar 删除末尾空格并根据真实长度存储</li></ul></li><li>碎片角度<ul><li>varchar 可能导致存储碎片</li></ul></li><li>内存<ul><li>查询varchar的表时为了保存数据结果转化为char,会按照其定义的大小分配空间,而非按照实际 长度</li></ul></li></ul><h4 id="mysql-的插入删除和更新插入删除和更新索引">mysql 的插入删除和更新<a href="https://www.cnblogs.com/qianxingmu/p/10746837.html" target="_blank" rel="noopener">插入删除和更新索引</a></h4><p>对于数据的操作实际上都是涉及对于索引的锁<br>mysql的删除仅仅是标记数据行,没有实际的删除,删除的数据行位置可以被新插入的行记录复用<br>mysql的删除和更新操作可能会使得空间占比低于MERGE_THRESHOLD (行数据 所占据页的空间比,一般为50%) ,导致当前页尝试与相邻页(如果也低于50%)进行合并<br>mysql的插入和更新涉及页的分裂</p><blockquote><p>当按序插入时,只会在有空间的页中添加或者新占用一页;但是如果是在中间插入,那么可能出现该记录的前后记录所在的页都是满页,这时会出现页的分裂,会将前面记录所在的满页的1-MERGE_THRESHOLD复制到新页,然后该记录插在新页。频繁的也分裂可能造成数据也空洞<br>可以通过降低 MERGE_THRESHOLD值去降低页合并的可能性;但是过小也可能造成数据页空洞,大量文件零散分布<br>可以通过查看页的分裂数然后利用  optimize table t 重建表,但是耗时而且锁住索引<br>这个命令的原理就是重建表，就是建立一个临时表 B，然后把表 A（存在数据空洞的表） 中的所有数据查询出来，接着把数据全部重新插入到临时表 B 中，最后再用临时表 B 替换表 A 即可，这就是重建表的过程。顺序插入的过程,可以避免页的分裂</p></blockquote><p>引发慢查询的情况有三种：</p><ul><li>索引没有设计好:可以建立索引解决</li><li>SQL 语句没有写好：优化语句</li><li>MYSQL 选错了索引 添加 <code>force index</code>强制使用索引</li></ul><p>expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键</p><p>索引建立原则 区分度<br>查询语句中同时出现where 和group 怎么走索引，索引能走多个吗</p>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面经收集</title>
      <link href="/2020/08/28/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/"/>
      <url>/2020/08/28/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p>Java 后台开发<br><a href="https://github.com/Snailclimb/JavaGuide" target="_blank" rel="noopener">Github 知识总结</a></p><ul><li><a href="https://www.nowcoder.com/discuss/491234?channel=1013&amp;source_id=home_feed" target="_blank" rel="noopener">美团一面</a></li></ul><p>面试问题收集：</p><ol><li><p>volatile不是线程安全<br>线程安全必须保证原子性，可见性，有序性。而volatile只能保证可见性和有序性,volatile 只能保证 可见性,有序性 不能保证操作的原子性,建议使用CAS操作 利用cocurrent.atomic包下面的封装</p></li><li><p>配置线程池需要考虑哪些因素</p></li></ol><blockquote><p>从任务的优先级，任务的执行时间长短，任务的性质（CPU密集/ IO密集），任务的依赖关系这四个角度来分析。并且近可能地使用有界的工作队列。<br>性质不同的任务可用使用不同规模的线程池分开处理：</p></blockquote><ul><li>CPU密集型：尽可能少的线程，Ncpu+1</li><li>IO密集型：尽可能多的线程, Ncpu*2，比如数据库连接池</li><li>混合型：CPU密集型的任务与IO密集型任务的执行时间差别较小，拆分为两个线程池；否则没有必要拆分。</li></ul><ol start="3"><li>集群基本概念—脑裂的产生和解决方案<br><a href="https://www.cnblogs.com/kevingrace/p/12433503.html" target="_blank" rel="noopener">脑裂</a></li></ol><ul><li>限定发送人数,确定集群有效无效</li><li>冗余通信(物理)</li><li>仲裁方式</li><li>磁盘锁定</li></ul><ol start="4"><li>Map 接口及其实现类</li></ol><blockquote><p>HashMap<br>LinkedHashMap<br>TreeMap<br>HashTable<br>WeakHashMap:以弱键 实现的基于哈希表的 Map。在 WeakHashMap 中，当某个键不再正常使用时，将自动移除其条目。更精确地说，对于一个给定的键，其映射的存在并不阻止垃圾回收器对该键的丢弃，这就使该键成为可终止的，被终止，然后被回收<br>EnumMap</p></blockquote><ol start="5"><li>StringBuilder StringBuffer</li></ol><blockquote><p>StringBuffer 和 StringBuilder 类的对象能够被多次的修改，并且不产生新的未使用对象。<br>由于 StringBuilder 相较于 StringBuffer 有速度优势，所以多数情况下建议使用 StringBuilder 类。然而在应用程序要求线程安全的情况下，则必须使用 StringBuffer 类。</p></blockquote><ol start="6"><li><p>juc</p></li><li><p>几个垃圾回收器（3对+1），Serial与Serial Old ,ps和po  ，pn和cms，g1</p></li><li><p>对象创建的生命周期(栈，线程本地，堆)，对象的分配(一般对象，大对象，一直存在的对象)，如何判断一个对象是否是垃圾对象(介绍了两个方法，各自特点)，强软弱需引用，有哪些垃圾回收算法（4个方法），各自的特点，还说了几个垃圾回收器（3对+1），Serial与Serial Old ,ps和po  ，pn和cms，g1，还介绍了各自的优点缺点，jdk怎么用的，stw的情况，还说了如何调优，jdk1.8默认ps po的调优（介绍了几个指令），最后还说了，我用的一直都是idea默认版本pspo。</p></li><li><p>AOP原理了解吗？</p></li></ol><blockquote><p>恒切面;切点；通知</p></blockquote><ol start="10"><li><p>shard</p></li><li><p>分布式session</p></li></ol><ul><li>粘性session：粘性Session是指将用户锁定到某一个服务器上;在nginx出配置;但容错性低</li><li>服务器session复制：修改 传播所有机器</li><li>session共享机制：reids共享</li></ul><ol start="12"><li>MySQL Explain详解</li></ol><blockquote><p>explain这个命令来查看一个这些SQL语句的执行计划，查看该SQL语句有没有使用上了索引，有没有做全表扫描，这都可以通过explain命令来查看</p></blockquote><ol start="13"><li>concurrenthashmap 是否线程安全?</li></ol><blockquote><p>concurrenthashmap的线程安全是指他的put和get操作是原子操作，是线程安全的;outIfabsent</p></blockquote><ol start="14"><li>在一个千万级的数据库查寻中，如何提高查询效率？</li></ol><ul><li>分表：femmale 枚举字段 分表</li><li>优化查询,避免全表查询,建立并使用索引</li><li>应尽可能的避免更新索引数据列(insert)，因为索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新索引数据列，那么需要考虑是否应将该索引建为索引</li><li>避免临时操作</li><li>尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。</li><li>避免全表查询<ul><li>where 子句中使用!=或&lt;&gt;</li><li>where 子句中使用 or 来连接条件</li><li>in 和 not in  like</li></ul></li></ul><ol start="15"><li>微信红包算法</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public static double getRandomMoney(RedPackage _redPackage) &#123;</span><br><span class="line">        // remainSize 剩余的红包数量</span><br><span class="line">        // remainMoney 剩余的钱</span><br><span class="line">        if (_redPackage.remainSize == 1) &#123;</span><br><span class="line">            _redPackage.remainSize--;</span><br><span class="line">            return (double) Math.round(_redPackage.remainMoney * 100) / 100;</span><br><span class="line">        &#125;</span><br><span class="line">        Random r = new Random();</span><br><span class="line">        double min = 0.01; //</span><br><span class="line">        double max = _redPackage.remainMoney / _redPackage.remainSize * 2;</span><br><span class="line">        double money = r.nextDouble() * max;</span><br><span class="line">        money = money &lt;= min ? 0.01 : money;</span><br><span class="line">        money = Math.floor(money * 100) / 100;</span><br><span class="line">        _redPackage.remainSize--;</span><br><span class="line">        _redPackage.remainMoney -= money;</span><br><span class="line">        return money;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="16"><li>为什么用B+树？</li></ol><blockquote><p>磁盘IO开销小 栈空间较小<br>查找比较稳定。效率比较高</p></blockquote><ol start="17"><li>解决哈希冲突有如下的方法：</li></ol><blockquote><p>开放定址法(线性探测，二次探测，伪随机探测)<br>链地址法<br>再散列法（双重散列，多重散列）<br>建立一个公共溢出区</p></blockquote><ol start="18"><li>外排序</li></ol><blockquote><p>利用外存也就是磁盘进行排序的一种简称。<br>典型的应用是hadoop　的 mapreduce 的merge 阶段(map shuffle reduce)</p></blockquote><ol start="19"><li>秒杀怎么解决超卖</li></ol><blockquote><p>redis 缓存数据库压力;消息队列;分步骤 下单 和 真正获取订单;限制用户访问频率和次数</p></blockquote><ol start="20"><li>消息队列</li></ol><blockquote><p>异步通信:降低服务耦合;提高并发度;流量削峰</p></blockquote><ol start="21"><li>HashMap 30分钟<br><a href="https://blog.csdn.net/zhengwangzw/article/details/104889549" target="_blank" rel="noopener"> HashMap 30分钟</a></li></ol><ul><li>因为1.7头插法扩容时，头插法会使链表发生反转，多线程环境下会产生环；</li></ul><ol start="22"><li><p>2-3树到红黑树</p></li><li><p>存储过程</p></li></ol><blockquote><p>存储过程可以说是一个记录集吧，它是由一些T-SQL语句组成的代码块，这些T-SQL语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就<br>由于数据库执行动作时，是先编译后执行的。然而存储过程是一个编译过的代码块，所以执行效率要比T-SQL语句高<br>一个存储过程在程序在网络中交互时可以替代大堆的T-SQL语句，所以也能降低网络的通信量，提高通信</p></blockquote><ol start="24"><li>linux 管道</li></ol><blockquote><p>管道是Linux中很重要的一种通信方式,是把一个程序的输出直接连接到另一个程序的输入,常说的管道多是指无名管道,无名管道只能用于具有亲缘关系的进程之间，这是它与有名管道的最大区别。</p></blockquote><ul><li>管道是一个固定大小的缓冲区。在Linux中，该缓冲区的大小为1页，即4K字节，使得它的大小不象文件那样不加检验地增长。使用单个固定缓冲区也会带来问题，比如在写管道时可能变满，当这种情况发生时，随后对管道的write()调用将默认地被阻塞</li><li>读取进程也可能工作得比写进程快。当所有当前进程数据已被读取时，管道变空。当这种情况发生时，一个随后的read()调用将默认地被阻塞，等待某些数据被写入，这解决了read()调用返回文件结束的问题。</li><li>半双工</li></ul><ol start="25"><li>request和response</li></ol><blockquote><p>Web服务器收到客户端的http请求，会针对每一次请求，分别创建一个用于代表请求的request对象、和代表响应的response对象</p></blockquote><ol start="26"><li>NIO</li></ol><blockquote><p>NIO主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector。传统IO基于字节流和字符流进行操作，而NIO基于Channel和Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector(选择区)用于监听多个通道</p></blockquote><ol start="27"><li>HashMap HashTable CocurrentHashmap LinkedHashMap TreeHashMap</li></ol><blockquote><p>JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry(ReentrantLock+Segment+HashEntry): volatile HashEntry&lt;K,V&gt; 确保可见性<br>DK1.8锁的粒度就是HashEntry（首节点）(synchronized+CAS+HashEntry+红黑树)</p></blockquote><ol start="28"><li>MVC 处理流程</li></ol><blockquote><p>用户发送请求至前端控制器DispatcherServlet<br>DispatcherServlet收到请求调用HandlerMapping处理器映射器<br>处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet<br>DispatcherServlet调用HandlerAdapter处理器适配器<br>HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)<br>Controller执行完成返回ModelAndView。<br>HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。<br>DispatcherServlet将ModelAndView传给ViewReslover视图解析器<br>响应客户</p></blockquote><ol start="29"><li>静态方法和实例方法</li></ol><blockquote><p>从逻辑关系来看：若方法与类的实例不存在逻辑上的联系，那么用静态方法。反之则最好使用实例化方法。<br>从性能角度:若方法经常被调用，则用静态方法更佳，因为这样可以避免频繁地实例化对象导致的资源占用，提高性能。然而，由于静态的东西，在构造的时候是在堆中声称的，在结束之前不会被释放与改变，会一直占用内存空间，所以不宜有过多的静态成员。<br>从线程并发的角度考虑:如果并发的可能性很大，则不适宜使用静态方法。如果并发的可能性很小，或者通过简单的同步操作可以保证线程安全，那就可以考虑使用静态方法</p></blockquote><ol start="33"><li>raft<br>leader candidate follower</li></ol><blockquote><p>leader负责对整个集群进行控制管理，同时接受客户端的请求。在整个集群中，不能同时出现多个leader，任何时刻只会有一个或者没有。<br>candidate就是处于选主阶段的状态，要么选举成功成为leader，要么退回到follower。<br>一般情况下大部分服务器都处于follower状态。跟随者可以理解为master-slave结构中的slave，就像是将军领导下的小兵。follower不会主动向集群发起消息</p></blockquote><ol start="34"><li><p>内连接左连接，完整型约束</p></li><li><p>top<br>P：CPU排序；M：排序</p></li><li><p>如何保障缓存一致性(缓存与数据库的双写一致性)<br>共识</p></li></ol><ul><li>缓存必须要有过期时间</li><li>保证数据库跟缓存的最终一致性即可，不必追求强一致性<br><a href="https://juejin.im/post/6844903941646319623" target="_blank" rel="noopener">数据库与缓存数据一致性问题</a><br>更新缓存的的Design Pattern有四种</li><li>Cache Aside Pattern<ul><li>失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中</li><li>命中：应用程序从cache中取数据，取到后返回。</li><li>更新：先把数据存到数据库中，成功后，再让缓存失效；更新的操作还有：<ul><li>先更新数据库,再写缓存 可能出现 AB 先后更新数据库,但更新缓存的顺序为BA 导致脏数据;其次如果并不确定该数据是否被频繁访问,如果每次更新数据库都更新缓存,可能造成缓存空间的浪费;所以更新不可取,删除更好(需求方主动触发缓存更新)</li><li>先更新缓存,然后更新数据库：更新操作可能失败,导致数据可能丢失,不能保证最终一致性(应当以数据库为主);同时也存在操作乱序的问题</li><li>先删除缓存,然后更新数据库：可能在 A在删除缓存 和更新数据库之间 出现B 缓存不命中,读取脏值到redis中的情况(在读写分离的情况下更为严重)</li><li>先更新数据库,然后删除缓存：可能出现缓存失效的情况下,A-&gt;读取旧值-&gt;B更新数据库-&gt;B删除缓存-&gt;A写旧值到到缓存(是否可以通过写redis时要求比较值的时间戳);但可能性低 同时主从读写分离的情况下,可能出现从库数据未脏数据的情况</li></ul></li><li>定时删除缓存(消息队列,过期时间);比较高频数据的写时间戳</li><li>删除缓存可能导致的缓存击穿 可以利用锁操作( set 在发现缓存为空时,竞争读写数据库的机会)</li></ul></li></ul><p>更强的一致性实现：分布式读写锁(共享读锁,在写锁存在的情况下不可以申请读锁)</p><ol start="37"><li>redis 锁<br>单节点 锁INCR、SETNX、SET</li></ol><ul><li>SETNX：排他性;该命令只会在键不存在的情况下才会为键设置值,这样当别的进程再去使用这个命令设置这个键的时候就会失败进而无法获得锁</li><li>避免死锁：在获得setnx 同时设置锁的过期时间;</li><li>释放锁时检查:A在获得锁之后,超时自动释放而不自知,但后续主动释放已经被B获得的锁,破坏了B涉及的互斥过程。</li></ul><p>分布式锁<br>共识算法<br>raft paxos gossip</p><p>CopyOnWriteArrayList 线程安全</p><blockquote><p>CopyOnWriteArrayList 不强调线程之间的同步,强调数据的共享(对于可能的写不干扰其他读)<br>对于所有涉及修改的操作,加锁,其实现都是复制一个与原本数据已知的数组对象,然后把指针指向这个对象;相当于线程的私有变量,随着线程的消亡而消亡(可能会面临内存泄漏的问题)<br>适合于读多写少的场景,但是对于数据量比较大的场景,复制会比较消耗时间,在完成之前访问,仍然获得旧数据</p></blockquote><p>如何存储一个弹幕系统的弹幕，使用redis的什么类型，怎么保证热点数据，每秒会产生大量的数据，redis扛不住怎么办<br><a href="https://www.cnblogs.com/java920043111/p/9286123.html" target="_blank" rel="noopener">bilibili 高并发实时弹幕系统的实现</a><br>消息队列  udp广播</p><p>spring AOP，JDK和CGlib的区别，除了针对接口和类以外的不同</p><blockquote><p>java动态代理是利用反射机制生成一个实现代理接口的代理类，在调用具体方法前调用InvokeHandler来处理。</p><ul><li>JDK代理是不需要以来第三方的库，只要要JDK环境就可以进行代理<br>而cglib动态代理是利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。</li><li>CGLib 必须依赖于CGLib的类库</li></ul></blockquote><p>实现 ReadWriteLock</p><p><a href="https://www.cnblogs.com/yihujiu/p/6379279.html" target="_blank" rel="noopener">大量日志查找</a><br>HAdoop mapreduce</p><p>Docker容器本质上是宿主机上的进程，卷相当于容器的磁盘。</p><blockquote><p>Docker通过nampespace实现了资源隔离，通过cgroups实现了资源限制，通过写时复制机制（copy-on-write）实现了高效的文件操作。</p></blockquote><p>轻量级锁</p><blockquote><p>他的出现并不是代替重量级锁，而是在没有多线程竞争的前提下，减少系统互斥量操作产生的性能消耗<br>锁战友的而时间步长</p></blockquote><p><a href="https://blog.csdn.net/scdn_cp/article/details/86491792" target="_blank" rel="noopener">无锁 -&gt; 偏向锁 -&gt; 轻量级 -&gt; 重量级</a></p><ul><li>初期锁对象刚创建时，还没有任何线程来竞争，对象的Mark Word是下图的第一种情形，这偏向锁标识位是0，锁状态01，说明该对象处于无锁状态</li><li>当有一个线程来竞争锁时，先用偏向锁，表示锁对象偏爱这个线程，这个线程要执行这个锁关联的任何代码，不需要再做任何检查和切换，这种竞争不激烈的情况下，效率非常高。这时Mark Word会记录自己偏爱的线程的ID，把该线程当做自己的熟人。如下图第二种情形</li><li>当有两个线程开始竞争这个锁对象，情况发生变化了，不再是偏向（独占）锁了，锁会升级为轻量级锁(monitorenter)，两个线程公平竞争，哪个线程先占有锁对象并执行代码，锁对象的Mark Word就执行哪个线程的栈帧中的锁记录。如下图第三种情形</li><li>如果竞争的这个锁对象的线程更多，导致了更多的切换和等待，JVM会把该锁对象的锁升级为重量级锁，这个就叫做同步锁，这个锁对象Mark Word再次发生变化，会指向一个监视器对象，这个监视器对象用集合的形式，来登记和管理排队的线程</li></ul><p><a href="https://www.xttblog.com/?p=4881" target="_blank" rel="noopener">Java为什么要引入偏向锁？</a><br>Java 对象头 记录 锁的状态以及当前线程ID 或时间戳<br>堆栈中记录着当前持有的锁的对象</p><p><a href="https://juejin.im/post/6844904023540105229" target="_blank" rel="noopener">Class.forName &amp; ClassLoader.loadClass 比较</a><br><a href="https://juejin.im/post/6873691965892853767" target="_blank" rel="noopener">new Object()到底占用几个字节，看完这篇就彻底明白了</a></p><p>mysql里什么是检查点、保存点和中间点？：w</p><p>Object 有哪些方法？</p><ul><li>hashCode</li><li>equals 之间判断地址是否相等,可重写</li><li>clone  默认仅仅是复制引用,浅拷贝; 重写该接口必须 实现Cloneable接口</li><li>toString 对象名@hashcode</li><li>notify notifyAll wat</li><li>protected finalize 垃圾回收器准备释放内存的时候，会先调用finalize(),并且只会调用一次(可能会出现方法)</li></ul><h2 id="算法">算法</h2><h3 id="排序算法">排序算法</h3><table><thead><tr><th>算法名</th><th>稳定</th><th>时间复杂度</th><th>空间复杂度</th><th>核心思想</th></tr></thead><tbody><tr><td>插入排序</td><td>稳定</td><td>O(n^2)</td><td>O(1)</td><td>在数组中实现,第一个节点构成的集合是有序的,然后依次增加集合相邻的元素进入,采取后移和插入的方式实现集合内的有序,直至集合包含所有元素</td></tr><tr><td>冒泡排序</td><td>稳定</td><td>O(n^2)</td><td>O(1)</td><td>循环的比较相邻的值,如果前者大于后者则调换位置,一次遍历可以把最大的放置在最后,然后可以放置次大</td></tr><tr><td>归并排序</td><td>稳定</td><td>O(nlogn)</td><td>O(n)</td><td>将数组分割为N个集合,集合内归并排序,然后合并集合</td></tr><tr><td>计数排序</td><td>稳定</td><td>O(n+k)</td><td>O(n+k)</td><td>在数组最大值和最小值的空间内,统计数组中每个元素出现的次数,然后输出即可</td></tr><tr><td>桶排序</td><td>稳定</td><td>O(n+k)</td><td>O(n+k)</td><td>可以把某个范围定义为桶,把元素分割到各个桶内,桶内使用任何排序使得有序,然后整体有序</td></tr><tr><td>基数排序</td><td>稳定</td><td>O(n*k)</td><td>O(n+k)</td><td>根据数组元素,将元素分为N个关键字,每次针对一个关键字排序,N个关键字排序之后保持有序</td></tr><tr><td>希尔排序</td><td>不稳定</td><td>O(n^1.3)</td><td>O(1)</td><td>设定步长为N,共可得到N个每个元素相邻下标为N的元素集合,集合内部插入排序,然后 不断缩减步长到1;由于 减少了集合间元素的比较,在当步长越小,集合也变得大体有序</td></tr><tr><td>选择排序</td><td>不稳定</td><td>O(n^2)</td><td>O(1)</td><td>选择最小/最大值到开头或者末尾,在剩下的元素中选择最小/最大,添加进之前的有序末尾</td></tr><tr><td>堆排序</td><td>不稳定</td><td>O(nlogn)</td><td>O(1）</td><td>基于完全二叉树,所以可以使用数组实现; 首先根据N个输入元素构建完全而二叉树;然后从节点N/2——1开始自下而上调整树,调整最大堆;随后将最大值和节点N互换,自上而下调整树,再次得到最大堆,持续可得到有序输出</td></tr><tr><td>快速排序</td><td>不稳定</td><td>O(nlogn)</td><td>O(nlogn)</td><td>通过选定一个基准,将所有小于该基准的放在左边,大于该基准的放在右边,随后对基准左右分别快排,获得全局有序</td></tr></tbody></table><p>mysql 事务的实现</p><blockquote><p>锁+MVCC<br>锁：读写锁/共享独占锁(二阶段锁提交)+间隙锁/临界锁(在二段加锁的情况下,可能导致死锁)<br>MVCC：undolog 实现未提交事务的原子性(redolog 保证已提交事务的持久性)<br>MVCC 是快照读,不能读创建readview之后提交的事务的更新,可以添加for update 强制当前读<br>innodb的RR隔离级别下,读自动开启行锁和间隙锁构成next-key锁,配合MVCC 解决幻读或者直接串行化</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM</title>
      <link href="/2020/08/15/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/JVM/"/>
      <url>/2020/08/15/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/JVM/</url>
      
        <content type="html"><![CDATA[<ol><li>JVM 内存</li></ol><ul><li>方法区：存放类运行时必须的结构信息,比如类的静态变量,常量,类的全局名称,方法信息,父类引用等如</li><li>堆：实际存储对象的地方,占据大量内存,主要GC对象,具体可以分为老年堆和年轻堆</li><li>虚拟机栈：每个线程都有一个自己独立的Java栈，每次线程执行到一个新的方法时就在栈里面压入一个栈帧。帧里包含了方法里的局部变量，操作数栈(数据运算)以及帧数据区。这三种区域中局部变量很好理解，就是在方法作用范围内的变量，包括基本变量和对象的引用</li><li>本地方法栈：调用系统提供的方法时,涉及的机制和数据</li><li>PC寄存器：线程运行时对于程序运行中的位置和状态的标识</li></ul><ol start="2"><li>类加载/Class.forName</li></ol><ul><li>class文件记载到内,把字节码文件转换为二进制文件</li><li>在方法区中形成内部数据结构</li><li>验证类文件中数据合法性</li><li>初始化的过程（主要给静态变量和静态块初始化）</li></ul><ol start="3"><li>实例化/newInstance</li></ol><ul><li>在堆中生成一个对象实例</li><li>对实例的内部变量初始化</li></ul><p>Eden区与Survivor的比例较大，HotSpot默认是 8:1，即分别占新生代的80%，10%，10%。如果一次回收中，Survivor+Eden中存活下来的内存超过了10%，则需要将一部分对象分配到 老年代。用-XX:SurvivorRatio参数来配置Eden区域Survivor区的容量比值，默认是8，代表Eden：Survivor1：Survivor2=8:1:1.<br>Major GC vs Full GC<br>Major GC 是清理永久代。Full GC 是清理整个堆空间—包括年轻代和老年代  永久代(方法区)<br>堆大小=新生代+老年代，新生代与老年代的比例为1：2，新生代细分为一块较大的Eden空间和两块较小的Survivor空间，分别被命名为from和to。(方便复制-清除；from to GC后交换角色)</p><p>大对象直接进入老年代，实际上是为了保证Eden区具有充足的空间可用的一种策略(复制算法耗时，好空间)</p><p>垃圾收集器: 垃圾收集器是垃圾回收算法（标记-清除算法、复制算法、标记-整理算法、火车算法）的具体实现<br>新生代收集器：Serial、ParNew、Parallel Scavenge<br>老年代收集器：Serial Old、Parallel Old、CMS；<br>整堆收集器：G1</p><ul><li>Serial收集器：新生代收集器，使用停止复制算法，使用一个线程进行GC，其它工作线程暂停</li><li>ParNew收集器：serial 多线程版本(除Serial外，目前只有它能与CMS收集器配合工作)</li><li>Parallel Scavenge:目标新生代,复制算法,多线程,但 CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间,而Parallel Scavenge收集器的目标则是达一个可控制的吞吐量（Throughput:吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间））；</li><li>Serial Old :目标老年代,标记整理,单线程</li><li>Parallel Old： serial的多线程版</li><li>cms：并发标记清理,针对老年代,标记清除(内存碎片);并发收集(使得用户线程可以工作)：浮动垃圾和内存碎片</li><li>G1（Garbage-First）<br>- 能充分利用多CPU、多核环境下的硬件优势；可以并行来缩短&quot;Stop The World&quot;停顿时间；也可以并发让垃圾收集与用户程序同时进行<br>- 分代收集，收集范围包括新生代和老年代：能独立管理整个GC堆（新生代和老年代），而不需要与其他收集器搭配；<br>- 结合多种垃圾收集算法，空间整合，不产生碎片：从整体看，是基于标记-整理算法；从局部（两个Region间）看，是基于复制算法；这是一种类似火车算法的实现；<br>- 可预测的停顿：低停顿的同时实现高吞吐量,可预测的停顿：低停顿的同时实现高吞吐量<br>- 场景：服务端</li></ul><p>GC是什么时候触发的（面试最常见的问题之一）<br>由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Minor GC和Full GC。<br>采用“分代式垃圾收集”。这种方法会跟Java对象的生命周期将堆内存划分为不同的区域，在垃圾收集过程中，可能会将对象移动到不同区域：</p><ul><li>伊甸园（Eden）：这是对象最初诞生的区域，并且对大多数对象来说，这里是它们唯一存在过的区域。</li><li>幸存者乐园（Survivor）：从伊甸园幸存下来的对象会被挪到这里。</li><li>终身颐养园（Tenured）：这是足够老的幸存对象的归宿。年轻代收集（Minor-GC）过程是不会触及这个地方的。当年轻代收集不能把对象放进终身颐养园时，就会触发一次完全收集（Major-GC），这里可能还会牵扯到压缩，以便为大对象腾出足够的空间</li></ul><p>Minor GC：<br>  一般情况下，当新对象生成，并且在Eden申请空间失败时，就会触发Minor GC，对Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。这种方式的GC是对年轻代的Eden区进行，不会影响到年老代。因为大部分对象都是从Eden区开始的，同时Eden区不会分配的很大，所以Eden区的GC会频繁进行。因而，一般在这里需要使用速度快、效率高的算法，使Eden去能尽快空闲出来。<br>Full GC ：<br>对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于Full GC的调节。有如下原因可能导致Full GC：<br>a) 年老代（Tenured）被写满；<br>b) 持久代（Perm）被写满；<br>c) System.gc()被显示调用；<br>d) 上一次GC之后Heap的各域分配策略动态变化；<br>面试题：jvm查看gc命令<br>jstat -gc 12538 5000<br>即会每5秒一次显示进程号为12538的java进成的GC情况，<br>面试题：如果频繁老年代回收怎么分析解决(蚂蚁金服面试题)<br>（个人理解）老年代是存放那些在程序中经历了好几次回收仍然还活着或者特别大的对象（这个大就要看你是否设置了-XX：PretenureSizeThreshold 参数了）。检查程序中是否有比较大的对象，或者这个参数设置是否合理。</p><ol start="5"><li>Java 内存模型（JMM）</li></ol><blockquote><p>Java内存区域:PC+堆+本地方法栈+线程栈+方法区<br>JMM:线程 和线程私有的工作内存(栈) 通过缓存一致性协议 实现对主内存的读写<br><img src="/images/JMM.png" alt="JMM"></p></blockquote><p>JVM 调优参数<br>CyclicBarrier的使用<br>CountDownLatch CyclicBarrier的使用</p><blockquote><p>多人回合制游戏(赛跑终点结束重新开始)<br>CyclicBarrier<br>包含一个可重入锁,该锁的condition,满足条件之后执行的任务(需要在其中设置退出条件不然无法退出),已经等待的人数<br>方法：dowait:将调用线程 添加进condition的阻塞队列中,执行condition.wait 等待notifyAll(最后一个进入者执行既定任务,并重置一切);reset 重置一切重新使用</p></blockquote><p>GC 对象复制之后 的forward point<br>OOpmap Cardtbale</p><p>fail-fast fail-safe</p><p>讲讲进程fork多个子进程和使用多线程的区别</p><ul><li>线程内fork进程,只能复制当前的线程</li><li>数据共享同步:进程间共享复杂,需要使用IPC,由于数据分离 所以同步简单,不需要加锁</li><li>资源(内存CPU)：进程占据资源多,切换复杂,CPU利用率低;</li><li>创建销毁：</li><li>编译调试复杂度</li><li>可靠性：进程之间不会有影响,线程挂了可能影响进程</li><li>分布式：进程适应天生支持分布式</li></ul><p>既然JVM有Full GC，为什么还会出现OutOfMemoryError?</p><ul><li>gc不了</li><li>产生对象太快来不及GC，GC需要安全点</li></ul><p>虚拟机性能检测工具</p><ul><li>jstat 虚拟机统计信息监控 -gc</li><li>jps：虚拟机进程状况检测</li><li>jinfo：java配置工具</li><li>jmap：java内存隐射工具</li><li>jstack java堆栈追踪工具</li><li></li></ul><p>升级老年代</p><ul><li>分配担保(允许担保失败的情况下进行mirroGC 可能引发fullgc)</li><li>年轻代 过15次GC</li><li>survior区的相同年龄的对象大于survior区的一般容量的话,那么大于这个年龄的进入老年代</li></ul><h2 id="jvm-调优">JVM 调优</h2><h2 id="synchronize-vs-lock-object-vs-condition">synchronize VS lock   object VS condition</h2><h3 id="synchronize">synchronize</h3><p>对象锁,保证只有一个线程能够获得锁,执行方法或者代码块,隐式的获得释放锁,无法感知中断<br>可重入</p><h3 id="lock">lock</h3><p>相对于synchronize 更加灵活,需要显示的获得以及释放锁,可感知中断(lockInterruptly)<br>其实现ReentrantLock 实现了lock接口,提供申请锁释放锁等基本功能<br>ReentrantReadWriteLock实现了ReadWriteLock接口,读写分离,允许多线程读只允许一个线程写</p><h3 id="object-vs-condition">object VS condition</h3><p>Object</p><ul><li>wait:只能由获得锁的线程执行,释放锁并将自己放置在该对象的等待队列</li><li>notify:只能由获得锁的线程执行,会从该对象的等待队列中释放出一个线程,并不保证释放锁</li></ul><h3 id="blockedsynchronize-vs-waittingwait">blocked(synchronize) vs (waitting)wait</h3><p><a href="https://www.zhihu.com/question/27654579/answer/254496076" target="_blank" rel="noopener">参考</a><br>线程新增了waitting 和 time-waitting 状态<br>synchronize会导致线程陷入blocked状态,调用wait/LockSupport.park方法会导致线程陷入wait状态;notify会导致线程从waitting状态变为blocked状态</p><ul><li>blocked状态:对锁的等待导致陷入blocked,获得锁则进入ready或者运行态</li><li>waitting:调用 wait 或者 t.join 或者 LockSupport.pack 进入waiting态,notify/unpack 进入 block态</li><li>timed waitting:waiting方法中的增加了时间,以sleep方法(sleep方法不释放锁,时间过后进入就绪态) 超时或者被唤醒会进入block态</li></ul><p>thread yeild 将线程从运行态转化为就绪态</p><h3 id="objectwait-vs-conditionawait">object.wait  VS condition.await</h3><p>后者需要配合 lock使用,在利用CAS操作释放锁之后,执行LockSupport.park操作休眠线程,进入waitting态,等待unpack唤醒,进入阻塞 不需要处理中断异常(lock的lockinterrupt()中对此有相关处理)<br>前者有系统提供支持,需要处理中断异常</p><h3 id="aqs-过程">AQS 过程</h3><h4 id="不包含condition">不包含condition</h4><p>lock操作尝试获取锁,失败后,将自己封装为head的next节点,只要自己的前继节点一直是head节点,那么死循环尝试获得锁,直到获得锁或者前继节点不是head节点,从而将调用LockSupport.park将自己休眠转化为waitting态<br>unlock操作: 独占状态下,如果不再占有所,那么CAS更新独占线程标志位为null,并更新state否则仅更新state;根据该节点的waitstatus 决定是否通知后续的节点,如果通知那么会调用LockSupport.unpack 该节点的线程 进入阻塞态</p><h4 id="包含condition">包含condition</h4><p>condition的操作必然是在获得锁的前提下,进行的,等同object的操作<br>lock获得锁成功<br>condition.await():CAS 更新state,放弃锁,并调用LockSupport.park 放弃CPU时间<br>此时因此而获得锁的线程执行signal操作,会找到该condition的阻塞队列里找到一个满足条件的 node,并调用LockSupport.park释放该node的线程,而线程获得CPU时间后,从LockSupport.park中返回,并尝试重新获得锁,要么获得锁或者陷入对lock的阻塞队列中<br>如果获得锁,那么执行await后续代码,最后unlock释放锁</p>]]></content>
      
      
      
        <tags>
            
            <tag> Java 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Algorithm</title>
      <link href="/2020/07/21/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Algorithm/"/>
      <url>/2020/07/21/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Algorithm/</url>
      
        <content type="html"><![CDATA[<p>算法概述</p><h2 id></h2><p>递归<br>动态规划</p><p>###并查集<br><a href="https://blog.csdn.net/qq_19782019/article/details/78916595" target="_blank" rel="noopener">size数组和rank数组</a><br>题目:<a href="https://leetcode-cn.com/problems/number-of-islands" target="_blank" rel="noopener">leetcode 200</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DataStructure</title>
      <link href="/2020/07/21/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/DataStructure/"/>
      <url>/2020/07/21/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/DataStructure/</url>
      
        <content type="html"><![CDATA[<p>算法概述</p><h2 id></h2><p>递归<br>动态规划<br>树</p><h3 id="其他">其他</h3><p><a href="https://www.cnblogs.com/jason2003/p/9676729.html" target="_blank" rel="noopener">线段树</a></p><blockquote><p>这个东西感觉挺有意思</p></blockquote><p>红黑树</p>]]></content>
      
      
      
        <tags>
            
            <tag> DataStructure 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络</title>
      <link href="/2020/07/06/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/07/06/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="基础问题">基础问题</h2><h3 id="http-报文键值对">http 报文键值对</h3><blockquote><p>host<br>Content-*<br>ACCEPT<br>COOKIE</p></blockquote><h3 id="osi-7层">OSI 7层</h3><ul><li>物理层：电路交换 报文交换 分组交换</li><li>数据链路层：组帧,差错控制,流量控制,介质访问(频分时分波分码分复用)</li><li>网络层：异构网络互联;路由与转发;拥塞控制<ul><li>ARP：查询IP与MAC地址的映射;DHCP：动态分配IP;ICMP:允许主机以及路由器报告差错情况;TRACEROTE</li><li>NAT CIDR(路由聚合)</li><li>OSPF RIP</li></ul></li><li>传输层：传输层寻址与端口;无连接服务和有连接服务<ul><li>UDP:无连接不可靠,数据校验(源端口目的端口;udp报文长度;校 验和; 数据)</li><li>TCP：连接管理：可靠传输;流量控制和拥塞控制(源目的端口：序号确认号数据偏移;标志位：SYN ACK PUS FIN RST ；校验和 窗口字段)</li></ul></li><li>会话层</li><li>表示层(加密)</li><li>应用层：CS 模式 P2P模式<ul><li>PING;HTTP:TCP 80</li><li>DNS udp 53</li><li>FTP TCP 2021</li><li>EMAIL:TCP SMTP:25 POP3 110</li></ul></li></ul><h3 id="close_wait-和-time_wait">close_wait 和 time_wait</h3><blockquote><p>close_wait 在 被关闭防 接收到fin报文时,发出ack 报文 进入close_wait状态 ,发送完报文,调用close(),close_wait 状态结束<br>socket 其实就是一个五元组，包括：源IP, 源端口, 目的IP, 目的端口, 类型(TCP or UDP)<br>TIME_WAIT</p><ul><li>防止前一个连接上延迟的数据包或者丢失重传的数据包，被后面复用的连接错误的接收</li><li>确保连接方能在时间范围内，关闭自己的连接(考虑到丢包的情况)</li></ul></blockquote><p>在高并发短连接的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接,避免有时出现客户端连接不上</p><ul><li>高并发导致服务器过多使用端口资源(0-65535)</li><li>短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接。<br>解决：</li><li>开启SYN cookie</li><li>开启 tcp_tw_reuse 允许TIME_WAIT的socket重用于TCP连接</li><li>开启 tcp_tw_recycle,开启TCP连接中TIME-WAIT sockets的快速回收,会丢弃时间戳较小的syn报文(在最新的linux内核中放弃这个参数,可能导致tcp网络极不稳定)</li></ul><h4 id="time_wait-和-close_wait大量出现">time_wait 和 close_wait大量出现</h4><blockquote><p>当time_wait(2MSL 60S) 比较多时,客户建立的连接没有有效利用 ,可以考虑tcp长连接复用;</p></blockquote><blockquote><p>大量close_wait的现象，主要原因是某种情况下对方关闭了socket链接，但是我方忙与读或者写，没有关闭连接</p></blockquote><p>tcp为什么可靠，和udp的区别，序号的作用除了可靠性还有什么？</p><ul><li>校验</li><li>序列号和确认机制</li><li>序列号</li><li>重传机制</li></ul><h3 id="tcp三次握手四次挥手为什么要三次握手">TCP三次握手四次挥手，为什么要三次握手</h3><blockquote><p>三次握手是为了避免两次握手带来的漏洞（如果两次建立连接，那么假设A-&gt;B，B-&gt;A的请求未到达，B认为链接建立，放数据，A认为链接未建立，不接受数据，B数据超时会再重发，引发锁）<br>四次挥手：最后一次挥手可能应为网络原因而丢失，故等待2MSL再没收到FIN 则认为对方收到了最后一次挥手<br>数据传输，所以四次挥手而非3次</p></blockquote><p>TCP拥塞协议，tcpudp区别</p><ul><li>是否连接</li><li>是否可靠传输,保证有序</li><li>一对读通信,udp广播多播</li><li>面向报文,面向字节流</li><li>首部开销</li><li>使用场景：适用于实时场景(视频频电话直播),可靠的传输(文件数据传输)</li></ul><h3 id="http和https区别">HTTP和HTTPs区别</h3><blockquote><p>http：超文本传输协议，明文传播<br>https： TCP 层与 HTTP 层之间加入了 SSL/TLS;http+ssl加密数据；<br>对称加密，非对称加密（公钥加密，私钥解密，GitHub，ssh，身份签名）</p></blockquote><h3 id="http">HTTP</h3><blockquote><p>Method<br>GET: 获取资源###<br>HEAD: 获取报文头部###<br>POST: 传输实体主体###<br>PUT: 传输文件###<br>DELETE: 删除文件###<br>OPTIONS: 询问支持方法####<br>Status Code：<br>200 （成功） 服务器已成功处理了请求<br>301 （永久移动） 永久重定向<br>302 （临时移动）<br>304 （未修改） 自从上次请求后，请求的网页未修改过。<br>307 （临时重定向） 服务器目前从不同位置的网页响应请求<br>401 （未授权） 请求要求身份验证<br>403 （禁止） 服务器拒绝请求<br>404 （未找到） 服务器找不到请求的网页<br>500 （服务器内部错误） 服务器遇到错误，无法完成请求<br>502 （错误网关） 服务器作为网关或代理，从上游服务器收到无效响应</p><p>HTTP vs HTTPS<br>https=http+对于数据进行SSL（Secure Sockets Layer）加密<br>1.https协议需要到ca申请证书，一般免费证书较少<br>2.http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议<br>3.http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443<br>4.http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全</p></blockquote><h3 id="http报文格式">http报文格式</h3><p>请求报文</p><ul><li>请求行：方法,url 协议版本 (GET /index.html HTTP/1.1)</li><li>请求头部 header 键值对(User-Agent,Accept,Host)</li><li>请求数据:GET 中不使用,POST中使用<br>响应报文</li><li>状态行：HTTP-Version Status-Code Reason-Phrase(状态代码的文本描述)</li><li>消息报头</li><li>响应正文</li></ul><p>GET VS POST</p><ul><li>数据位置:GET提交,请求的数据会附在URL之后,POST提交：把提交的数据放置在是HTTP包的body中</li><li>数据长度:GET:特定浏览器和服务器对URL长度有限制，例如IE对URL长度的限制是2083字节(2K+35) 而 POST对提交数据的大小有限制</li><li>安全性</li></ul><h4 id="ipv4-报文格式">IPV4 报文格式</h4><ul><li>版本 首部长度 总长度</li><li>标识 标志 片偏移(数据报分组之后在元报文的偏移量;数据链路层有最大报文传输单元限制MTU)</li><li>生存时间 具体协议(TCP UDP) 首部校验和</li><li>源目的地址</li><li>可选字段 填充</li><li>数据</li></ul><p>路由算法</p><ul><li>OSPF</li><li>RIP</li></ul><h4 id="dns">DNS</h4><p>13台根服务器 顶级域名服务器  权限域名服务器 本地域名服务器<br>定义域名 一级域名  二级域名<br>域名解析服务器分类：</p><ul><li>主域名服务器：负责维护一个区域所有域名信息，为特定域名的所有信息的权威来源，可以修改信息。</li><li>辅助域名服务器：当主域名服务器出现故障，关机或负载过重等情况，辅助域名服务器作为备份服务器来提供域名解析服务，辅助域名服务器是从另一台远程域名服务器下载的所有域名信息，域名信息不具有修改权限</li><li>缓存域名服务器：当从远程域名服务器获得域名解析信息后，将其缓存到高速缓存中，当下次需要请求相同的域名解析时，直接从本地缓存中读取，缓存域名信息不具有权威性</li><li>转发域名服务器：转发域名服务器用来请求不在本地域名服务器上的信息，当收到域名请求服务时，现在本地缓存中查取，如果查询不到。即依次向指定的域名服务器发出请求，直到查到所需信息返回结果。否则，返回无法映射的信息。<br>dig :命令主要用来从 DNS 域名服务器查询主机地址信息</li></ul><h4 id="浏览器访问wwwbaiducom的过程"><a href="https://blog.nowcoder.net/n/a8337baa9c554acdab25b898f7b0970b" target="_blank" rel="noopener">浏览器访问www.baidu.com的过程</a></h4><blockquote><p>DNS域名解析:从浏览器缓存中获取,从本机/操作系统中尝试查找域名(host文件)</p><ul><li>如果在局域网,可能在路由器或者在ISP存在缓存</li><li>询问本地域名服务器,本地域名没有的话,询问根域名服务器,如果是迭代的话,可能从根域名服务器获得下一步需要去查询的顶级域名服务器,可能获得下一步的授权域名服务器,获得真实的IP,缓存并返回给主机。<br>获得ip 然后发送TCP连接</li></ul></blockquote><p>tcpdump</p><blockquote><p>使用tcpdump抓包在卡顿的时候会抓到大量的syn请求</p></blockquote><p>SYN FLOOD</p><blockquote><p>前提:服务端在第二次握手时,就分配相关资源给该tcp连接<br>synflood利用这一缺陷,大量发送syn request包,耗尽服务端的资源从而使之无法提供正常服务<br>解决：<br>限制ip的访问次数<br>开启syncookie:在第二次握手时,不分配资源而是根据syn包的一些信息以及自己的秘钥经过算法计算出cookie值,下次返回ack 再计算一次,相同才开始分配资源;延迟资源分配到简历真正连接的时候</p></blockquote><p>http1 VS http1.1</p><ul><li>http1:增加HTTP头、扩展PUT、POST等方法</li><li>HTTP1.1 :长连接、流水线支持，最广泛使用的HTTP传输协议</li></ul><p>粘包问题</p><blockquote><p>传输层有两种协议，TCP和UDP。TCP是面向流的，UDP是面向报文的；<br>应用层需要提取传输层的数据，在使用UDP协议时，可以提取完整的报文，但是使用TCP报文时，无法保证提取完整的报文，需要将收到的报文按照字节序排序完成后提取<br>由于TCP是可靠的，面向连接的，每次报文传输的代价相对于UDP更大，通常会避免频繁发小报文，按照nagle算法 会积累一定的小报文，集中发送，但是而接收方接到报文后，需要按照预设的分隔标记从中提取多个小报文。<br>解决方法:<br>1.在发送数据前，将自己要发送的字节流大小告知接收方。(可能增加传输和等待回应所带来的时间损耗)<br>2.在TCP报文头的基础上，为字节流增加固定窗长度报文头，增加字节流的实际长度。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OS</title>
      <link href="/2020/07/06/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/OS/"/>
      <url>/2020/07/06/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/OS/</url>
      
        <content type="html"><![CDATA[<h2 id="线程状态及各状态之间的转换">线程状态及各状态之间的转换</h2><blockquote><p>新建状态、就绪状态、运行状态、阻塞状态及死亡状态</p></blockquote><h2 id="进程的内存结构">进程的内存结构</h2><blockquote><p>可执行文件的内容：代码段、数据段、BSS段和其他段<br>代码段：代码<br>数据段：存储初始化了的全局静态变量和局部静态变量和只读数据<br>BSS段（Block Start By Symbol）:未初始化的全部静态变量和局部静态变量，为其预留空间<br>其他段；保存于程序相关的其他信息，比如编译器信息，调试信息，动态链接信息等</p><p>装载可执行文件后，进程的空间大致可分为 代码区、数据区（bss+数据段）、向上的堆和向下的栈<br>代码段：可读可执行<br>数据段：可读可写<br>堆：malloc 等程序员申请空间<br>栈：系统运行时产生的变量，比如运行系统的信息、方法的参数、方法返回地址、局部变量等</p></blockquote><h2 id="线程的内存结构">线程的内存结构</h2><blockquote><p>线程共享进程的代码段，数据段，堆段，但是每个线程都拥有自己的私有栈，存储线程 ID、栈指针、PC、通用目的寄存器和条件码。<br>Linux的线程栈是在进程的堆空间申请的。<br>linux线程同步：<a href="https://www.cnblogs.com/yinbiao/p/11190336.html" target="_blank" rel="noopener">https://www.cnblogs.com/yinbiao/p/11190336.html</a><br>互斥锁（临界区）：特殊全局变量划分临界区<br>条件变量：等待该变量发生变化的等待队列，线程因特定条件休眠<br>信号量：互斥锁只允许一个线程进入临界区，而信号量允许多个线程进入临界区<br>读写锁：可以同时读，但不可以同时写</p></blockquote><h2 id="fork">fork</h2><blockquote><p>fork()函数用于从一个已经存在的进程内创建一个新的进程，新的进程称为“子进程”，相应地称创建子进程的进程为“父进程”。使用fork()函数得到的子进程是父进程的复制品，子进程完全复制了父进程的资源，包括进程上下文、代码区、数据区、堆区、栈区、内存信息、打开文件的文件描述符、信号处理函数、进程优先级、进程组号、当前工作目录、根目录、资源限制和控制终端等信息，而子进程与父进程的区别有进程号、资源使用情况和计时器等</p><p>由于复制父进程的资源需要大量的操作，十分浪费时间与系统资源，因此Linux内核采取了写时拷贝技术（copy on write）来提高效率<br>在使用fork()函数创建子进程的时候，在调用fork()函数前是一个进程在执行这段代码，而调用fork()函数后就变成了两个进程在执行这段代码。两个进程所执行的代码完全相同，都会执行接下来的if-else判断语句块。</p><p>当子进程从父进程内复制后，父进程与子进程内都有一个&quot;pid&quot;变量：在父进程中，fork()函数会将子进程的PID返回给父进程，即父进程的pid变量内存储的是一个大于0的整数；而在子进程中，fork()函数会返回0，即子进程的pid变量内存储的是0；如果创建进程出现错误，则会返回-1，不会创建子进程。</p></blockquote><blockquote><p>父进程pid和子进程pid的大小关系<br>如果进程ID最大值没有达到系统进程数的上限,子进程比父进程ID大.<br>但是如果进程ID达到上限,系统会分配之前分配但是已经退出的进程ID给新进程,这样有可能出现子进程ID比父进程小.</p></blockquote><p>需要注意的是在一个线程中,调用fork函数,只会复制进程空间内该线程,不会复制其他线程(在当前线程上下文操作,该线程不能感知其他线程)</p><h2 id="内存管理">内存管理</h2><h3 id="非连续分配管理方式">非连续分配管理方式</h3><blockquote><p>允许程序分散的装入不相邻的内存分区 配合后面的虚存技术<br>固定分区会产生内部碎片,动态分配会产生外部碎片<br>根据分区的大小是否固定又分为 分页存储管理方式(基本分页存储管理方式和请求分页管理方式) 和 分段存储管理方式</p></blockquote><h4 id="基本分页管理方式">基本分页管理方式</h4><p>页的大小一般为4K(大小有页面大小和管理页的开销决定;内存为页帧,外存称之为块)<br>从而把64位地址空间分为 页号和页内偏移量<br>页表 为 <code>页号</code> 和 <code>块号</code> 的 对应<br>系统中存在页表寄存器,包含 <code>页表的起始地址</code> <code>页表长度</code><br>而每个进程都在进程控制块PCB存储自己的 页表寄存器值,当进程运行时将值放进页表寄存器 将进程内部的地址与之对应,把进程的虚拟地址的页号与之相对应 获取真实的块号(由于每次访存操作都涉及逻辑地址到物理地址的转换所以转换速度必须快,而且在内存中都需要存储页表 =&gt; 页表项即页号不能太大,页不能太小 同时 页太大会导致 内存利用率低加载慢 取折中 4K)</p><p>存储一个数据至少需要访问两次内存</p><ul><li>首先访问页表,获取块号</li><li>如果块在内存,就在内存中读取</li></ul><p>为了降低第一次访存的消耗,引入快表(联想寄存器TLB),即利用时间局部性原理 存储最近的页号和块号的映射</p><p>为了避免一层页表导致占据太多进程内存空间,引入多级页表(64位地址分为n级页号-1级页号),使得只需要保持当前使用的页表在内存即可(通过n级页号锁定n级页表)</p><h3 id="虚拟内存管理">虚拟内存管理</h3><p>处于局部性原理,不需要把进程的数据一次性装入内存;利用虚存技术,可以将内存的数据多次装入内存同时由于局部性原理保证程序的运行正常<br>虚拟存储器基于局部性原理,给用户提供了远大于内存的空间;</p><h4 id="请求分页式">请求分页式</h4><p>页表机制+缺页中断机制+地址变换机制<br>页表项= 页号 + 物理块号 + 状态位(是否在内存) + 访问字段 + 修改位 + 外存地址<br>访问字段：用于记录页面在一段时间内的访问次数以及多长时间未被访问</p><h4 id="请求分段式">请求分段式</h4><h4 id="请求段页式">请求段页式</h4><h2 id="协程">协程</h2><blockquote><p>又称微线程，纤程。英文名Coroutine;<br>可以看做用户态下的线程，协程的切换逻辑由可以在用户态下实现，同时不需要进行上下文的切换，因而相对于线程速度快很多；之所以不需要切换上下文，是因为传统的线程生命周期是一种嵌套形式的，同时只有一个线程有效，且线程无效后切换需要进行上下文的切换，而协程切换后，会向相应东西存放在随时可用的活动栈中(在堆中分配内存)<br>每个协程都有自己私有栈,同时协程之间存在共享栈,由runnig-&gt;suspend设及私有栈恢复到共享栈,相反运行意味着保存到私有栈<br>携程的状态从ready 到 running 到 susbpend 到 running 到 dead<br>协程 VS 线程：不切换上下文;不涉及锁(自己实现协程间调度) 但linux并不支持携程 协程因为线程不会主动释放CPU时间,与机遇优先级抢占式的cpu调度不符</p></blockquote><blockquote><p><a href="https://zhuanlan.zhihu.com/p/94018082" target="_blank" rel="noopener">有栈协程实现原理</a> <a href="https://blog.csdn.net/liushengxi_root/article/details/85114692" target="_blank" rel="noopener">云风协程库保存和恢复协程运行栈原理讲解</a></p></blockquote><h2 id="作业调度算法">作业调度算法</h2><ul><li>FCFS：利于长进程，而不利于短进程</li><li>短作业优先：利于短进程，而不利于长进程</li><li>时间片轮转：时间片轮转调度算法</li><li>优先级调度算法</li><li>响应比高这优先：响应比= 等待时间+运行时间/运行时间 :既照顾了短进程，又考虑了进程到达的先后次序，也不会使长进程长期得不到服务，因此是一个比较全面考虑的算法，但每次进行调度时，都需要对各个进程计算响应比。所以系统开销很大，比较复杂</li><li>多级队列调度算法</li></ul><h2 id="存储器连续分配方式中分区分配算法">存储器连续分配方式中分区分配算法</h2><ul><li>首次适应分配算法:总是从第1条记录开始顺序查找空闲分区表，找到第一个能满足作业长度要求的空闲区，分割这个空闲区，一部分分配给作业，另一部分仍为空闲区</li><li>循环首次适应算法:每次分配均从上次分配的位置之后开始查</li><li>最佳适应分配算法(BF)：是按作业要求从所有的空闲分区中挑选一个能满足作业要求的最小空闲区，这样可保证不去分割一个更大的区域，使装入大作业时比较容易得到满足。为实现这种算法，把空闲区按长度递增次序登记在空闲区表中，分配时，顺序查找。</li><li>最坏适应算法(worst fit algorithm)：要求空闲区按其大小递减的顺序组成空闲区可用表或自由链。当用户作业或进程申请一个空闲区时，先检查空闲区可用表或自由链的第一个空闲可用区的大小是否大于或等于所要求的内存长度，若可用表或自由链的第一个项所示空闲区长度小于所要求的，则分配失败，否则从空闲区可用表或自由链中分配相应的存储空间给用户，然后修改和调整空闲区可用表或自由链。</li></ul><h2 id="页面置换算法">页面置换算法</h2><ul><li>最佳置换算法（OPT) ：选择以后永不使用或在最长时间内不再被访问的内存页面予以淘汰。</li><li>先进先出置换算法（FIFO）：选择最先进入内存的页面予以淘汰。</li><li>最近最久未使用算法（LRU）：选择在最近一段时间内最久没有使用过的页，把它淘汰。</li><li>最少使用算法（LFU）：选择到当前时间为止被访问次数最少的页转换。</li><li>时钟算法/最近未用算法：使用访问位和修改位标记页,优先替换未使用未修改的页,然后替换已修改的页。</li></ul><h2 id="页面分配策略">页面分配策略</h2><p>分页式的虚拟内存系统,对于每个进程如何分配主存空间</p><ul><li>固定分配局部置换：每个进程固定分配物理块,置换只发生在进程分配的空间</li><li>可变分配全局置换：每个进程分配少量物理块,同时维持全局空闲块,进程空间不足时从全局获取</li><li>可变分配局部置换：每个进程分配部分物理块,根据每个进程的缺页频率,动态增减进程的空间物理块数</li></ul><h2 id="磁盘调度">磁盘调度</h2><ul><li>先来先服务（FCFS）：是按请求访问者的先后次序启动磁盘驱动器，而不考虑它们要访问的物理位置</li><li>最短寻道时间优先（SSTF）：让离当前磁道最近的请求访问者启动磁盘驱动器，即是让查找时间最短的那个作业先执行，而不考虑请求访问者到来的先后次序，这样就克服了先来先服务调度算法中磁臂移动过大的问题</li><li>扫描算法（SCAN）或电梯调度算法：总是从磁臂当前位置开始，沿磁臂的移动方向去选择离当前磁臂最近的那个柱面的访问者。如果沿磁臂的方向无请求访问时，就改变磁臂的移动方向。在这种调度方法下磁臂的移动类似于电梯的调度，所以它也称为电梯调度算法。</li><li>循环扫描算法（CSCAN）：循环扫描调度算法是在扫描算法的基础上改进的。磁臂改为单项移动，由外向里。当前位置开始沿磁臂的移动方向去选择离当前磁臂最近的哪个柱面的访问者。如果沿磁臂的方向无请求访问时，再回到最外，访问柱面号最小的作业请求。</li></ul><h2 id="高速缓存与主存的三种映射方式">高速缓存与主存的三种映射方式</h2><ul><li>全相联映射：存中任意一个块都可以映射到cache中任意一个块的方式:利用率高但寻找困难</li><li>直接相联映射：内存块数%cache块数的值或者其低位地址决定其映射的cache行;寻找方便但是冲突率高</li><li>组相连映射:把cache分为x行一组,共y组,对于组实行直接相连映射,对于组内全相联映射</li></ul><p><a href="https://zhuanlan.zhihu.com/p/83597838" target="_blank" rel="noopener">参考0</a><br><a href="https://www.zhihu.com/question/19732473/answer/241673170" target="_blank" rel="noopener">参考1</a><br>BIO NIO AIO<br>同步 VS 异步</p><blockquote><p>是否需要自己主动去获取结果;<br>场景：发送完请求,可以不等待请求结果,发送下一个请求,提高效率,保证并发<br>是否存在异步阻塞IO?既然异步了,由OS负责准备数据到用户空间,由OS和线程/进程争抢总线,完成之后通知结果,进程本身可以轮询,仍然有自己控制,不算阻塞把</p></blockquote><p>阻塞 VS 非阻塞</p><blockquote><p>调用者是否被阻塞,或者说丧失自由/放弃CPU时间<br>传统的IO流都是阻塞式的</p><ul><li>本地IO:当一个线程调用read()或者write()方法时，该线程将被阻塞，直到有一些数据读读取或者被写入，在此期间，该线程不能执行其他任何任务</li><li>网络IO：在完成网络通信进行IO操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量的客户端时，性能急剧下降<br>非阻塞IO 不阻塞当前线程,可以做其他事情;由于大多时候,IO操作并不频繁,每个通道/外设 不是随时都有,所以可以有少数线程负责很多IO的输入输出的管理(减少上下文切换时间)</li></ul></blockquote><p>IO模型主要分类：</p><ul><li>同步IO 和 异步IO</li><li>阻塞IO 和 非阻塞IO</li><li>同步阻塞IO(synchronize block io): BIO</li><li>同步非阻塞IO(synchronize noblock io)</li><li>IO多路复用JAVA NIO</li><li>异步非阻塞IO(asychronous noblock io): AIO/IOCP</li></ul><p>用户程序进行IO的读写，基本上会用到系统调用read&amp;write，read把数据从内核缓冲区复制到进程缓冲区，write把数据从进程缓冲区复制到内核缓冲区，它们不等价于数据在内核缓冲区和磁盘之间的交换。<br>BIO</p><blockquote><p>创建连接的那个线程会阻塞自己到等待数据到达,由内核进程复制数据到用户空间,之后可以运行</p></blockquote><p>同步非阻塞</p><blockquote><p>创建连接的线程调用完之后可以得到是否调用成功的结果,然后可以轮询询问是否完成(也可以分批获取缓冲区的数据,不必要一次性获得)<br>适用于大量网络连接且IO不频繁的状态,避免大量创建线程同时可以从内核缓冲区读取不完整的数据(例如拆包粘包Netty)</p></blockquote><p>NIO</p><blockquote><p>创建连接的线程向selector注册一个channel,由其负责处理所有I操作,监控channel,并分发写进buffer,然后自己转做其他事情</p></blockquote><p>BIO VS NIO</p><blockquote><p>面向流 面向缓冲区<br>阻塞   非阻塞<br>无     selector</p></blockquote><p>BIO、NIO、AIO适用场景</p><blockquote><p>BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择。<br>NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂。<br>AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持</p></blockquote><p>selcet/poll/epoll 都属于 同步IO</p><p>Netty</p><h3 id="大端存储-小端存储">大端存储 小端存储</h3><blockquote><p>大端存储与小端存储模式主要指的是数据在计算机中存储的两种字节优先顺序。<br>小端存储指从内存的低地址开始,先存储数据的低序字节再存高序字节;相反,大端存储指从内存的低地址开始,先存储数据的高序字节再存储数据的低序字节</p></blockquote><p>用途：</p><blockquote><p>小端存储:常见于本地主机上(也有部分类型主机为大端存储)<br>大端存储:常见于网络通信上，网际协议TCP/IP在传输整型数据时一般使用大端存储模式表示,例如TCP/IP中表示端口和IP时，均采用的是大端存储</p></blockquote><p>如何避免死锁：</p><ul><li>银行家算法：分配资源前先评估风险，会不会在分配后导致死锁。</li><li>顺序加锁，这样能防止死锁现象</li></ul><p>多线程 VS 多进程</p><ul><li>线程只是进程的一个执行路径</li></ul><h3 id="文件描述符">文件描述符</h3><p><a href="https://segmentfault.com/a/1190000009724931" target="_blank" rel="noopener">文件描述符（File Descriptor）简介</a><br>系统为了维护文件描述符,维持了3个层次的表</p><ul><li>进程层次的文件描述符表<ul><li>文件描述符flag</li><li>指向系统级表的指针</li></ul></li><li>系统级的文件描述符表<ul><li>当前文件的偏移</li><li>状态标识</li><li>文件访问模式:读 写 读写</li><li>inode引用</li><li>其他:访问权限,文件其他属性等</li></ul></li><li>文件系统的inode表<ul><li>文件类型</li><li>文件锁</li></ul></li></ul><p>当我们打开一个文件或者建立socket时,会返回一个文件描述符,就是一个数字(0 1 2 分别默认标准输入/输出/错误输出),标识在进程空间内文件描述符表的索引(进程描述符表的长度默认为1024)</p><p>socket 连接使用过程</p><ul><li>create socket :寻找inode文件,创建相关数据结构,并返回文件描述符</li><li>bind：把socket与ip port 绑定(客户端无需调用,在connect时会自动分配一个port)</li><li>listen：将连接socket转化为监听套接字(更改socket状态为LISTEN)由tcp/ip协议簇完成监听</li><li>accept:<ul><li>客户端会通过connect连接服务端,服务端会维持两个连接队列,未完成3次握手的和已完成3次握手的</li><li>accept函数默认为阻塞函数,当已完成握手连接队列非空时,会返回队列首的连接文件描述符(一个完整的连接套接字,包含源目的端口ip,这样可以实现socket复用)</li></ul></li><li>send/recv：</li><li>select/poll/epoll<ul><li>select 成功返回就绪的文件描述符数量,如果&gt;0,则循环遍历事件,然后确定是哪个并处理</li></ul></li></ul><p>socket描述</p><blockquote><p>accept建立连接之后,返回一个文件描述符,指向socket套接字,包含源ip/端口 目的ip/端口 也就是父进程与fork出的子进程共同监听一个端口,但是由于请求类型不同(建立连接由主进程负责,而已建立的连接由多个子进程竞争锁获得负责) 可以区分<br><a href="http://blog.chinaunix.net/uid-23629988-id-285722.html" target="_blank" rel="noopener">kernel如何选择socket接收数据</a> 根据协议选择不同链表,然后遍历选择(源ip端口等信息)最符合的socket</p></blockquote><p>select</p><blockquote><p>在内核处理时需要两次循环遍历发现就绪,在外也需要循环遍历发现就绪事件,耗时,且传进去的fd_set位图表示监视的文件描述符,默认限制1024长度<br>select在调用时使用不同set表示监听不同的事件类型(读写异常);do-select 中会对调用返回对应文件的poll函数,检测是否有时间发生,如果发生返回类型mask,并判断是否是读/写/异常,然后添加进不同的返回列表中;</p></blockquote><p>poll<br><a href="https://blog.51cto.com/10706198/1783610" target="_blank" rel="noopener">使用示例</a></p><h4 id="select-解析">select 解析</h4><p><a href="http://lxr.linux.no/linux+v3.9/fs/select.c" target="_blank" rel="noopener">select 内核源码</a><br><a href="https://blog.csdn.net/weixin_42462202/article/details/95315926" target="_blank" rel="noopener">Linux select内核源码剖析</a><br><a href="https://blog.csdn.net/caogenwangbaoqiang/article/details/80949643" target="_blank" rel="noopener">select模型linux内核源码注释总结</a></p><p>select函数的参数</p><ul><li>最大文件描述符+1</li><li>读事件监听set</li><li>写事件监听set</li><li>异常事件监听set</li><li>默认等待时间(null:阻塞;0:立刻返回;其他)</li></ul><p>select -&gt; do_select<br>在死循环中,</p><ul><li>遍历文件描述符,并调用其poll函数,将该进程添加进其等待队列 然后陷入睡眠</li><li>如果时间到达或者被中断唤醒,会继续循环遍历文件描述符,如果调用poll函数后发现有时间发生,就绪事件记录+1,遍历完成后,如果就绪事件&gt;0或者等待超时,就跳出死循环,否则继续休眠</li></ul><p>缺点：</p><ul><li>fd set长度有限制</li><li>需要在用户空间和内核空间之间拷贝fdset数据</li><li>检查是否发生事件时,是轮询遍历,而且范围内包含不关注的文件描述符;返回结果也需要轮询</li></ul><h3 id="poll-解析">poll 解析</h3><p><a href="https://blog.51cto.com/10706198/1783610" target="_blank" rel="noopener">使用示例</a><br><a href="http://gityuan.com/2019/01/05/linux-poll-select/" target="_blank" rel="noopener">源码解析</a><br><a href="https://www.cnblogs.com/shuqin/p/11662645.html" target="_blank" rel="noopener">poll(2) 源码分析</a><br>poll 函数的参数</p><ul><li>pollfd数组</li><li>最大文件描述符</li><li>时间</li></ul><p>poll利用 pollfd 结构体记录 file-description 和 event(POLLINT/POLLOUT/异常) 以及 revents(系统触发的事件)<br>过程</p><ul><li>利用 pollfd 数组记录监听的文件描述符对应的连接以及类型;</li><li>之后调用poll函数,其内会将数组转化为链表(按页分配内存申请内存,每页存储一个pollfd数组,利用<a href="https://lenzhao.com/topic/5a28f4b52e95f0fd0a9818a8" target="_blank" rel="noopener">copy_from_user</a>把用户空间的pollfd拷贝到核心空间,然后next页,如果分配失败就会free所有节点,然后返回内存错误);</li><li>之后根据链表来遍历;大致过程与select类似,但是会将触发的事件类型记录在revents中(首先会过滤掉不感兴趣的事件);并通过copy_to_user 拷贝回用户空间</li><li>在poll返回的结果&gt;0则会轮询查询event与revents是否一致</li></ul><p>相对于select 突破了1024的默认长度限制,只要满足长度小于RLIMIT_NOFILE(进程最大打开文件描述符限制即可;可以设置65535)</p><p>缺点：</p><ul><li>仍需在用户和内核空间拷贝数据,量变得更大</li><li>相对于select更精确,但检查事件以及返回时然后需要遍历确认</li></ul><h3 id="epoll-解析">epoll 解析</h3><p><a href="http://lxr.linux.no/linux+v3.9/fs/eventpoll.c" target="_blank" rel="noopener">eventspoll源码</a><br><a href="http://lxr.linux.no/linux+v3.9/include/linux/fs.h" target="_blank" rel="noopener">struct file</a><br><a href="http://wxgg.cc/blogs/2018/12/libevent-cpp-5-%E5%B0%81%E8%A3%85epoll%E5%8F%8Aepoll%E5%86%85%E6%A0%B8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.html" target="_blank" rel="noopener">封装epoll及epoll内核实现原理</a><br><a href="https://www.iminho.me/wiki/blog-23.html" target="_blank" rel="noopener">IO多路复用原理剖析</a><br><a href="http://gityuan.com/2019/01/06/linux-epoll/" target="_blank" rel="noopener">源码解读epoll内核机制</a><br><a href="https://www.cnblogs.com/apprentice89/p/3234677.html" target="_blank" rel="noopener">epoll用法回顾</a><br><a href="https://icoty.github.io/2019/06/03/epoll-source/" target="_blank" rel="noopener">epoll源码分析(基于linux-5.1.4)</a><br><a href="https://zhuanlan.zhihu.com/p/64746509" target="_blank" rel="noopener">如果这篇文章说不清epoll的本质，那就过来掐死我吧</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">struct eventpoll &#123;</span><br><span class="line">    spinlock_t lock;</span><br><span class="line">    struct mutex mtx;</span><br><span class="line">    //调用epoll_wait过程中陷入阻塞的进程队列</span><br><span class="line">    wait_queue_head_t wq;</span><br><span class="line">    //与文件相关的等待队列,保存了所有等待该文件相关事件的进程(file-&gt;poll()),对于该文件的读写操作会唤醒该队列</span><br><span class="line">    wait_queue_head_t poll_wait;</span><br><span class="line">    //就绪状态的文件描述符的列表</span><br><span class="line">    struct list_head rdllist;</span><br><span class="line">    //存储监控的红黑树</span><br><span class="line">    struct rb_root rbr;</span><br><span class="line">    struct file *file;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>过程：</p><ul><li>epoll_create:创建file实例,创建eventpoll,赋值给file-&gt;private_date,获得未使用fd与改file绑定,然后返回fd</li><li>epoll_ctl:控制监听的事件,增加/删除/修改,实质是通过对之前创建的eventpoll中的红黑树进行操作以insert为例<ul><li>初始化epollitem(fd file)</li><li>初始化ep_pqueue,添加到socket文件的等待队列并注册回调函数ep_ptable_queue_proc-&gt;ep_poll_callback(判断是否是感兴趣的事件,添加进epoll的就绪队列,并唤醒epoll在wait阶段的阻塞进程)</li><li>在红黑树中插入节点</li></ul></li><li>epoll_wait: 调用 ep_poll ,在死循环中判断:如果就绪队列为空,那么休眠,将自己阻塞在eventpoll的等待队列,等待ep_poll_callback 唤醒 否则跳出循环,拷贝就绪队列的events事件到用户空间</li></ul><p>其他</p><ol><li>红黑树中存储需要监听的事件,节点类型是epollitem,比较的方法是首先比较socket对应的file指针地址(没看到重写比较符) 然后比较fd值</li><li>ep_poll_callback 函数 会首先将当前触发的操作的添加到eventpoll的就绪队列,然后唤醒该eventpoll的等待队列</li></ol><p>优点:相对于select/poll 的轮询和数据拷贝操作</p><ul><li>利用回调函数,在唤醒时将就绪的文件添加到就绪队列,拷贝回用户空间,无需轮询(将之前的wait操作拆分为ctl和wait操作)</li><li>利用eventpoll中的红黑树存储关注的文件描述符和事件,无需频繁的拷贝所有数据</li></ul><p>缺点：</p><ul><li>对于大量的频发事件,会频繁调用回调函数,效率不高,适合大量低速的连接</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">struct epitem &#123;</span><br><span class="line">    union &#123;</span><br><span class="line">        struct rb_node rbn; //RB树节点将此结构链接到eventpoll RB树</span><br><span class="line">        struct rcu_head rcu; //用于释放结构体epitem</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    struct list_head rdllink; //用于将此结构链接到eventpoll就绪列表的列表标头</span><br><span class="line">    struct epitem *next; //配合ovflist一起使用来保持单向链的条目</span><br><span class="line">    struct epoll_filefd ffd; //此条目引用的文件描述符信息</span><br><span class="line">    int nwait; //附加到poll轮询中的活跃等待队列数</span><br><span class="line"></span><br><span class="line">    struct list_head pwqlist;</span><br><span class="line">    struct eventpoll *ep;  //epi所属的ep</span><br><span class="line">    struct list_head fllink; //链接到file条目列表的列表头</span><br><span class="line">    struct wakeup_source __rcu *ws; //设置EPOLLWAKEUP时使用的wakeup_source</span><br><span class="line">    struct epoll_event event; //监控的事件和文件描述符</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="et-lt">ET LT</h3>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人网站搭建</title>
      <link href="/2020/07/05/Blog/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/"/>
      <url>/2020/07/05/Blog/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<h1 id="域名">域名</h1><h2 id="域名购买">域名购买</h2><p>国内域名</p><h2 id="域名解析">域名解析</h2><p>godaddy<br>国内解析<br>cloudflare</p><h1 id="审核">审核</h1><h2 id="阿里云-初审">阿里云 初审</h2><p>主要是网站名称的问题，发现不能使用成语。</p><h2 id="管局审核">管局审核</h2><p>在hexo相应处增加该信息</p><h2 id="公安局审核">公安局审核</h2><p>公安联网备案申请,并在hexo相应处增加该信息</p><h1 id="部署">部署</h1><h2 id="服务器部署hexo">服务器部署hexo</h2><h3 id="安装必要软件">安装必要软件</h3><p>git nginx</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get-install nodejs npm</span><br><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><h3 id="配置服务器文件夹接受本地hexo传输文件">配置服务器文件夹接受本地hexo传输文件</h3><p>参考<a href="https://www.cnblogs.com/luoshuitianyi/p/10333928.html" target="_blank" rel="noopener">Hexo搭建(VPS)</a></p><ol><li>创建裸仓库，用于接受文件</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir hexo.git</span><br><span class="line">cd hexo.git</span><br><span class="line">git init --bare # 裸仓库只存储历史和元数据信息，不维护工作目录</span><br></pre></td></tr></table></figure><ol start="2"><li>创建文件夹(中转目录和nginx根目录)以及git hook</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /tmp/hexo  #中转目录</span><br><span class="line">mkdir /var/www/hexo #nginx 根目录</span><br></pre></td></tr></table></figure><p>编辑 hooks/post-receive 文件,指定 ~/hexo.git/目录下的仓库更新后的操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">GIT_REPO=~/hexo.git                      # 触发 hook</span><br><span class="line">TMP_GIT_CLONE=/tmp/hexo                  # 存在 /tmp 下</span><br><span class="line">PUBLIC_WWW=/var/www/hexo                 # 展示网站的目录</span><br><span class="line">rm -rf $&#123;TMP_GIT_CLONE&#125;                  # 删除之前内容</span><br><span class="line">git clone $GIT_REPO $TMP_GIT_CLONE       # 将 Git 仓库上传的内容复制到/tmp</span><br><span class="line">rm -rf $&#123;PUBLIC_WWW&#125;/*                   # 删除展示网站的目录的全部内容</span><br><span class="line">cp -rf $&#123;TMP_GIT_CLONE&#125;/* $&#123;PUBLIC_WWW&#125;  # 将/tmp所有内容复制到网站目录</span><br></pre></td></tr></table></figure><p>使得post-receive 可执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x hexo/hexo.git/hooks/post-receiv</span><br></pre></td></tr></table></figure><ol start="4"><li>配置https<br>从阿里云申请免费证书，下载证书，放置在相关位置，并修改nginx配置文件</li></ol><figure class="highlight plain"><figcaption><span>of Hexo</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        listen [::]:80;</span><br><span class="line">        server_name _;</span><br><span class="line">        rewrite ^/(.*)$ https://www.whetstone.life:443/$1 permanent;</span><br><span class="line">&#125;</span><br><span class="line">#Config of https</span><br><span class="line">server &#123;</span><br><span class="line">        listen 443;</span><br><span class="line">        listen [::]:443;</span><br><span class="line">        server_name _;</span><br><span class="line">        ssl on;</span><br><span class="line">        ssl_certificate /etc/nginx/ssl/www.whetstone.life.pem;</span><br><span class="line">        ssl_certificate_key /etc/nginx/ssl/www.whetstone.life.key;</span><br><span class="line">        ssl_session_timeout 5m;</span><br><span class="line">        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;</span><br><span class="line">        ssl_prefer_server_ciphers on;</span><br><span class="line">        server_name _;</span><br><span class="line">        location / &#123;</span><br><span class="line">                root /var/www/hexo;</span><br><span class="line">                index index.html;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改防火墙,在阿里云ECS实例中修改安全组规则</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -A INPUT -p tcp --dport 443 -j ACCEPT</span><br></pre></td></tr></table></figure><h2 id="配置-ssh-互信">配置 ssh 互信</h2><p>只需要服务器信任本地host即可,方便从本地传输文件到服务器无需输入密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp ./.ssh/id_rsa.pub root@ip:/root</span><br><span class="line">cat id_rsa.pub &gt; .ssh/authorized_keys</span><br></pre></td></tr></table></figure><h2 id="本地hexo配置deploy">本地hexo配置deploy</h2><p>配置多个deploy对象，参考 <a href="https://hexo.io/zh-cn/docs/one-command-deployment" target="_blank" rel="noopener">hexo deploy配置</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">- type: git</span><br><span class="line">  repository: git@github.com: ***/***.github.io.git </span><br><span class="line">  branch: master </span><br><span class="line">- type: git</span><br><span class="line">  repository: root@ip:/path/to/push</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> VPS hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>blog 产生记</title>
      <link href="/2020/07/05/Blog/blog/"/>
      <url>/2020/07/05/Blog/blog/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> hexo next </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/07/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Clousim/"/>
      <url>/2020/07/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Clousim/</url>
      
        <content type="html"><![CDATA[<p><a href="http://www.trojx.me/2019/12/30/cloudsim-plus-faq/" target="_blank" rel="noopener">云计算仿真工具CloudSim Plus常见问题总结</a><br><a href="https://veviz.github.io/2016/05/17/CloudSim/" target="_blank" rel="noopener">CloudSim Introduction</a><br><a href="https://blog.csdn.net/wjh1313677/article/details/45625999" target="_blank" rel="noopener">CloudSim源码分析-DatacenterBroker创建</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>java 语言学习</title>
      <link href="/2020/06/30/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/Java/"/>
      <url>/2020/06/30/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/Java/</url>
      
        <content type="html"><![CDATA[<h1 id="多线程">多线程</h1><h2 id="线程创建方法">线程创建方法</h2><blockquote><p>1.继承Thread类，重写run()线程执行程序，创建线程<br>2.实现Runnable接口，重写run()方法，作为参数构造thread，创建线程<br>3.使用Callable和Future创建线程<br>4.使用线程池例如用Executor框架</p></blockquote><ul><li>Executor 的参数</li></ul><blockquote><p>实现Runnable接口比继承Thread类所具有的优势：<br>1)可以避免java中的单继承的限制；可以继承多个接口<br>2)Thread 实现了Runnable 接口, 提供了更多的可用方法和成员而已</p></blockquote><h2 id="多线程">多线程</h2><p>synchronize作为多线程关键字，是一种同步锁，它可以修饰以下几种对象：</p><ul><li>代码块：被修饰的代码块称为同步语句块，其作用的范围是大括号{ }里的代码，作用的对象是调用这个代码块的对象；</li><li>方法：被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象</li><li>静态方法：作用的范围是整个静态方法，作用的对象是这个类的所有对象</li><li>类：作用的范围是synchronize后面括号里的部分，作用的对象是这个类的所有对象</li></ul><p>锁：线程争夺对于锁，获取锁，然后运行代码</p><ul><li>对象锁 this 对象,其他对象</li><li>类锁</li></ul><blockquote><p>线程开始<br>线程停止：正常执行完run；interrupt使得线程异常，执行完run<br>其他：</p><blockquote><p>设置线程优先级(特性：继承性(线程A启动线程B，B继承A的优先级) ; 随机性(线程的调度顺序不一定根据优先级,具有随机性))<br>yield方法，释放CPU资源，通常它会让当前运行线程回到可运行性状态，使得有相同优先级的线程有机会执行。<br>sleep方法，使当前线程睡眠至少时间<br>join()方法：保证当前线程停止执行，直到该线程所加入的线程完成为止。然而，如果它加入的线程没有存活，则当前线程不需要停止（基于wait方法和notify方法）</p></blockquote></blockquote><h1 id="gc">GC</h1><h2 id="背景">背景</h2><blockquote><p>内存空间是有限的，如果高效利用有限的空间，可以通过释放不适用的对象所占用的内存(Java虚拟机所管理的内存区域分为如下部分：方法区、堆内存、虚拟机栈、本地方法栈、PC寄存器)</p></blockquote><h2 id="gc对象">GC对象</h2><blockquote><p>程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈帧随着方法的进入和退出做入栈和出栈操作，实现了自动的内存清理；内存垃圾回收主要集中于 java 堆和方法区中，在程序运行期间，这部分内存的分配和使用都是动态的</p></blockquote><h3 id="判定方法">判定方法</h3><blockquote><p>如何判断对象不再存活：引用计数（每个对象有一个引用计数属性，计数为0时可以回收，但无法解决对象相互循环引用的问题）和可达分析（通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连，则证明此对象是不可用的）</p></blockquote><h3 id="触发gc的条件">触发GC的条件</h3><blockquote><p>1.程序主动调用System.gc<br>2.内存不足被动触发(年轻代升级空间不够,或者永久代空间不足)</p></blockquote><h2 id="gc-roots">GC ROOTS</h2><blockquote><p>虚拟机栈、方法区和本地方法栈；方法区中类静态属性引用的对象；常量<br>1.系统类加载器锁加载的类<br>2.阻塞线程以及运行线程涉及的对象；本地方法栈涉及的对象<br>3.全局对象，上锁对象<br>4.针对younggc来说，gcroot的对象包括所有年老带对象</p></blockquote><h2 id="为对象分配内存的方法">为对象分配内存的方法</h2><ul><li>规整内存/指针碰撞:将内存分为已使用和未使用的两部分,使用指针将两者隔开,然后指针右移需要的空间即可(建立在压缩空闲空间的基础上,耗时)</li><li>空闲列表法:把空间的空间的大小范围列表排序,然后选择(有首次适应,循环适应,最有适应,最坏适应)</li></ul><p>卡表(cardTable)</p><blockquote><p>JVM 把每512字节表示为一个卡页,<br>为了提高重新标记的效率，并发标记阶段会把这些发生变化的对象所在的Card标识为Dirty，这样后续阶段就只需要扫描这些Dirty Card的对象，从而避免扫描整个老年代</p></blockquote><h2 id="gc常用算法">GC常用算法</h2><blockquote><p>1.标记-清除算法：标记对象的存活或者死亡;清除对象会导致大量碎片<br>2.复制算法：内存分为两部分，只使用其中一部分，这部分内存用完后，将其中存活的对象移动至另一部分，其他删除；没有碎片，但内存利用率低<br>3.标记-压缩算法：在上种算法的基础上，将存活的对象整理到一起；如果存活对象过多会导致，复制次数过多，效率下降<br>4.分代收集算法（JVM Hotspot在使用）：根据对象的生存周期，将堆分为新生代(Young)和老年代(Tenure)。在新生代中，由于对象生存期短，每次回收都会有大量对象死去，那么这时就采用复制算法。老年代里的对象存活率较高，没有额外的空间进行分配担保，所以可以使用标记-整理 或者 标记-清除。</p></blockquote><h3 id="cms">CMS</h3><blockquote><p>基于标记-清除算法<br>堆被划分为新生代和老年代，新生代又被进一步划分为Eden和Survivor区，而Survivor由FromSpace和ToSpace组成。<br><br>新生代：新创建的对象都是用新生代分配内存，Eden空间不足时，触发Minor GC，这时会把存活的对象转移进Survivor区。<br><br>老年代：老年代用于存放经过多次Minor GC之后依然存活的对象，老年代内存不足时触发，Major GC</p></blockquote><h3 id="zgc">ZGC</h3><blockquote><p>todo</p></blockquote><h3 id="cms-vs-g1"><a href="https://www.cnblogs.com/heyonggang/p/11718170.html" target="_blank" rel="noopener">CMS VS G1</a></h3><blockquote><p>CMS：Concurrent Mark Sweep，基于标记-清楚算法，作用于老年代，以并发获取最短回收停顿时间为目标的</p><blockquote><p>初始标记（标记root直接关联的对象）、并发标记（root  trace）、重新标记（并发标记中涉及的对象）、并发清除（CMS concurrent sweep）<br>优点：并发收集、低停顿<br>缺点：</p><blockquote><p>CMS收集器对CPU资源非常敏感，频繁GC，CPU资源不足。<br>CMS收集器无法处理浮动垃圾（Floating Garbage），并发清除阶段，运行产生的垃圾无法在本次回收。<br>CMS收集器是基于标记-清除算法，导致碎片。<br>安全点：程序执行时并非在所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停，安全点的初始目的是找到一个稳定的执行状态。在这个执行状态下，Java虚拟机的堆栈不会发生变化；长时间执行”的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等<br></p></blockquote></blockquote></blockquote><blockquote><p>G1：Garbadge First Collector；基于标记-整理算法；G1重新定义了堆空间，将堆划分为一个个区域；来进行垃圾回收，不必在全堆范围内收集，可以预测停顿时间</p><blockquote><p>与CMS的步骤类似，只是第4步时，他根据region排序价值和预测时间去清除，最后然后拷贝存活对象至新的region<br>卡表：？？？与老年代引用年轻代<br>相对于CMS优势：可预测的停顿模型；避免了CMS的垃圾碎片；超大堆的表现更出色</p></blockquote></blockquote><h1 id="设计模式">设计模式</h1><h2 id="单例模式">单例模式</h2><blockquote><p>单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象</p></blockquote><blockquote><blockquote><ol><li>懒汉模式：实例在使用到的时候才创建,当多线程并发调用 getInstance(),如果方法不加synchronize 关键字修饰,会导致线程不安全</li></ol></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class LHan &#123;</span><br><span class="line">    private static LHan instance;</span><br><span class="line">    private LHan()&#123;&#125;</span><br><span class="line">    public static LHan getInstance()&#123;</span><br><span class="line">        if(instance == null)&#123;</span><br><span class="line">            instance = new LHan();</span><br><span class="line">        &#125;</span><br><span class="line">        return instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><blockquote><ol start="2"><li>饿汉模式,实例在最初已经初始化,getInstance()方法线程安全，但浪费内存空间</li></ol></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class EHan &#123;</span><br><span class="line">    private static EHan instance = new EHan();</span><br><span class="line">    private EHan()&#123;&#125;</span><br><span class="line">    public static EHan getInstance()&#123;</span><br><span class="line">        return instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><blockquote><ol start="3"><li>双检锁,双重校验锁,在synchronize 关键字内外都加上一层if判断,即避免内存浪费,又保证了线程安全,同时 比直接上锁提高了执行效率</li></ol></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class DoubleCheck &#123;</span><br><span class="line">    private static DoubleCheck instance;</span><br><span class="line">    private DoubleCheck()&#123;&#125;</span><br><span class="line">    public static DoubleCheck getInstance()&#123;</span><br><span class="line">        if(instance == null)&#123;</span><br><span class="line">            synchronize(DoubleCheck.class)&#123;</span><br><span class="line">                if(instance == null)&#123;</span><br><span class="line">                    instance = new DoubleCheck();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><blockquote><ol start="4"><li>静态内部类(内部类是外部类的一个成员,分为静态内部类和非静态内部类：静态内部类可以直接调用外部类的静态成员(静态成员变量和静态方法)，但是不能直接调用外部类的非静态成员；而非静态内部类可以直接调用外部类的其他成员)</li></ol></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class SingleTon &#123;</span><br><span class="line">    private static class SingletonHolder &#123;</span><br><span class="line">        private static final SingleTon INSTANCE = new SingleTon();</span><br><span class="line">    &#125;</span><br><span class="line">    private SingleTon()&#123;&#125;</span><br><span class="line">    public static final SingleTon getInstance()&#123;</span><br><span class="line">        return SingletonHolder.INSTANCE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><blockquote><ol start="5"><li>枚举</li></ol></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public enum SingleTonn &#123;</span><br><span class="line">    INSTANCE;</span><br><span class="line">    public void AnyMethod()&#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id></h1><h1 id="其他常见问题">其他常见问题</h1><h2 id="hashmap-hashtable-concurrenthashmap">HashMap HashTable ConcurrentHashMap</h2><blockquote><p>都是 数组+单链表 实现<br><a href="https://blog.csdn.net/mbshqqb/article/details/79799009" target="_blank" rel="noopener">参考1</a><br>HashMap基于hashing原理，我们通过put()和get()法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用LinkedList来解决碰撞问题，当发生碰撞了，对象将会储存在LinkedList的下一个节点中。 HashMap在每个LinkedList节点中储存键值对对象。<br>　　当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的LinkedList（链表只让挂7个元素，超过七个就会转成一个红黑树进行处理，当红黑树下挂的节点小于等于6的时候，系统会把红黑树转成链表）中。键对象的equals()方法用来找到键值对<br>String, Interger这样的类，作为HashMap的键是再适合不过了，因为String对象是不可变的，计算hashCode()，就要防止键值改变</p></blockquote><blockquote><p>HashTable：无论key还是value都不能为null，线程安全，实现线程安全的方式是在修改数据时锁住整个HashTable；<br>HashMap：无论key还是value都能为null，线程不安全（在多个线程并发扩容时，会在执行transfer()方法转移键值对时，造成链表成环，导致程序在执行get操作时形成死循环 <a href="https://www.cnblogs.com/lonelyJay/p/9726187.html" target="_blank" rel="noopener">参考1</a> <a href="https://www.sohu.com/a/341902281_100123073" target="_blank" rel="noopener">参考2</a> ;单链表复制是是插入排序，因为时刻知道链表头在哪）</p></blockquote><blockquote><p>但是 HashMap线程不安全，而HashTable安全但是效率低，出现了ConcurrentHashMap使用分段锁<br>cocurrent 将hashmap的数据分为若干个子数组,每个子数组包装为segment对其加锁;<br>抛开 HashMap，hash 冲突有那些解决办法？开放定址法、链地址法、再哈希法<br><a href="https://www.cnblogs.com/cosmos-wong/p/11845934.html" target="_blank" rel="noopener">java stack不推荐使用</a>,建议使用dequeue代替</p></blockquote><p>HashMap 扩容时机</p><ul><li>hashmap首次插入元素时会resize初始化table</li><li>hashmap中元素总数量达到阈值threshold(阈值初始化时等于)</li><li>如果某个链表的长度&gt;=8-1,则转化为红黑树(小于等于6时转换回来);在转化时,首先判断数组长度是否小于64那么就扩容,否则才转化</li></ul><h2 id="linkedhashmap-treemap">LinkedHashMap TreeMap</h2><blockquote><p>LinkedHashMap保存了记录的插入顺序,在用Iterator遍历LinkedHashMap时,先得到的记录肯定是先插入的,也可以在构造时用带参数,按照应用次数排序.<br>在遍历的时候会比HashMap慢,不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关<br>TreeMap实现SortMap接口,能够把它保存的记录根据键排序,默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。插入查询的效率都是O(logN)</p></blockquote><h2 id="arraylist-vs-linkedlist">Arraylist VS LinkedList</h2><blockquote><p>LinkedList与ArrayList一样实现List接口，只是ArrayList是List接口的大小可变数组的实现，LinkedList是List接口链表的实现。基于链表实现的方式使得LinkedList在插入和删除时更优于ArrayList，而随机访问则比ArrayList逊色些。<br>LinkedList实现所有可选的列表操作，并允许所有的元素包括null。<br>除了实现 List 接口外，LinkedList 类还为在列表的开头及结尾 get、remove 和 insert 元素提供了统一的命名方法。这些操作允许将链接列表用作堆栈、队列或双端队列。<br>此类实现 Deque 接口，为 add、poll 提供先进先出队列操作，以及其他堆栈和双端队列操作</p></blockquote><h2 id="volatile和synchronized特点">volatile和synchronized特点：</h2><blockquote><p>执行控制（执行顺序，并发）和内存可见（读写经过内存）<br>volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别(class对象的锁)的<br>volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞<br>volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化</p></blockquote><h2 id="java两种数据类型">Java两种数据类型</h2><blockquote><p>分为基本数据类型（boolean、byte、int、char、long、short、double、float）和引用数据类型（数组、类、接口）<br>Java为每 一个基本数据类型都引入了对应的包装类型（Boolean，Character，Byte，Short，Integer，Long，Float，Double），可以使用自动装箱/拆箱进行替换（装箱就是自动将基本数据类型转换为包装器类型；拆箱就是自动将包装器类型转换为基本数据类型）<br>例如：int与Integer的基本使用对比</p><ul><li>Integer是int的包装类，Integer变量必须实例化后才能使用；Integer的默认值是null;int是基本数据类型，int变量不需要初始化，int的默认值是0。</li><li>在使用时，Integer实际是对象的引用，指向此new的Integer对象；int是直接存储数据值 ；</li></ul></blockquote><h2 id="设计模式">设计模式</h2><blockquote><p><a href="https://www.runoob.com/design-pattern/design-pattern-tutorial.html" target="_blank" rel="noopener">https://www.runoob.com/design-pattern/design-pattern-tutorial.html</a><br>工厂模式:定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行<br>优点： 1、一个调用者想创建一个对象，只要知道其名称就可以了。 2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。</p><p>控制反转（Inversion of Control，缩写为IoC）；依赖注入<br>缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事<br>使用场景： 1、日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。2、设计一个连接服务器的框架，需要三个协议，“POP3”、“IMAP”、“HTTP”。</p><p>单例模式：保证一个类仅有一个实例，并提供一个访问它的全局访问点。<br>主要解决：一个全局使用的类频繁地使用，实现共享，锁,static<br>优点：1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。2、避免对资源的多重占用（比如写文件操作）。<br>缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。</p><p>装饰器模式:动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活<br>主要解决：一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。<br>优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能.<br>缺点：多层装饰比较复杂。</p><p>组合模式：是用于把一组相似的对象当作一个单一的对象</p><p>外观模式：隐藏系统的复杂性，客户端请求的简化方法和对现有系统类方法的委托调用（列类似于自动化脚本的概念）。<br>优点： 1、减少系统相互依赖。 2、提高灵活性。 3、提高了安全性。<br>缺点：不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。</p><p>代理模式：其他对象提供一种代理以控制对这个对象的访问<br>主要解决：远程调用，RPC；直接调用带来的危险，添加控制，火车站<br>静态代理：添加日志</p></blockquote><h2 id="堆栈">堆栈</h2><blockquote><p>都是一种数据项按序排列的数据结构，只能在一端(称为栈顶(top))对数据项进行插入和删除。<br>堆：一棵树的数组对象（大顶堆，小顶堆），一般程序员申请    ；栈：先入后出，有一半程序员申请 队列：先入先出</p></blockquote><h2 id="bean">bean</h2><blockquote><p><a href="https://www.awaimai.com/2596.html" target="_blank" rel="noopener">https://www.awaimai.com/2596.html</a><br>bean是一个由Spring IoC容器实例化、组装和管理的对象。<br>类的实例化、依赖的实例化、依赖的传入都交由 Spring Bean 容器控制而不是new</p></blockquote><h2 id="malloc-vs-new">malloc VS new</h2><h2 id="4种io模式">4种IO模式</h2><blockquote><ul><li>同步阻塞IO（Blocking IO）</li><li>同步非阻塞IO（Non-blocking IO）</li><li>IO多路复用（IO Multiplexing）</li><li>异步IO（Asynchronous IO）<br><a href="https://blog.csdn.net/qq_34802511/article/details/81543817" target="_blank" rel="noopener">https://blog.csdn.net/qq_34802511/article/details/81543817</a><br>同步io操作导致请求进程阻塞，直到i/o操作完成；异步io操作不导致请求进程阻塞<br>以read IO为例子，大致分为2步 1）等待数据准备(数据从磁盘拷贝到内核内存) 2）将数据从内核拷贝到进程中<br>同步阻塞在两个阶段都会阻塞；而同步非阻塞IO只会在第二个阶段阻塞，进程在第一步受阻后，会返回，然后反复询问是否内核准备好数据；<br>IO多路复用：在同步非阻塞的基础上，可以使用一个进程监视多个输入（select，poll，epoll）<br>而异步IO中，两步都不会造成阻塞，知道数据已经复制到进程内存区，会通知进程</li></ul></blockquote><h2 id="nio">NIO</h2><blockquote></blockquote><p><a href="https://juejin.im/post/6844903729435508750" target="_blank" rel="noopener">Java ClassLoader 再不理解就老了</a></p><h2 id="类的加载">类的加载</h2><p>在类的加载之前需要首先基于javac命令将java源文件编译成class文件,然后在运行中加载.<br>我们借助类加载器完成类的加载,类的加载共分为三个阶段:加载 链接(验证 准备 解析)  初始化</p><ul><li>加载：根据类的全限定名来找到相应的class文件,并加载到内存</li><li>链接<ul><li>验证：验证class字节流文件中的信息符合虚拟机的要求,不会危害自身安全</li><li>准备：给类变量分配内存并初始化为默认值,初始化常量(final)</li><li>解析：将常量池(在编译期即被确定的一些常量)中符号引用转化为直接引用<ul><li>举例：对于类而言就是将全限定名转化为该类在内存中的地址</li><li>对于类引用的解析,是在初始化之前加载还是在初始化之后使用前加载,可以由加载器自己决定实现</li></ul></li></ul></li><li>初始化：给类的静态变量赋给定的初始值,这些操作和静态代码块会统一放置在类构造器<clinit>方法中,该方法只会执行一次.</clinit></li><li>使用：在实例构造器<init>方法中包含了代码分别为 父类的初始化方法-普通常量的初始化赋值-普通代码块-构造函数<ul><li>主动使用-触发初始化:new 创建类的实例;访问类的静态变量或类方法;反射;初始化子类导致初始化父类</li><li>被动使用- 不会触发初始化:主动使用的一些例外<ul><li>子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化</li><li>通过数组定义来引用类，不会触发此类的初始化,例如MyObject[] b = new MyObject[10];</li><li>常量字段编译期不确定：UUID.random().toString()</li><li>父类接口：一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中运行期才确定的常量）才会初始化</li></ul></li></ul></init></li><li>卸载：当MySample类被加载，连接和初始化后，它的生命周期就开始了。当代表MySample类的Class对象不再被引用，即不可触及时，Class对象就会结束生命周期，MySample类在方法区内的数据也会被卸载，从而结束MySample类的生命周期。一个类何时结束生命周期，取决于代表它的Class对象何时结束生命周期</li></ul><blockquote><p>由Java虚拟机自带的加载器所加载的类，在虚拟机的生命周期中，始终不会被卸载。Java虚拟机自带的类加器包括根类加载器，扩展类加载器和系统类加载器。Java虚拟机本身会始终引用这些类加载器，而这些类加载器则会始引用它们所加载的类的Class对象，因此这Class对象终是可及的。由用户自定义的类加载器所加载的类是可以被卸载的。</p></blockquote><p>父子类的执行顺序</p><ul><li>父类<clinit> 子类 <clinit> 虚拟机会保证 子类初始化之前 父类已经初始化defineClass</clinit></clinit></li><li>父类<init> 子类<init></init></init></li><li><init>:父类<init>+普通成员变量赋值+代码块+构造函数</init></init></li></ul><h2 id="类加载的委派机制">类加载的委派机制</h2><p>通常情况下有4种类加载器:</p><ul><li>Bootstrap classLoader 特定目录下,JavaHome/lib</li><li>Extension classLoader 特定目录下,JavaHome/lib/ext</li><li>Application classLoader ClassHome 下 以及 外部依赖</li><li>自定义类加载器</li></ul><p>ClassLoader.defineClass</p><blockquote><p>将字节流转化为class对象</p></blockquote><p>ClassLoader.loadClass</p><ul><li>首先调用findLoadedClass:寻找是否已经加载过该类,如果有则返回</li><li>如果无,那么存在父类加载器,则尝试调用父类加载器的loadClass ,那么调用bootstrap 加载器</li><li>如果还是找不到,会调用findClass(默认抛出classNotfiound异常,被继承后需要重写逻辑;UrlClassLoader中会根据全限定类名找到路径去加载)</li></ul><p>如果想违背父类机制</p><blockquote><p>那么重写loadClass方法,首先调用findLoadedClass  然后直接调用findClass</p></blockquote><h3 id="相同类的加载">相同类的加载</h3><p>利用不同的自定义类加载器实例 实现加载,通过实现不同的findClass方法实现加载,由于JVM 中通过类加载器和全限定类名来确保一个类的唯一性,所以类名字一致但不会重合</p><h3 id="钻石依赖">钻石依赖</h3><p>项目管理上有一个著名的概念叫着「钻石依赖」，是指软件依赖导致同一个软件包的两个版本需要共存而不能冲突。<br>MAVEN</p><blockquote><p>maven 是这样解决钻石依赖的，它会从多个冲突的版本中选择一个来使用，如果不同的版本之间兼容性很糟糕，那么程序将无法正常编译运行。Maven 这种形式叫「扁平化」依赖管理。</p></blockquote><p>JVM</p><blockquote><p>使用 ClassLoader 可以解决钻石依赖问题。不同版本的软件包使用不同的 ClassLoader 来加载，位于不同 ClassLoader 中名称一样的类实际上是不同的类。</p></blockquote><h3 id="threadcontextclassloader">Thread.contextClassLoader</h3><p>首先 contextClassLoader 是那种需要显示使用的类加载器，如果你没有显示使用它，也就永远不会在任何地方用到它<br>其次线程的 contextClassLoader 默认是从父线程那里继承过来的，所谓父线程就是创建了当前线程的线程。程序启动时的 main 线程的 contextClassLoader 就是 AppClassLoader。这意味着如果没有人工去设置，那么所有的线程的 contextClassLoader 都是 AppClassLoader。</p><p>用处</p><blockquote><p>如果不同的线程使用不同的 contextClassLoader，那么不同的线程使用的类就可以隔离开来。<br>如果我们对业务进行划分，不同的业务使用不同的线程池，线程池内部共享同一个 contextClassLoader，线程池之间使用不同的 contextClassLoader，就可以很好的起到隔离保护的作用，避免类版本冲突。</p></blockquote><h3 id="类的运行时寻找机制">类的运行时寻找机制</h3><ul><li>java.lang.File 编译器会自动导入java.lang包</li><li>其他import 的包<br>如果出现多个同名的类,编译器会报错</li></ul><h3 id="classloader-的传递性">classLoader 的传递性</h3><p>当程序在运行中遇到一个未知的类时,虚拟机会使用调用者的class对象的classLoader(class有该字段记录加载器)来加载当前类,通常情况下为系统加载器即AppClassLoader</p><h2 id="final-vs-static-vs-finally">final vs static vs finally</h2><blockquote><p>final 标识常量，创建或者初始化后不可更改，可以修饰 属性，方法（不可被重写），类（不可被继承），局部变量<br>static 标识唯一性，可以修饰 变量，方法（与类的具体实例），代码段 （仅仅在类被初次加载的时候被调用一次，之后再调用不会再加载；如有父类先进行父类的初始化），不可修饰局部变量<br>finally 是异常处理里的内容，try catch finally<br>static final=final static：修饰的属性表示一旦给值，就不可修改，并且可以通过类名访问，也可以修饰方法，表示该方法不能重写</p></blockquote><h2 id="throws和throw">throws和throw</h2><blockquote><p>throws出现在方法函数头，可以跟多个异常类名，用逗号隔开，表示出现异常的一种可能性，并不一定会发生这些异常，由调用方去处理，当然也可以不处理，当产生异常，系统会报；<br>而throw出现在函数体，是抛出了异常，执行throw则一定抛出了某种异常对象。<br>两者都是消极处理异常的方式（这里的消极并不是说这种方式不好），只是抛出或者可能抛出异常，但是不会由函数去处理异常，真正的处理异常由函数的上层调用处理。</p></blockquote><h1 id="异常体系throwable">异常体系(throwable)</h1><blockquote><p><a href="https://blog.csdn.net/junlixxu/article/details/6096266" target="_blank" rel="noopener">java异常体系</a><br>Java把异常当作对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类<br>在Java API中已经定义了许多异常类，这些异常类分为两大类，错误Error和异常Exception</p></blockquote><h2 id="error">error</h2><blockquote><p>程序无法处理的错误,多与内存线程相关，比如OutOfMemoryErrorThreadDeath等。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。</p></blockquote><h2 id="exception">Exception</h2><blockquote><p>Exception是程序本身可以处理的异常，这种异常分两大类运行时异常和非运行时异常</p></blockquote><h3 id="运行时异常非受检异常">运行时异常(非受检异常)</h3><blockquote><p>个人理解 运行时才可能出现的异常,比如NullPointerException，IndexOutOfBoundsException，IllegalArgumentException,RuntimeException,InputMismatchException等,可以不处理，系统会统一处理，打出日志</p></blockquote><h3 id="非运行时异常受检异常checkexception">非运行时异常(受检异常:checkException)</h3><blockquote><p>系统在预编译检查时发现的错误,必须在编译前解决，否则无法编译成功，比如IOException、SQLException等以及用户自定义的Exception<br>通过throws 要求调用者必须处理或者向上排除</p></blockquote><h2 id="异常处理">异常处理</h2><ul><li>try catch finally</li><li>throws 可能的Exception 有调用者处理</li><li>异常链的处理,避免异常覆盖：Throwable 里面有 cause同类型字段,可以保存构造异常时传递的根异常参数,实现异常链条</li></ul><h1 id="出现异常的处理方法">出现异常的处理方法</h1><p>top<br>ps -ef<br>gc<br>iostat  查TCP 连接</p><h1 id="java-多线程-java多线程面试题">Java 多线程 <a href="https://blog.csdn.net/qq_36387471/article/details/105479238" target="_blank" rel="noopener">Java多线程面试题</a></h1><h1 id="java-spi机制是什么">Java SPI机制是什么？</h1><blockquote><p>SPI(service Provider  interface)是一种服务发现机制，提供服务接口，且为该接口寻找服务的实现<br>约定：</p></blockquote><ul><li>当服务提供者提供了接口的一种具体实现后，在jar包的META-INF/services目录下创建一个以“接口全限定名”为命名的文件，内容为实现类的全限定名；</li><li>接口实现类所在的jar包放在主程序的classpath中；</li><li>主程序通过java.util.ServiceLoder动态装载实现模块，它通过扫描META-INF/services目录下的配置文件找到实现类的全限定名，把类加载到JVM；</li><li>SPI的实现类必须携带一个不带参数的构造方法；</li></ul><p>加载过程</p><ul><li>ServiceLoader 初始化</li><li>应用程序通过迭代器接口获取对象实例：首先判断是否有缓存实例对象,如果没有就通过反射加载对象并实例化,并把实例化对象缓存到provider,返回对象</li></ul><p>加载-&gt;验证-&gt;解析-&gt;初始化-&gt;使用-&gt;卸载</p><p><a href="https://juejin.im/post/6844903633574690824" target="_blank" rel="noopener">JVM 类加载机制及双亲委派模型</a></p><h1 id="双亲委派模式">双亲委派模式</h1><p>类加载器</p><ul><li>启动（Bootstrap）类加载器：负责将 Java_Home/lib下面的类库加载到内存中（比如rt.jar）。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以不允许直接通过引用进行操作</li><li>标准扩展（Extension）类加载器：基于java是由 Sun 的 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将Java_Home /lib/ext或者由系统变量 java.ext.dir指定位置中的类库加载到内存中。开发者可以直接使用标准扩展类加载器。</li><li>应用程序（Application）类加载器：基于java是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。它负责将系统类路径（CLASSPATH）中指定的类库加载到内存中。开发者可以直接使用系统类加载器。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，因此一般称为系统（System）加载器。</li><li>自定义加载器<br>该模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器，而这种父子关系一般通过组合（Composition）关系来实现，而不是通过继承（Inheritance）</li></ul><p>需要注意的是 对于任意一个类，都需要由加载它的类加载器和这个类本身共同确立其在Java虚拟机中的唯一性</p><p>双亲委派模型：</p><blockquote><p>某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。<br>这样可以防止他人写的类替换掉系统的默认类</p></blockquote><p><a href="https://juejin.im/post/6844903806757502984" target="_blank" rel="noopener">java 循环依赖</a></p><p><a href="https://baijiahao.baidu.com/s?id=1667840029586081215" target="_blank" rel="noopener">内存屏障</a><br>指令重排序</p><blockquote><p>对于单线程的指令,可能对指令重排序减少对于寄存器的反复读写操作,可以减少执行时间,而多线程下的指令重排序可能导致意外的错误,比如使用未初始化的变量</p></blockquote><p>内存一致性问题</p><blockquote><p>内存模型：对于多核CPU,每个核都使用高速缓存加快数据的读取(而不是每次都到主存存取),但是每个CPU的高速缓存必然是互相隔离的,可能出现共享变量副本不一致的情况<br>一般有两种解决方案：</p></blockquote><ul><li>在总线上加锁的方式:在总线上发送busy信号,阻塞其他CPU对 与其他部件的访问 比如 内存,但是效率低下</li><li>缓存一致性协议：比如说inter的MESI 协议保证了每个缓存中使用的变量副本一致</li></ul><p>内存屏障分为两种</p><ul><li>load barrier：读屏障</li><li>Store barrier：写屏障</li></ul><p>内存屏障的作用</p><ul><li>阻止屏障两侧的指令重排序</li><li>写的时候,强制把缓冲区/高速缓存的数据写会内存,并让缓冲区的数据失效,读的时候需要从主存读取</li></ul><p>常见的内存屏障组合有4种</p><ul><li>LoadLoad屏障:保证屏障后的语句读取数据之前完成之前语句的读操作</li><li>StoreStore屏障：保证屏障后的写入操作执行之前,之前的写入操作的对其他处理器可见(获取最新结果)</li><li>LoadStore 屏障：保证屏障之后的写操作被执行完之前,之前读操作的结果必须完成</li><li>StoreLoad 屏障：保证之后的读操作执行之前,屏障之前的写操作的结果对其他处理器可见<br>其中StoreLoad是核心 ,因为只有先写后读的操作顺序颠倒才会导致比较严重的后果</li></ul><p>volatile 与 内存屏障</p><ul><li>在每个volatile写操作之前插入StoreStore屏障,在其之后 插入StoreLoad屏障</li><li>在每个volatile读操作之前插入LoadLoad屏障,在其之后插入LoadStore屏障<br>从而禁止了指令的重排序和内存的可见性</li></ul><p>提前担保机制</p><p>static synchronize VS synchronize</p><p>ZGC</p><p><a href="https://www.pianshen.com/article/38291243907/" target="_blank" rel="noopener">JVM里的记忆集合</a><br>GC两个关键难点</p><ul><li>跨代引用：分带收集将对象分为老年代和年轻代,年轻代朝生夕死,YGC频繁发生,但是可能存在老年代引用新生代导致错误清除新生代对象</li><li>并发标记：stop-word方式的标记对系统影响大,且没有利用多核资源,故而采用并发标记,但是并发标记过程中存在对象的变化没有被感知的风险</li></ul><p>为了解决跨代引用,最简单的方法就是遍历所有的老年代对象,但是实际上只有少部分老年代对象对于年轻代对象有引用,这样效率很低：从而引入了&quot;记忆集&quot;的思想<br>记忆集：记录非GC收集区域指向收集区域的抽象数据结构,具体而言就是记录内存空间是否存在记老年代对于新生代的引用状况,根据记录精度分为3种</p><ul><li>字长精度：每个记录精确到一个机器字长,该字中包含跨代指针</li><li>对象精度：每个记录精确到一个对象,该对象包含跨代指针字段</li><li>卡精度：每个记录精确到一块内存区域,该区域中包含跨代指针<br>CMS 和 G1 中使用的是cardTable基于卡精度;卡表是个字节数组，每个字节对应堆空间老生代中的512个字节（这512个字节叫做卡页）是否有跨代引用</li></ul><p><a href="https://blog.csdn.net/MACRosshaha/article/details/108433196" target="_blank" rel="noopener">GC</a><br>并发标记的可达性分析:<br>三色标记：</p><ul><li>白色：尚未被垃圾收集器访问</li><li>黑色：已被访问,且该对象的所有引用已被扫描</li><li>灰色：已被访问,且至少存在一个对象未被扫描</li></ul><p>并发标记可能出现浮动垃圾和对象消失问题</p><blockquote><p>浮动垃圾:黑色对象的引用白色对象不再应用<br>对象消失：新增白色对象被黑色对象引用,但没有拉入统计而被回收<br>浮动垃圾的问题并不严重,数量不大而且可以下次回收;而对象消失可能干扰 系统的运行导致严重后果</p></blockquote><p>对象消失必然有两个前提：</p><ul><li>增加了黑色对象到该白色对象的引用</li><li>删除后了所有灰色对象对于到该白色对象的直接或者间接引用<br>解决方法：</li><li>增量更新：记录新增的黑色对白色的引用,并发结束后,重新扫描</li><li>原始快照：在开始GC之前,对对对象之间的关系快照,涉及删除灰色到白色引用时备份引用,后面再扫描确认(此间产生的对象默认存活)<br>两种方法 都通过写屏障 来实现记录的操作(并非内存屏障)<br><a href="https://cloud.tencent.com/developer/article/1599225" target="_blank" rel="noopener">G1回收器：我怎么知道你是什么时候的垃圾 垃圾回收详细过程</a></li></ul><p>高并发下 写屏障可能导致虚共享问题<br><a href="https://www.cnblogs.com/cyfonly/p/5800758.html" target="_blank" rel="noopener">false sharing</a> 并发杀手<br>CPU 和 3级cache<br>其中速度 L1&gt;L2&gt;L3; 空间L3&gt;L2&gt;L1<br>每个cpu核有自己的L1 L2缓存,共享L3级缓存<br>缓存中以缓存行(cache Line)作为单位存储,通常是64字节,一次性读取连续的64字节的数据,他有效隐射内存的一块地址<br>当多线程所私有的变量处于同一个cache行时,会出现多线程轮番争用拥有权,并发变串行,同时该cache行的更改会将其他核高级cache行设置为失效,强制要求读取内存,即伪共享(可以通过<a href="http://ifeve.com/disruptor-cacheline-padding/" target="_blank" rel="noopener">缓存行填充</a>,使得自己的变量成为占满缓存行)<br>而在G1通过配置要求判断是否已经为脏位,是脏位就无须再写,同时java中支持配置注解填充缓存行</p><p>java  泛型和 重写 继承的关系和缺陷<br><a href="https://www.cnblogs.com/wuqinglong/p/9456193.html" target="_blank" rel="noopener">Java泛型类型擦除以及类型擦除带来的问题</a><br><a href="http://blog.sina.com.cn/s/blog_7ffb8dd501012ku9.html" target="_blank" rel="noopener">泛型与类型擦除</a></p><blockquote><p>在代码阶段的重载检查和在JVM 阶段的检查<br>如何实现泛型的多态</p></blockquote><p>Java 基础，集合类有哪些，全部说一遍</p><blockquote><p>四大类吧，分别是List、Queue、Set、Map</p></blockquote><ul><li>List：常见的有 ArrayList、LinkedList、Vector、CopyOnWriteArrayList</li><li>Queue：常见的有 ArrayDeque、PriorityQueue、ArrayBlockingQueue、LinkedBlockingQueue、DelayBlockingQueue等等</li><li>Map：HashMap、LinkedHashMap、TreeMap、ConcurrentHashMap等等</li><li>Set：HashSet、LinkedHashSet、TreeSet等</li></ul><p>JAVA的final字段</p>]]></content>
      
      
      
        <tags>
            
            <tag> java 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读</title>
      <link href="/2020/06/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
      <url>/2020/06/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h4 id="大多是data-center-资源集中">大多是Data Center ,资源集中</h4><h4 id="cooperative-game-based-virtual-machine-resource-allocation-algorithms-in-cloud-data-centershindawi">Cooperative Game-Based Virtual Machine Resource Allocation Algorithms in Cloud Data Centers(hindawi)</h4><ol><li>Cloud Data Center(CDC)资源利用率低</li><li>思路：对不同资源使用不同的基于 value 的博弈论解决方法;<ul><li>CPU: Shaply value(SV), payoff by number contribution</li><li>memory: weighted Shaply value(WSV),payoff by coliation ;and  members’s payoff about positive effort of coliation</li><li>storage: proportional Shaply value(PSV)</li><li>bandwith: weigthed-egalitarian Shaply value(WESV) payoff by member contribution and  heterogeneity between members</li></ul></li><li>不足：<ul><li>task 生成分为四类,每类的资源要求固定(task 不具有 变动性)</li><li>数据未公开</li><li>未解释 四类资源某些不足时的处理???</li></ul></li></ol><h4 id="game-theoretic-resource-allocation-in-cloud-computing">Game theoretic resource allocation in cloud computing</h4><ol><li>介绍：同名书中的相干章节，基于Min-Max Game<ul><li>输入：request的信息，resource的信息</li><li>输出：分配矩阵</li></ul></li><li>思路：实现最大化资源的 utility(效用) 的目标；</li><li>utility 的公式构成(又分为单类资源utility和全局资源utility) ?? 不同资源,CPU<ul><li>budget</li><li>cost per sencod</li><li>request 量</li><li>request time 消耗时间</li><li>budget和time的factor因子</li></ul></li><li>算法：<ul><li>挑选出可以进行博弈的request</li><li>依次对每一种资源选择全局最大化utility时的分配，iteration</li></ul></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> cloud-computing resource allocation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>毕设实验</title>
      <link href="/2020/06/11/%E5%B7%A5%E5%85%B7/%E6%AF%95%E8%AE%BE/"/>
      <url>/2020/06/11/%E5%B7%A5%E5%85%B7/%E6%AF%95%E8%AE%BE/</url>
      
        <content type="html"><![CDATA[<p>##实验分类：</p><ol><li>小规模 系统搭建(请求链条不需要长)</li><li>大规模仿真模拟(可以模拟长请求链和大规模，大流量)</li></ol><p>###小规模系统构成：</p><ol><li>请求发送者(微服务的benchmark 附带流量)</li><li>微服务benchmark/请求处理<ul><li>服务链确定</li><li>流量监控(istio)</li></ul></li><li>决策中心(初次放置,调整): 博弈论均衡<ul><li>思路：<ul><li>分类</li><li>加权 集中</li></ul></li><li>放置：资源充足时, 参数 服务链(整体时延) &gt; 资源使用集中程度(避免资源过度集中于某些machine,也避免过度分散)</li><li>缩容：谨慎，按照kubeneats自带策略/长期监控流量,然后决策调整</li><li>扩容：存在多服务链扩容,博弈论<ul><li>资源不冲突，分配</li><li>资源冲突，考虑优先级, 其他参数 资源利用率,资源集中程度<br>###大规模仿真模拟</li></ul></li></ul></li><li>工具：CloudSim(docker)</li><li>微服务的指标细化(QOS,基本资源需求,基本处理能力)</li><li>流量构造(常规多样流量；突发大规模流量)</li></ol><p>###目标：</p><ol><li>满足已存在的QOS 要求(根据流量调整实例的部署，扩缩容)</li><li>资源利用率</li><li>性能表现(latency,稳定性)</li></ol><p>###问题：</p><ol><li>利用博弈论简化问题，<ul><li>只考虑了部署实例的问题，没有考虑具体资源的供给(如何量化的问题),</li><li>暂时没有考虑后续的伸缩</li><li>未考虑 资源不集中</li></ul></li><li>平衡不是目标，平衡是为了降低干扰，我的目标是提高QOS，稳定性，提高资源利用率，降低资源占有率</li><li>长请求链的实际存在依据(实际运行中的每个环节都是请求链的一环)：更多例子</li><li>微服务benchmark的自带流量测试比较简单/不够复杂和波动，需要重新构造设计</li></ol><p>已完成：</p><ol><li>benchmark:<br>1.1 已部署 <a href="https://github.com/microservices-demo/microservices-demo" target="_blank" rel="noopener">Sock-Shop</a> <a href="https://github.com/GoogleCloudPlatform/microservices-demo" target="_blank" rel="noopener">Hipster</a> <a href="https://github.com/FudanSELab/train-ticket/wiki" target="_blank" rel="noopener">Train-Ticket</a> <a href="https://github.com/delimitrou/DeathStarBench" target="_blank" rel="noopener">DeahStarBench</a></li></ol><p>1.2 待部署 <a href="https://github.com/dream-lab/riot-bench" target="_blank" rel="noopener">Riot</a></p><ol start="2"><li>决策中心<br>2.1 熟悉了解 <a href="https://www.coursera.org/learn/game-theory-1/" target="_blank" rel="noopener">博弈论理论</a><br>2.2 算法实现，需要想清楚问题</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Kuberneats </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>源码阅读</title>
      <link href="/2020/04/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
      <url>/2020/04/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>docker</p><ul><li><a href="https://mp.weixin.qq.com/s/zyDGaT6SGFUVU60r9L7S3Q?" target="_blank" rel="noopener">参考博客1</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>云计算模拟</title>
      <link href="/2020/03/31/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E4%BA%91%E8%AE%A1%E7%AE%97%E6%A8%A1%E6%8B%9F/"/>
      <url>/2020/03/31/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E4%BA%91%E8%AE%A1%E7%AE%97%E6%A8%A1%E6%8B%9F/</url>
      
        <content type="html"><![CDATA[<p>毕业设计需要对于大型云计算环境进行模拟，经过调研，决定使用<a href="http://www.cloudbus.org/cloudsim/" target="_blank" rel="noopener">CloudSim</a> <a href="https://github.com/Cloudslab/cloudsim" target="_blank" rel="noopener">Github</a></p><p>CloudSim是在离散事件模拟包SimJava上开发的函数库,可以直接当做Java工程使用，即导入IDEA<br><a href="https://www.cnblogs.com/sddai/p/6036893.html" target="_blank" rel="noopener">国内比较全的关于CloudSim的介绍</a><br><a href="https://www.cnblogs.com/xxfna/articles/9563068.html" target="_blank" rel="noopener">如何将CloudSim导入IDEA</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> CloudSim </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux</title>
      <link href="/2020/01/13/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/linux/"/>
      <url>/2020/01/13/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/linux/</url>
      
        <content type="html"><![CDATA[<p>本问用于记录linux常用的命令</p><p>ssh</p><p>scp</p><blockquote><p>在两个服务器之间传输文件<br>rz<br>传输本地文件到服务器<br>sz [filename]<br>传输服务器文件到本地</p></blockquote><p>find [PATH] [option]</p><blockquote><p>在指定目录下查找相关文件<br>example : find . -name “name”</p></blockquote><p>tail [file] [option]</p><blockquote><p>从后开始查询文件，默认查询最后十行<br>tail -n 100 nohup.log</p></blockquote><p>cat/touch<br>netstat<br>telnet<br>chown/chmod/chgrp<br>useradd</p><p>配置 <a href="https://wiki.archlinux.org/index.php/Readline" target="_blank" rel="noopener">命令自动补全</a></p><blockquote><p>配置 ~/.inputrc 文件</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> linux command </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>shell</title>
      <link href="/2020/01/12/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/shell/"/>
      <url>/2020/01/12/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/shell/</url>
      
        <content type="html"><![CDATA[<p>shell 是UNIX系统的用户与操作系统之间的一种接口;</p><p><a href="https://blog.csdn.net/Jiaach/article/details/83788984" target="_blank" rel="noopener">注意事项</a><br>在 单引号 以及 反单引号 里使用 ${AVAILABLE}引用变量</p><p>PATH 变量 谨慎使用</p>]]></content>
      
      
      
        <tags>
            
            <tag> shell script </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>frp</title>
      <link href="/2020/01/12/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/frp/"/>
      <url>/2020/01/12/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/frp/</url>
      
        <content type="html"><![CDATA[<p>云服务器　<a href="https://promotion.aliyun.com/ntms/act/campus2018.html" target="_blank" rel="noopener">阿里云ECS</a><br>关于端口限制(connect timeout) <a href="https://blog.csdn.net/cao0507/article/details/82758288" target="_blank" rel="noopener">https://blog.csdn.net/cao0507/article/details/82758288</a></p><p>crontab</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">PROCESS_NUM=`ps -ef | grep &quot;frpc -c &quot; | grep -v &quot;grep&quot; | wc -l`</span><br><span class="line">FRP_PATH=&apos;/home/sun/fpr/frp_0.31.1_linux_amd64&apos;</span><br><span class="line">if [ $PROCESS_NUM -lt 1 ];</span><br><span class="line">then</span><br><span class="line">    `nohup $&#123;FRP_PATH&#125;/frpc -c $&#123;FRP_PATH&#125;/frpc.ini &gt; $&#123;FRP_PATH&#125;/nohup.out 2&gt;&amp;1 &amp;`</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/womenrendeme/article/details/89053746" target="_blank" rel="noopener">多客户端</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> frp shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker</title>
      <link href="/2020/01/09/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/docker/"/>
      <url>/2020/01/09/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/docker/</url>
      
        <content type="html"><![CDATA[<p>##Install<br><a href="https://docs.docker.com/install/linux/linux-postinstall/" target="_blank" rel="noopener">官方教程</a></p><p>##Usage<br>docker</p><blockquote><p>docker ps -a<br>docker images<br>dokcer stop/restart/rm CONTAINER_ID<br>docker rmi IAMGE_ID<br>docker logs CONTAINER_ID --tail NUMBER<br>docker inspect</p></blockquote><p>dokcer java 应用启动慢　尝试解决</p><blockquote><p>1.非阻塞熵池策略 优化　<a href="http://hongjiang.info/tomcat-startup-slowly-in-docker/" target="_blank" rel="noopener">Docker中apache-tomcat启动慢的问题</a>　<a href="https://www.cnblogs.com/a1304908180/p/10745284.html" target="_blank" rel="noopener">为什么阿里云服务器的docker启动tomcat这么慢？</a> -Djava.security.egd=file:/dev/urandom　－＞　-Djava.security.egd=file:/dev/./urandom<br>2.JVM 容量优化，即增加参数值 -Xms256m -Xmx512m -XX:PermSize=64m -XX:MaxPermSize=128m</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> docker install use </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubernets</title>
      <link href="/2020/01/09/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/kubernets/"/>
      <url>/2020/01/09/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/kubernets/</url>
      
        <content type="html"><![CDATA[<h2 id="install">Install</h2><p>我安装的是 minikube <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-linux" target="_blank" rel="noopener">K8S官方教程</a><br>注意点:</p><ul><li><p>网络问题：</p><ul><li><a href="https://coding.imooc.com/learn/questiondetail/81560.html" target="_blank" rel="noopener">更改镜像源</a></li><li>更改 k8s image 源<blockquote><p>kubeadm init --image-repository <a href="http://registry.aliyuncs.com/google_containers" target="_blank" rel="noopener">registry.aliyuncs.com/google_containers</a><br>kubeadm init --image-repository <a href="http://index.docker.io/mirrorgooglecontainers" target="_blank" rel="noopener">index.docker.io/mirrorgooglecontainers</a></p></blockquote></li></ul></li><li><p>启动选项:</p><ul><li>选择 vm drive(in local linux environment use local docker)</li></ul><blockquote><p>minikube start --vm-driver=none</p></blockquote><ul><li>更改 kubeadm 配置</li></ul><blockquote><p>导出　kubeadm 原本配置　old.yaml，然后更改为 new.yaml<br>kubeadm config migrate --old-config old.yaml --new-config new.yaml</p></blockquote></li><li><p>最终:</p></li></ul><blockquote><p>minikube start --vm-driver=none --image-repository=<a href="http://registry.aliyuncs.com/google_containers" target="_blank" rel="noopener">registry.aliyuncs.com/google_containers</a></p></blockquote><h2 id="kubernetsminikube-相关操作">Kubernets/minikube 相关操作</h2><p><a href="http://docs.kubernetes.org.cn/664.html" target="_blank" rel="noopener">k8s中文文档</a><br>minikube</p><blockquote><p>minikube stop/delete</p></blockquote><p>port</p><blockquote><p>containerPort,targetPort,nodePort,port 之间的区别<br>在deployment 文件中　containerPort相当于映射到容器外的端口 == docker run IMAGE_ID -P OUTSIDE_PORT:INSIDE_PORT<br>docker exec -it  --privileged   ab56f4a5d15c  /bin/sh  携带权限进入 docker，避免进入docker内需要某些权限的操作</p></blockquote><p>kubectl</p><blockquote><p>kubectl describe pod/orders-5dbffdd8ff-zqp2c --namespace=‘sock-shop’<br>kubectl get pods --namespace=‘sock-shop’<br>kubectl edit deploy/shipping  --namespace=‘sock-shop’</p></blockquote><h2 id="相关概念">相关概念</h2><ol><li>pod vs container</li><li>containerPort vs targetPort vs nodePort vs port</li><li>service</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> k8s install </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>microservice 部署</title>
      <link href="/2020/01/08/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BE%AE%E6%9C%8D%E5%8A%A1/microservice/"/>
      <url>/2020/01/08/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BE%AE%E6%9C%8D%E5%8A%A1/microservice/</url>
      
        <content type="html"><![CDATA[<h2 id="部署-microservice-benchmark">部署　microservice benchmark</h2><p><a href="https://github.com/microservices-demo/microservices-demo" target="_blank" rel="noopener">官方教程</a></p><h2 id="问题">问题</h2><ol><li><p>yml部署文件　unable to recognize</p><ul><li>错误：</li></ul><blockquote><p>unable to recognize “deploy/kubernetes/manifests-logging/elasticsearch.yml”: no matches for kind “Deployment” in version “extensions/v1beta1”, unable to recognize “deploy/kubernetes/manifests-logging/fluentd-daemon.yml”: no matches for kind “DaemonSet” in version “extensions/v1beta1”, unable to recognize “deploy/kubernetes/manifests-logging/kibana.yml”: no matches for kind “Deployment” in version “extensions/v1beta1”</p></blockquote><ul><li>解决　<a href="https://github.com/microservices-demo/microservices-demo/issues/802" target="_blank" rel="noopener">benchmark github issue</a></li></ul></li><li><p>部署pod无法正常运行</p><ul><li>部署错误，原本服务应当暴漏出的接口无法访问</li></ul><blockquote><p>发现是因为 一些pod在部署之后，发现频繁重启,就是因为这些暴露出的接口无法访问，它们是作为监测是否健康的接口存在，认为容器启动错误，因而POD重启container<br>NAME                            READY   STATUS        RESTARTS   AGE<br>carts-fc985d95-h78dn            0/1     Running       22         12h<br>经过各种排查，无法发现原因，最终一次偶然发现行得通了，尝试通过更改配置重现这次情况，最后发现，是因为容器启动太慢，导致监测的delay相对太小，因而监测失败<br>而重复监测失败，重复重启，又有多个pod(contianer)重启，导致CPU占有率高，从而启动速度可能更受影响</p></blockquote><ul><li>尝试排查错误<br>　       1. 观察日志无法发现错误<br>　       2. 经过观察，基本都是80端口的问题</li><li>尝试<br>　       1. 是否因为port范围限制?尝试在/etc/kubernets/manifests/api-servers.yaml中更改，无效<br>　       2. 尝试更改　pod 的yaml 中的port ，并重新apply,确定是否是端口限制的原因</li><li>解决方法：</li></ul><blockquote><p>本质是因为docker启动慢，而此时　pod 的检测已经开始了，从而判断docker未正常启动，从而重启docker,从而陷入循环，所以有两种方法<br>1.加快docker的启动速度，详见<a href="https://walkdeadtobe.github.io/2020/01/09/docker/" target="_blank" rel="noopener">dokcer java 应用启动慢</a><br>2.延后pod的检测，等docker正常启动，可以增加 initialDelaySeconds,failureThreshold,periodSeconds,successThreshold等参数的值</p></blockquote></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> microservice deployment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Coding</title>
      <link href="/2019/12/30/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%87%8D%E6%9E%84/"/>
      <url>/2019/12/30/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%87%8D%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p>最近在重构之前用java写的SSO的代码，有点感触<br>1.对自己写的屎一样的代码，尽量重构，起码让自己以后重新看时，还敢承认这是自己的代码<br>2.写代码时，要注意自己的最初目的，不要让函数超出了它本身应该做的事情<br>3.尽量不要涉及硬编码的部分，如果大量重复的硬编码，那么该思考是不是必要的，也许它应该是数据库的信息？</p>]]></content>
      
      
      
        <tags>
            
            <tag> reconstruct </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>deployment</title>
      <link href="/2019/12/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%83%A8%E7%BD%B2/"/>
      <url>/2019/12/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<blockquote><h1 id="1-nginx">1 nginx</h1></blockquote><blockquote><blockquote><h2 id="11-dockerfile">1.1 dockerfile</h2></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#Dockerfile</span><br><span class="line">FROM nginx:latest</span><br><span class="line">MAINTAINER chengr chengr@buaa.edu.cn</span><br><span class="line">#mkdir</span><br><span class="line">RUN mkdir -p /home/cast/web/kexie_BigScreen_vue/dist \</span><br><span class="line"> &amp;&amp; mkdir -p /home/cast/web/act-kexie-big \</span><br><span class="line"> &amp;&amp; mkdir -p /home/cast/web/vue_front_of_talent/vue-demo \</span><br><span class="line"> &amp;&amp; mkdir -p /home/cast/web/talent_zhejiang/vue-demo \</span><br><span class="line"> &amp;&amp; mkdir -p /home/cast/web/kexie_news/dist \</span><br><span class="line"> &amp;&amp; mkdir -p /home/cast/web/activeDay0904 \</span><br><span class="line"> &amp;&amp; mkdir -p /home/cast/web/kexie_Local_BigScreen_vue/dist \</span><br><span class="line"> &amp;&amp; mkdir -p /home/cast/web/kexie_Local_BigScreen_GuangXi/dist \</span><br><span class="line"> &amp;&amp; mkdir -p /home/cast/web/kexie_BigsScreen_city/dist</span><br><span class="line"></span><br><span class="line">#WORKDIR /home/LAB/bdbc.kg</span><br><span class="line">#copy file</span><br><span class="line">COPY nginx.conf /etc/nginx/</span><br><span class="line">COPY default /etc/nginx/conf.d/default.conf</span><br><span class="line">#COPY Frontend/talent/vue-demo /home/cast/web/vue_front_of_talent/vue-demo</span><br><span class="line">#COPY /home/LAB/bdbc.kg/Frontend/kexie/dist /home/cast/web/kexie_BigScreen_vue/dist</span><br><span class="line"></span><br><span class="line">EXPOSE 80 8003 8010 9010  8888 8889  8890  8891</span><br></pre></td></tr></table></figure><blockquote><blockquote><h2 id="12-build-images">1.2 build images</h2></blockquote></blockquote><p>docker build -t nginx_bh .</p><blockquote><blockquote><h2 id="13-create-container">1.3 create container</h2></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">docker run \</span><br><span class="line">--name beihang_nginx \</span><br><span class="line">-p 80:80 \</span><br><span class="line">-p 8010:8010 \</span><br><span class="line">-p 9010:9010 \</span><br><span class="line">-p 8888:8888 \</span><br><span class="line">-p 8889:8889 \</span><br><span class="line">-p 8890:8890 \</span><br><span class="line">-p 8891:8891 \</span><br><span class="line">-p 8003:8003 \</span><br><span class="line">-v /home/LAB/bdbc.kg/Frontend/talent/vue-demo:/home/cast/web/vue_front_of_talent/vue-demo \</span><br><span class="line">-v /home/LAB/bdbc.kg/Frontend/kexie_BigScreen_vue/dist:/home/cast/web/kexie_BigScreen_vue/dist \</span><br><span class="line">-v /home/LAB/bdbc.kg/Frontend/talent_zhejiang/vue-demo:/home/cast/web/talent_zhejiang/vue-demo \</span><br><span class="line">-d nginx_bh</span><br></pre></td></tr></table></figure><blockquote><p>其他需要注意或者修改的地方</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python ~/replace.py</span><br></pre></td></tr></table></figure><p>替换前端页面/nginx配置文件(网关地址,单点登录服务地址)</p><blockquote><p>增加新后端时，需要注意的地方</p></blockquote><ul><li>1.后端以及网关处关于验证的部分是否需要更改（待改进）<ul><li>1.1 后端管理授权部分代码</li><li>1.2 网关与SSO 交互部分</li></ul></li><li>2.是否可能因为时延部分，导致网关与后端验证失败</li></ul><blockquote><h1 id="2-kong">2 kong</h1></blockquote><blockquote><blockquote><h2 id="21-dockerfile">2.1 dockerfile</h2></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#Dockerfile</span><br><span class="line">FROM gecwf5gs.mirror.aliyuncs.com/library/kong:1.4</span><br><span class="line">WORKDIR /usr/src/app</span><br><span class="line">ADD my_kong_plugin my_kong_plugin</span><br><span class="line">WORKDIR /usr/src/app/my_kong_plugin</span><br><span class="line">RUN luarocks make &amp;&amp; luarocks pack kong-plugin-myplugin &amp;&amp; luarocks install kong-plugin-myplugin-0.1.0-1.all.rock &amp;&amp; cp ./conf/kong.conf /etc/kong/</span><br><span class="line">ENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]</span><br><span class="line">EXPOSE 8000 8443 8001 8444</span><br><span class="line">STOPSIGNAL SIGQUIT</span><br><span class="line">CMD [&quot;kong&quot;, &quot;docker-start&quot;]</span><br></pre></td></tr></table></figure><blockquote><blockquote><h2 id="22-build-image">2.2 build image</h2></blockquote></blockquote><p>docker build -t  gateway .</p><blockquote><blockquote><h2 id="23-create-container">2.3 create container</h2></blockquote></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name gateway \</span><br><span class="line">--network=kong-net \</span><br><span class="line">-e &quot;KONG_DATABASE=postgres&quot; \</span><br><span class="line">-e &quot;KONG_PG_</span><br><span class="line">hunHOST=kong-database&quot; \</span><br><span class="line">-e &quot;KONG_CASSANDRA_CONTACT_POINTS=kong-database&quot; \</span><br><span class="line">-e &quot;KONG_PLUGINS= bundled,kong-plugin-myplugin&quot;   \</span><br><span class="line">-e &quot;KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl&quot; \</span><br><span class="line">-p 8000:8000 \</span><br><span class="line">-p 8443:8443 \</span><br><span class="line">-p 8001:8001 \</span><br><span class="line">-p 8444:8444 \</span><br><span class="line">-e &quot;KONG_PROXY_ACCESS_LOG=/dev/stdout&quot; \</span><br><span class="line">-e &quot;KONG_ADMIN_ACCESS_LOG=/dev/stdout&quot; \</span><br><span class="line">-e &quot;KONG_PROXY_ERROR_LOG=/dev/stderr&quot; \</span><br><span class="line">-e &quot;KONG_ADMIN_ERROR_LOG=/dev/stderr&quot; \</span><br><span class="line">gateway</span><br></pre></td></tr></table></figure><blockquote><p>额外需要修改 或者注意的地方</p></blockquote><p>conf/kong.conf 或者 /etc/kong/kong.conf</p><p>1.配置因为API请求中包含很大数据量,不配置会导致数据传输不完全(相应需要配合修改docker nginx 中相关内容)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">nginx_proxy_large_client_header_buffers = 8 64k  </span><br><span class="line">nginx_proxy_proxy_buffer_size = 40m  </span><br><span class="line">nginx_proxy_proxy_buffers = 4 40m  </span><br><span class="line">ngin_proxy_proxy_read_timeout = 600  </span><br><span class="line">nginx_proxy_proxy_send_timeout = 600</span><br></pre></td></tr></table></figure><p>2.定义log格式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx_http_log_format=notice escape=json &apos;&#123; &quot;@timestamp&quot;: &quot;$time_iso8601&quot;, &apos; &apos;&quot;remote_addr&quot;: &quot;$remote_addr&quot;, &apos; &apos;&quot;referer&quot;: &quot;$http_referer&quot;, &apos; &apos;&quot;request&quot;: &quot;$request&quot;, &apos; &apos;&quot;status&quot;: $status, &apos; &apos;&quot;bytes&quot;:$body_bytes_sent, &apos; &apos;&quot;agent&quot;: &quot;$http_user_agent&quot;, &apos; &apos;&quot;user&quot;: &quot;$http_username&quot;, &apos; &apos;&quot;x_forwarded&quot;: &quot;$http_x_forwarded_for&quot;, &apos; &apos;&quot;upstr_addr&quot;: &quot;$upstream_addr&quot;,&apos; &apos;&quot;upstr_host&quot;: &quot;$upstream_http_host&quot;,&apos; &apos;&quot;ups_resp_time&quot;: &quot;$upstream_response_time&quot; &#125;&apos;</span><br></pre></td></tr></table></figure><p>3.更改access/error日志格式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">proxy_access_log =  /dev/stdout  notice  </span><br><span class="line">admin_access_log =  /dev/stdout  notice  </span><br><span class="line">proxy_error_log  =  /dev/stderr  </span><br><span class="line">admin_error_log =  /dev/stderr</span><br></pre></td></tr></table></figure><p>4.修改kong插件代码 myplugin/access.lua</p><blockquote><p>210.14.118.96/210.14.118.95/smart.cast.org.cn-&gt;10.1.1.1<br>111.203.146.69/sso-smart.cast.org.cn:8080 -&gt;10.1.1.2:8080</p></blockquote><p>5.代码中使用时间作为加密因素之一，注意与后端服务时区保持一致，否则可能导致后端验证失败,401</p><blockquote><p>初步解决方案为　多个服务器　都　使用时间戳都转化为北京时间</p></blockquote><p>6.开启 myplugin key-auth<br>7.psql -U kong  -W</p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bug记录和解决</title>
      <link href="/2019/12/20/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/bug%E8%AE%B0%E5%BD%95%E5%92%8C%E8%A7%A3%E5%86%B3/"/>
      <url>/2019/12/20/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/bug%E8%AE%B0%E5%BD%95%E5%92%8C%E8%A7%A3%E5%86%B3/</url>
      
        <content type="html"><![CDATA[<ol><li></li></ol><blockquote><p>问题描述：人才库后端检测token失效后,返回要求跳转<br>bug描述：由于返回跳转地址与Host不同,涉及跨域问题<br>尝试1：解决问题位置,排除了问题出在授权服务器所在,确定由于浏览器拦截跨域请求<br>尝试2：尝试将跨域请求伪装成同域的请求,在经同域的nginx拦截,使用rewrite规则或者return 301 重定向；错误,由于ajax请求,是局部数据请求,本身就是为了避免全局刷新的问题,所以ajax请求会自动紧接着执行重定向请求,最终仍然跨域<br>尝试3：尝试获取后端返回的重定向请求中的Location header,然后可以在ajax的complete函数中实现判断301/302状态,跳转到Location所在地址,错误：同尝试2的错误,ajax请求会紧接着执行重定向请求,因而会导致最终执行到complete函数时,已经没有 Location 头,（此外也可能是因为跨域请求只允许暴露部分header,你也可以选择在Access-Control-Expose-Headers 中添加 你所需要暴露进而获取的header）<br>尝试4：从后端入手,当token过期或者无token时,构造状态码为401（Unauthorized）的请求,并添加Header Location的值为所要跳转的地址,同时将Location 添加到 Access-Control-Expose-Headers中,最后在前端的ajax 请求 complete函数中,设置对于 401请求的跳转处理</p></blockquote><ol start="2"><li></li></ol><blockquote><p>问题描述：spring oauth code 模式,以code请求token ,无法获得token,报 500 错误<br>排查:查看当时日志,发现是数据库查询出现问题,但没有指明查询的数据表；因而 开启MySQL数据库的日志功能,记录查询操作,从而定位数据表</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set global general_log=on; #开启日志</span><br><span class="line">show variables like &apos;%general_log%&apos;; #获得日志文件位置,tail命令查询最新日志</span><br></pre></td></tr></table></figure><blockquote><p>前因后果：由于每次服务重启,都要执行数据库脚本(即先drop 然后 create,之后写入)；考虑到许多账户信息无需重复写入,所以更改脚本如果存在就无需drop,否则才create;同时这也引发问题,即对于oauth 模式不仅有账户信息,还有其他认证信息比如说本问题中涉及的 oauth_access_token,重新启动时应当清除其中的一些认证信息,最简单的方式就是清除重建其中的table(除身份信息)<br>解决：短暂解决，直接删除重复的行即可，之后会重新更改数据库脚本</p></blockquote><ol start="3"><li></li></ol><blockquote><p>问题描述：在vue下使用外部图片链接作为 img的src 源,出现403forbidden<br>排查：起初通过chrome-&gt;developer tools-&gt;network  发现在访问原链接之后会发生一次302 重定向,在第二次请求的时候发生403 forbidden,猜测是否是因为重定向的原因导致403发生(认为由于浏览器或者js没有处理重定向)，后来尝试更改改为重定向之后链接发现,仍然有403 错误，最终发现可能是由于外部图片提供对于盗链的处理导致的<br>原因：图片提供的服务器根据 Request Header 的 Referer 来源字段判断图片是否盗链,所以可以通过隐藏这一字段来实现获取图片</p></blockquote><blockquote><p>解决：在html head 标签下添加</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt;</span><br></pre></td></tr></table></figure><blockquote><p>此外，由于是在vue项目下进行全局配置，以后是否会引发其他问题，是需要考虑的;后来发现 通过 vue-meta 插件可以<a href="https://blog.csdn.net/zc_ad/article/details/87776163" target="_blank" rel="noopener">配置单个页面的 head</a></p></blockquote><ol start="4"><li></li></ol><blockquote><p>问题描述：在替换SSO服务打包之后的jar包之后，访问人才库，发现每隔一会,SSO分发的token就会失效<br>经过反复排查不是jar包损坏，后来经过开启mysql数据库日志：当建立数据库连接1分钟或者6秒之后，连接就会自动(?)断开,而在spring对于数据库的连接配置 autoConnect=true 以及 初始化脚本有对于数据库中部分表内容的全部删除,所以之后会重新建立连接，同时删除之前存储在数据库里面的token，导致最终每过一分钟就会使得token失效</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">2019-07-31T15:47:07.471818Z   82 Connectroot@localhost on oauth using TCP/IP</span><br><span class="line">2019-07-31T15:47:07.472235Z   82 Query/* mysql-connector-java-5.1.46 ( Revision: 9cc87a48e75c2d2e87c1a293b2862ce651cb256e ) */SELECT  @@session.auto_increment_increment AS auto_increment_increment, @@character_set_client AS character_set_client, @@character_set_connection AS character_set_connection, @@character_set_results AS character_set_results, @@character_set_server AS character_set_server, @@collation_server AS collation_server, @@init_connect AS init_connect, @@interactive_timeout AS interactive_timeout, @@license AS license, @@lower_case_table_names AS lower_case_table_names, @@max_allowed_packet AS max_allowed_packet, @@net_buffer_length AS net_buffer_length, @@net_write_timeout AS net_write_timeout, @@query_cache_size AS query_cache_size, @@query_cache_type AS query_cache_type, @@sql_mode AS sql_mode, @@system_time_zone AS system_time_zone, @@time_zone AS time_zone, @@transaction_isolation AS transaction_isolation, @@wait_timeout AS wait_timeout</span><br><span class="line">2019-07-31T15:47:07.472785Z   82 QuerySET character_set_results = NULL</span><br><span class="line">2019-07-31T15:47:07.473024Z   82 QuerySET autocommit=1</span><br><span class="line">2019-07-31T15:47:07.473220Z   82 Queryselect @@session.transaction_read_only</span><br><span class="line">2019-07-31T15:47:13.644983Z   73 Quit</span><br><span class="line">2019-07-31T15:47:13.648349Z   74 Quit</span><br><span class="line">2019-07-31T15:47:13.648871Z   75 Quit</span><br><span class="line">2019-07-31T15:47:13.649378Z   76 Quit</span><br><span class="line">2019-07-31T15:47:13.650263Z   77 Quit</span><br><span class="line">2019-07-31T15:47:13.650841Z   78 Quit</span><br><span class="line">2019-07-31T15:47:13.651369Z   79 Quit</span><br><span class="line">2019-07-31T15:47:13.651845Z   80 Quit</span><br><span class="line">2019-07-31T15:47:13.652346Z   81 Quit</span><br><span class="line">2019-07-31T15:47:13.652853Z   82 Quit</span><br></pre></td></tr></table></figure><blockquote><p>解决尝试：a) 可能是代码的原因，在对代码进行检查以及和git版本进行核对之后发现，代码并没有更改，排除之  b) maven 依赖的问题，猜测可能是由于maven依赖更新的原因，导致的不兼容，首先怀疑的是对于mysql的java 驱动 java-mysql-connector ,尝试过旧版本后发现版本不兼容，编译报错 ，最终把以前的jar解压后一一比对其中的依赖包文件版本是否相同，但是发现所有的依赖文件版本相同，当然也可能是由于maven其他我不知道的原因导致的，但是暂时排除之  c) 可能是由于mysql数据库本身配置的原因，比如说mysql配置中的 connect_timeout，net_read_timeout,net_write_timeout等参数，但是更改这些参数之后并没有起作用  d) 最终一次意外的尝试发现，当数据库停止运行一段时间后，再次运行之前有问题的jar包，发现不会出现重新连接的情况，猜测可能是数据库连接池没有释放或者类似的原因，导致再连数据库会出现问题 e)回来经过仔细审查发现，是由于crontab脚本出现的错误，导致最终每分钟会尝试执行数据库连接(脚本本身有错误以及脚本监控时候的设计有问题)，着可能导致SSO服务出现数据库连接闪断;<br>解决：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.</span><br><span class="line">service mysqld stop    #关闭mysql数据库</span><br><span class="line">service crond stop     #关闭crontab服务</span><br><span class="line">杀死SSO的进程</span><br><span class="line">echo 3 &gt; /proc/sys/vm/drop_caches  #释放相关缓存</span><br><span class="line">2.等待5分钟左右</span><br><span class="line">3.</span><br><span class="line">service crond start    #重启 crontab 服务,执行相关定时任务</span><br><span class="line">service mysqld stop    #重启 mysql  服务</span><br></pre></td></tr></table></figure><ol start="5"><li></li></ol><blockquote><p>问题描述：在使用git pull  origin master 报错</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">remote: Repository not found. </span><br><span class="line">fatal: repository &apos;https://github.com/*/*.git/&apos; not found</span><br></pre></td></tr></table></figure><blockquote><p>经过查询<a href="https://www.jianshu.com/p/5eb3a91458de" target="_blank" rel="noopener">相关博客</a>,发现是由于之前使用git clone 要求输入用户名与密码，而输入了另一个账户的密码，windows把密码记住了，下次直接使用(这涉及git credential)<br>在当前目录下查看  git config --list 可以看到配置 credential.helper=manager<br>解决方法<br>1: 在windows 用户凭据管理中更改涉及该仓库的用户名和密码(个人使用有效)<br>2: git credential-manager uninstall   git credential-manager install 再输入密码 <a href="https://www.cnblogs.com/zqyw/p/10988018.html" target="_blank" rel="noopener">来源博客</a> (未经测试)</p></blockquote><ol start="6"><li></li></ol><blockquote><p>问题描述：由postman 发出请求,经过 Kong 网关 向 ES 发出请求时,ES报 error “headers name contain non-ascii”<br>进一步排除,一共包含3个部分，postman-&gt;Kong-&gt;ES<br>1.postman发出的请求header有问题<br>2.Kong网关在处理的过程中出现问题<br>3.ES出现问题<br>经过排查日志，发现请求顺畅，到达ES处，但是ES处返回error，因而使中间某个环节出现问题<br>直接向ES发出相关简单请求发现,没有错误，首先暂不考虑3<br>检查了postman的所有header,认为没有错误,那么很可能问题出现在Kong网关部分<br>因此问题很可能出在自定义的网关插件处，经过排查日志,也没有发现那里有错误,为了进一步确定是否是因为这个插件，直接禁止这个插件，发现正常了，起码不报error “headers name contain non-ascii”,那么就确定的确是插件中的某些逻辑出现问题，导致错误，进一步排查插件的问题<br>因为是header相关的问题，因而使用笨方法，尝试挨个注释每个命令，然后刊注释哪个之后正常即该code出问题（或者注释所有相关代码，然后解注释，看哪个有问题？），最终确定产生问题的代码</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx.set_header(&apos;encrypt2&apos;)=encrypt</span><br></pre></td></tr></table></figure><blockquote><p>由代码可知，header name 应该不会出现非ASCII值，而encrypt变量是加密产生的，其包含非ascii值，所以进一步<br>1.header name 包含非ascii值：在nginx/kong处给header 赋值时，由于非ascii导致溢出（？）或者（该想法未验证）encrypt超过普通header能容纳的长度，溢出<br>2.header name 不包含asciiz值：ES在判断的时候,对header 内容 和 header name中包含非ascii值，都报同一个error</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learn Markdown</title>
      <link href="/2019/11/15/Blog/markdown/"/>
      <url>/2019/11/15/Blog/markdown/</url>
      
        <content type="html"><![CDATA[<blockquote><p>代码引用</p></blockquote><p>`print(‘hello world!’)`<br><code>print('hello world!')</code></p><p>&lt;!–￼0–&gt;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(&apos;hello world!&apos;)  </span><br><span class="line">printf(&quot;helloworld\n&quot;);  </span><br><span class="line">cout &lt;&lt; &quot;helloworld\n&quot;;  </span><br><span class="line">print(&quot;helloworld&quot;)  </span><br><span class="line">console.log(&quot;helloworld&quot;);  </span><br><span class="line">fmt.Printf(&quot;helloworld\n&quot;);  </span><br><span class="line">echo &quot;helloworld&quot;  </span><br><span class="line">&lt;h1&gt;helloworld&lt;h1&gt;  </span><br><span class="line">print(&quot;hello world&quot;)</span><br></pre></td></tr></table></figure><blockquote><p>大小</p></blockquote><p><code># 一号字</code></p><h1 id="一号字">一号字</h1><p><code>## 二号字</code></p><h2 id="二号字">二号字</h2><p><code>### 三号字</code></p><h3 id="三号字">三号字</h3><p><code>#### 四号字</code></p><h4 id="四号字">四号字</h4><blockquote><p>居中,字体,颜色</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;center&gt;&lt;font color=red size=3 face=&quot;Monospace&quot;&gt;居中&lt;/font&gt;&lt;font color=black size=5&gt;字体&lt;/font&gt;&lt;font color=blue size=6&gt;颜色&lt;/font&gt;&lt;/center&gt;</span><br></pre></td></tr></table></figure><center><font color="red" size="3" face="Monospace">居中</font><font color="black" size="5">字体</font><font color="blue" size="6">颜色</font></center><blockquote><p>空格,列表</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&amp;ensp;</span><br><span class="line">&amp;emsp;</span><br><span class="line">&amp;ensp;&amp;emsp;</span><br></pre></td></tr></table></figure><p> 一个空格<br> 两个空格<br>  三个空格</p><p>无序列表： - + *<br>有序列表：1. 2. 3.<br>可以混合使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- 一级标题  </span><br><span class="line">    + 二级标题  </span><br><span class="line">        + 二级标题  </span><br><span class="line">            * 三级标题  </span><br><span class="line">            * 三级标题  </span><br><span class="line">                1. 四级标题</span><br><span class="line">                2. 四级标题</span><br></pre></td></tr></table></figure><ul><li>小标题<ul><li>二级标题</li><li>二级标题<ul><li>三级标题</li><li>三级标题<ol><li>四级标题</li><li>四级标题</li></ol></li></ul></li></ul></li></ul><blockquote><p>链接,图片</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[链接](链接地址)</span><br></pre></td></tr></table></figure><p><a href="https://walkdeadtobe.github.io/" target="_blank" rel="noopener">我的链接</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![用来描述图片的关键词](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=702257389,1274025419&amp;fm=27&amp;gp=0.jpg &quot;我是可有可无的标题,划过图片可见)</span><br></pre></td></tr></table></figure><p><img src="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=702257389,1274025419&amp;fm=27&amp;gp=0.jpg" alt="用来描述图片的关键词" title="我是可有可无的标题,划过图片可见"></p><blockquote><p>加粗,倾斜,斜体加粗,删除</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">**这是加粗的文字**  </span><br><span class="line">*这是倾斜的文字*  </span><br><span class="line">***这是斜体加粗的文字***  </span><br><span class="line">~~这是加删除线的文字~~</span><br></pre></td></tr></table></figure><p><strong>这是加粗的文字</strong><br><em>这是倾斜的文字</em><br><em><strong>这是斜体加粗的文字</strong></em><br><s>这是加删除线的文字</s></p><blockquote><p>引用</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;这是引用的内容  </span><br><span class="line">&gt;&gt;这是引用的内容  </span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;这是引用的内容</span><br></pre></td></tr></table></figure><blockquote><p>这是引用的内容</p><blockquote><p>这是引用的内容</p><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><p>这是引用的内容</p></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><blockquote><p>分割线</p></blockquote><p>三个或者三个以上的*或者-</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">---</span><br></pre></td></tr></table></figure><hr><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">----</span><br></pre></td></tr></table></figure><hr><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">***</span><br></pre></td></tr></table></figure><hr><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*****</span><br></pre></td></tr></table></figure><hr><blockquote><p>表格</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">表头1|表头2|表头3</span><br><span class="line">---|:--:|---:</span><br><span class="line">内容|内容|内容</span><br><span class="line">内容|内容|内容</span><br></pre></td></tr></table></figure><table><thead><tr><th>表头1</th><th style="text-align:center">表头2</th><th style="text-align:right">表头3</th></tr></thead><tbody><tr><td>内容</td><td style="text-align:center">内容</td><td style="text-align:right">内容</td></tr><tr><td>内容</td><td style="text-align:center">内容</td><td style="text-align:right">内容</td></tr></tbody></table><p>第二行分割表头和内容。</p><ul><li>有一个就行，为了对齐，多加了几个<br>文字默认居左<br>-两边加：表示文字居中<br>-右边加：表示文字居右<br>注：原生的语法两边都要用 | 包起来.</li></ul><blockquote><p>注释</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--哈哈我是注释，不会在浏览器中显示。--&gt;</span><br><span class="line">[comment]: &lt;&gt; (哈哈我是注释，不会在浏览器中显示。)</span><br><span class="line">[comment]: &lt;&gt; (哈哈我是注释，不会在浏览器中显示。)</span><br><span class="line">[comment]: &lt;&gt; (哈哈我是注释，不会在浏览器中显示。)</span><br><span class="line">[//]: &lt;&gt; (哈哈我是注释，不会在浏览器中显示。)</span><br><span class="line">[//]: # (哈哈我是注释，不会在浏览器中显示。)</span><br><span class="line">[^_^]: # (哈哈我是注释，不会在浏览器中显示。)</span><br></pre></td></tr></table></figure><!--哈哈我是注释，不会在浏览器中显示。--><blockquote><p>流程图</p></blockquote><p><a href="https://support.typora.io/Draw-Diagrams-With-Markdown/" target="_blank" rel="noopener">markdown 教程</a></p><p>&lt;!–￼15–&gt;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: Start</span><br><span class="line">op=&gt;operation: Your Operation</span><br><span class="line">cond=&gt;condition: Yes or No?</span><br><span class="line">e=&gt;end</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line">cond(yes)-&gt;e</span><br><span class="line">cond(no)-&gt;op</span><br><span class="line">​</span><br></pre></td></tr></table></figure><pre><code>&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&gt;在不支持latex的md中插入公式暂时的方法是使用在线latex网站生成公式的图片，然后复制图片链接展示[在线latex编辑网站](http://latex.codecogs.com/eqneditor/samples/example1.php)&gt;页面内跳转[我在这里](#id1)&lt;span id='id1'&gt;我要跳转&lt;a href='#id1'&gt;我要跳转</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>系统迁移</title>
      <link href="/2019/11/09/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%BF%81%E7%A7%BB/"/>
      <url>/2019/11/09/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%BF%81%E7%A7%BB/</url>
      
        <content type="html"><![CDATA[<p>这套系统由4部分组成</p><p>Logstash是一个开元数据收集引擎，具备实时管道功能；Logstash可以动态的将俩字不同来源的数据统一起来，并将数据标准化至你所选择的目的地。这里我们选择的Elasricearch</p><p>Elastricearch 是一个分布式可扩展的实时搜索的分析引擎，一个建立在全文搜索引擎Apache Lucene 基础上的搜索引擎，Elastricsearch 不仅包括全文搜索功能，还可以进行</p><ul><li>分布式实时文件存储，将每一个字段都编入索引，使之可以被搜索</li><li>实时分析的分布式搜索引擎</li><li>可以扩展到上百台服务器上，处理PB级别的结果或者非结构化数据</li></ul><p>FIleBeat  是一个日志文件托运工具，在服务器安装客户端后，FIlebeat可以监控日志目录或者指定的日志文件，追踪读取这些文件（追踪文件的变化，不停的读），并且转发这些信息到elasticsearch或者logstarsh中存放。</p><p>Metricbeat可以定期收集操作系统和服务器的运行指标（CPU，内存，硬盘，IO,读写速度，进程等等），Metricbeat可以将收集到的指标和数据发送到你指定的输出，比如：elasticsearch，最终达成监视服务器的目标。</p><p>Kibana是一个开源的分析和可视化平台，设计用于和Elasticsearch一起工作。你用Kibana来搜索，查看，并和存储在Elasticsearch索引中的数据进行交互。你可以轻松地执行高级数据分析，并且以各种图标、表格和地图的形式可视化数据。Kibana使得理解大量数据变得很容易。它简单的、基于浏览器的界面使你能够快速创建和共享动态仪表板，实时显示Elasticsearch查询的变化。</p><p><font size="6">kong</font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">log_format json_log escape=json &apos;&#123; &quot;@timestamp&quot;: &quot;$time_iso8601&quot;, &apos;  &apos;&quot;remote_addr&quot;: &quot;$remote_addr&quot;, &apos;  &apos;&quot;referer&quot;: &quot;$http_referer&quot;, &apos;  &apos;&quot;request&quot;: &quot;$request&quot;, &apos;  &apos;&quot;status&quot;: $status, &apos;  &apos;&quot;bytes&quot;:$body_bytes_sent, &apos;  &apos;&quot;agent&quot;: &quot;$http_user_agent&quot;, &apos;  &apos;&quot;user&quot;: &quot;$http_username&quot;, &apos; &apos;&quot;x_forwarded&quot;: &quot;$http_x_forwarded_for&quot;, &apos;  &apos;&quot;upstr_addr&quot;: &quot;$upstream_addr&quot;,&apos;  &apos;&quot;upstr_host&quot;: &quot;$upstream_http_host&quot;,&apos;  &apos;&quot;ups_resp_time&quot;: &quot;$upstream_response_time&quot; &#125;&apos;;</span><br><span class="line">access_log logs/access.log json_log;</span><br></pre></td></tr></table></figure><p><font size="6">logstash</font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#filebeat_kong.conf</span><br><span class="line">input&#123;</span><br><span class="line">   beats &#123;</span><br><span class="line">        type =&gt; &quot;nginx-log&quot; #&quot;logs&quot;</span><br><span class="line">        port =&gt; 9044</span><br><span class="line">          &#125;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">filter&#123;</span><br><span class="line">    json&#123; #获取nginx log日志</span><br><span class="line">        source =&gt; &quot;message&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    mutate&#123;# 删去logstash转化后保留的messegae字段</span><br><span class="line">            remove_field =&gt; [&quot;message&quot;]</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">output&#123;</span><br><span class="line">    stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;10.1.1.46:9200&quot;]</span><br><span class="line">        index =&gt; &quot;system-syslog-%&#123;+YYYY.MM&#125;&quot;</span><br><span class="line">        document_type =&gt; &quot;logs&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font size="6">filebeat</font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#filebeat.yml</span><br><span class="line">filebeat.prospectors:</span><br><span class="line"></span><br><span class="line">- input_type: log</span><br><span class="line"> # encoding: UTF-8</span><br><span class="line">  paths:</span><br><span class="line">    - /home/LAB/chengr/kong_log/file.log</span><br><span class="line">  json.keys_under_root: true #在一次部署中发现这一行不能识别，最终注释之解决</span><br><span class="line">  #json.add_error_key: true</span><br><span class="line">  #json.message_key: log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">output.logstash:</span><br><span class="line">  #The Logstash hosts</span><br><span class="line">  hosts: [&quot;10.1.1.46:9044&quot;]</span><br></pre></td></tr></table></figure><p><font size="6">elastcisearch</font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#config/elasticsearch.yml</span><br><span class="line">cluster.name: my-es-cluster</span><br><span class="line">node.name: es-node-1</span><br><span class="line">path.data: /home/LAB/chengr/ELK/data/data-es</span><br><span class="line">path.logs: /home/LAB/chengr/ELK/log/log-es</span><br><span class="line">network.host: 10.1.1.46</span><br><span class="line">http.port: 9200</span><br></pre></td></tr></table></figure><p><font size="6">kibana</font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#config/kibana.yml</span><br><span class="line">server.port: 5601</span><br><span class="line">elasticsearch.url: &quot;http://10.1.1.46:9200&quot;</span><br></pre></td></tr></table></figure><p>ps:部署在实际机器上时将配置中ip改为对应的IP</p><p><font size="5">kibana 添加邮件预警 </font><br><a href="http://www.cnblogs.com/small-k/p/8551960.html" target="_blank" rel="noopener">http://www.cnblogs.com/small-k/p/8551960.html</a><br><a href="https://blog.51cto.com/10546390/2051676" target="_blank" rel="noopener">https://blog.51cto.com/10546390/2051676</a></p><p>ps:<a href="https://docs.konghq.com/0.13.x/configuration/?_ga=2.242544130.102618566.1558236281-1173907870.1558236281#proxy_access_log" target="_blank" rel="noopener">kong 相关配置地址</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Aminer</title>
      <link href="/2019/11/03/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Aminer/"/>
      <url>/2019/11/03/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Aminer/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/t6am3/AMiner_Name_Disambiguation" target="_blank" rel="noopener">Github 项目地址</a><br>这是一场关于论文 同名消歧的比赛,<a href="https://biendata.com/competition/aminer2019/data/" target="_blank" rel="noopener">项目地址</a><br>我们主要借鉴的<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4597035&amp;tag=1" target="_blank" rel="noopener">论文</a><br>论文中发现直接聚类的效果不好，其思路是首先进行居于规则的原子聚类，然后基于原子聚类的结果进一步进行聚类算法，论文中所举的例子是层次聚类(Hierarchical Clustering)以及K-means聚类,论文中发现这种方法可以大幅提升正确率<br>但是我们在实际中发现,论文中所提及的原子聚类效果并不好，也有可能是这场比赛所提供的数据集的问题，最终我们尝试使用自己首先进行规则上的归类，然后再进行基于层次聚类以及K-means聚类</p>]]></content>
      
      
      
        <tags>
            
            <tag> Competition ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>distributed algorithm</title>
      <link href="/2019/10/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
      <url>/2019/10/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Raft</p></blockquote><p><a href="https://cloud.tencent.com/developer/news/263309" target="_blank" rel="noopener">参考链接</a><br>Raft是一个一致性算法，旨在易于理解。它提供了Paxos的容错和性能。不同之处在于它被分解为相对独立的子问题，它清楚地解决了实际系统所需的所有主要部分。我们希望Raft能够为更广泛的受众提供共识，并且这个更广泛的受众将能够开发出比现在更多的高质量共识系统。</p><p>Raft是一个通过管理一个副本日志的一致性算法。它提供了跟(multi-)Paxos一样有效的功能，但是它的架构和Paxos不一样；它比Paxos更加容易理解，并且能用于生产环境中。为了加强理解，raft把一致性的问题分成了三个子问题，例如leader election, log replication, and safety,</p><p>Role</p><p>Leader，Follower，candidate</p><p>在Raft集群中，有且仅有一个Leader，在Leader运行正常的情况下，一个节点服务器要么就是Leader，要么就是Follower。Follower直到Leader故障了，才有可能变成candidate。</p><p>Leader负责把client的写请求log复制到follower。它会和follower保持心跳。每个follower都有一个timeout时间（一般为150ms~300ms），在接受到心跳的时候，这个timeout时间会被重置。如果follower没有接收到心跳，这些follower会把他们的状态变为candidate，并且开启新的一轮leader election。</p><p>term逻辑时钟</p><p>Term相当于paxos中的proposerID，相当于一个国家的朝代。term是一段任意的时间序号。每一任Leader都有一个与之前不同的term。</p><p>当Leader选举成功之后，一个节点成为了Leader，就会产生一个新的term，并且直到Leader故障，整个集群都会一直在这个term下执行操作。</p><p>如果leader选举失败了，则会再生成出一个term，再开启一轮leader选举。</p><p>Quorums：</p><p>多数派，意思是超过一半的机器存活，则这个机器可用，这个Quorums指的就是集群可用的指标。例如：集群中的节点数为2N，如果有N+1的机器存活，则代表集群可用，可接受请求，写入log，应用到state machine中去，执行操作。如果少于N+1个机器存活，则代表集群可用，可接受请求，可写入log，但不应用到state machine中去，不执行操作。</p><p>Leader Election</p><p>只有在下列两种情况下才会进行leader election：</p><p>在第一次启动raft集群的时候</p><p>在一个已存在的Leader故障的时候</p><p>选举流程：</p><p>如果以上两种任何一种发生了，所有的Follower无法再和Leader保持心跳，则它们都会等待一个（选举）timeout，如果其中一个Follower的timeout最先到时，则这个Follower变成candidate开始选举，</p><p>第一，增加term计数器，</p><p>第二，给自己投票并向所有其他的节点服务器请求投自己一票。</p><p>如果一个Follower在接受到投票请求时，接受到两个term相同的投票请求时（也就是说，产生了两个candidate），则在多个相同term的投票请求中，这个Follower只能给投给其中一个请求，只能投一票，并且按照先来先服务的原则投票。</p><p>如果这个candidate收到另外一个节点服务器的消息，并且这个节点服务器的term序号和当前的term序号一样大，甚至更大的话，则这个candidate选举失败，从而它的状态变成Follower，并且接受新的Leader。</p><p>如果一个candidate获得了Quorums选票N+1(2N为集群中节点的数目)，则它变成新的leader。</p><p>如果多个candidate和多个Follower投完票之后，有多个candidate获得了相同的票数，则会产生split vote，则新的term产生，重新选举。Raft用随机选举timeout迅速地解决split vote问题，这个方法就是对于产生spit vote的candidates各自随机生成一个选举timeout，谁先到时，谁当leader，其他candidate都变为Follower。</p><p>当一个leader被选举出来之后，就在Follower timeout到时变为candidate之前，发心跳信息给所有Followers。</p><p>Log Replication（Raft协议具体过程）</p><p>Leader负责把client的请求日志复制给其他Followers。</p><p>Raft协议具体过程就是通过复制状态机的架构实现的，如下：</p><p>步骤：</p><p>Client发送请求给Leader，其中每个请求都是一条操作指令。</p><p>Leader接受到client请求之后，把操作指令(Entry)追加到Leader的操作日志中。紧接着对Follower发起AppendEntries请求、尝试让操作指令(Entry)追加到Followers的操作日志中，即落地。如果有Follower不可用，则一直尝试。</p><p>一旦Leader接受到多数（Quorums）Follower的回应，Leader就会进行commit操作，每一台节点服务器会把操作指令交给状态机处理。这样就保证了各节点的状态的一致性。</p><p>各服务器状态机处理完成之后，Leader将结果返回给Client。</p><p>Saftety</p><p>Raft的安全性，体现在如下几个方面：</p><p>Election safety:在一个term下，最多只有一个Leader。</p><p>Leader Append-Only:一个Leader只能追加新的entries，不能重写和删除entries</p><p>Log Matching:集群中各个节点的log都是相同一致的</p><p>Leader Completeness:如果一个log entry被committed了，则这个entry一定会出现在Leader的log里。</p><p>State Machine Safety:如果一个节点服务器的state machine执行了一个某个log entry命令，则其他节点服务器，也会执行这个log entry命令，不会再执行其他命令</p><p>之前四条，在前面都有所提及，而State Machine Safety是在Leader election过程中用到过。</p><p>State Machine Safety</p><p>一个candidate在选举的时候，它会向其他节点服务器发送包含他的log的消息，获取票数，如果它的log是最新的，则会获取选票，如果它的log不是最新的，其他节点服务器还有更加新的log，则会拒绝给这个candidate投票。这就保证了State Machine Safety。</p><p>所以State Machine Safety保证的就是一个candidate必须拥有最新的log，才能获取票数，才有机会赢得Leader选举，才有机会成为Leader。</p><p>Follower crashes</p><p>如果一个follower故障了，则不会再接受AppendEntriesandvoterequests，并且Leader会不断尝试与这个节点保持心跳。</p><p>如果这个节点恢复了，则会接受Leader的最新的log，并且将log应用到state machine中去，执行log中的操作</p><p>方格指的是client发出的一条请求。</p><p>方格虚线，说明一条log entry写入了log。</p><p>方格实线，说明一条log entry应用到state machine中</p><p>Leader crashes</p><p>则会进行Leader election。</p><p>如果碰到Leader故障的情况，集群中所有节点的日志可能不一致。</p><p>old leader的一些操作日志没有通过集群完全复制。new leader将通过强制Followers复制自己的log来处理不一致的情况，步骤如下：</p><p>对于每个Follower，new leader将其日志与Followers的日志进行比较，找到他们的达成一致的最后一个log entry。</p><p>然后删除掉Followers中这个关键entry后面的所有entry，并将其替换为自己的log entry。该机制将恢复日志的一致性。</p><p>下面这种情况集群中所有节点的日志可能不一致：</p><p>总结</p><p>Raft要求具备唯一Leader，并把一致性问题具体化为保持日志副本的一致性，以此实现相较Paxos而言更容易理解、更容易实现的目标。Raft是state machine system，Zab是primary-backup system。</p><p>引用</p><ul><li><a href="https://en.wikipedia.org/wiki/Raft_(computer_science)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Raft_(computer_science)</a></li><li><a href="https://raft.github.io/" target="_blank" rel="noopener">https://raft.github.io/</a></li><li><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">http://thesecretlivesofdata.com/raft/</a></li><li><a href="https://raft.github.io/raft.pdf" target="_blank" rel="noopener">https://raft.github.io/raft.pdf</a></li><li><a href="https://www.cnblogs.com/bangerlee/p/5991417.html" target="_blank" rel="noopener">https://www.cnblogs.com/bangerlee/p/5991417.html</a></li><li><a href="https://www.bilibili.com/video/av21667358/" target="_blank" rel="noopener">https://www.bilibili.com/video/av21667358/</a></li><li><a href="https://en.wikipedia.org/wiki/State_machine_replication" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/State_machine_replication</a></li><li><a href="https://github.com/CNiceToUpp/notes/blob/master/paxos%2Craft%2Czab/paper/In%20Search%20of%20an%20Understandable%20Consensus%20Algorithm.pdf" target="_blank" rel="noopener">https://github.com/CNiceToUpp/notes/blob/master/paxos%2Craft%2Czab/paper/In Search of an Understandable Consensus Algorithm.pdf</a></li></ul><blockquote><p>PAXOS</p></blockquote><p>它的假设前提是，在分布式系统中进程之间的通信会出现丢失、延迟、重复等现象，但不会出现传错的现象。Paxos算法就是为了保证在这样的系统中进程间基于消息传递就某个值达成一致。</p><p>在Paxos算法中，有两种角色：</p><p>Proposer<br>Acceptor<br>Paxos算法分为两个阶段。具体如下：</p><p>阶段一：<br>(a) Proposer选择一个提案编号N（全剧唯一version），然后向半数以上的Acceptor发送编号为N的Prepare请求。</p><p>(b) 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。如果已经接受过，比较版本号大小，持久化最新的，并返回信息</p><p>阶段二：<br>(a) 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定。</p><p>(b) 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/09/19/Blog/hexo/"/>
      <url>/2019/09/19/Blog/hexo/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="指令入门">指令入门</h2><h3 id="创建-post">创建 post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="启动本地服务">启动本地服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="生成静态文件">生成静态文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="部署到远程服务器">部署到远程服务器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><h2 id="配置详情">配置详情</h2><p>主题:next<br>根目录下的配置文件是全局配置文件,theme指定的目录下配置文件时作为全局的补充</p><h2 id="plugin">plugin</h2><ul><li>hexo-generator-search</li><li>hexo-renderer-markdown-it</li></ul><h2 id="path">path</h2><p>hexo 配置文件 : “D:\Document\Github_Blog\hexo\_config.yml”</p><h2 id="问题">问题</h2><p><a href="https://convivae.top/posts/hexo-bo-ke-cai-keng/" target="_blank" rel="noopener">hexo toc 锚点失效</a><br><a href="https://hexo.io/docs/configuration#Directory" target="_blank" rel="noopener">使用 skip_render 排除某些psot的渲染</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/09/19/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/centos/"/>
      <url>/2019/09/19/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/centos/</url>
      
        <content type="html"><![CDATA[<p>centos  安装  psycopg2</p><p>直接 pip install psycopg2报错，根据错误 还需要安装 pip install psycopg2-binary/setuptools,以及  yum install gcc<br>可能还需要安装</p><ul><li>sudo yum install postgresql-libs</li><li>sudo yum install postgresql-devel</li><li>sudo yum install python-devel</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/09/19/README/"/>
      <url>/2019/09/19/README/</url>
      
        <content type="html"><![CDATA[<h1 id="myblog">myblog</h1><h3 id="plugin">plugin</h3><ul><li>hexo-generator-search</li><li>hexo-renderer-markdown-it</li></ul><h3 id="path">path</h3><p>hexo 配置文件 : “D:\Document\Github_Blog\hexo\config.yml”</p><p>my_github_blog in markdown</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Raft算法</title>
      <link href="/2019/09/17/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Raft/"/>
      <url>/2019/09/17/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Raft/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> algorithm 一致性 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>windows terminal</title>
      <link href="/2019/09/04/%E5%B7%A5%E5%85%B7/Windows_terminal/"/>
      <url>/2019/09/04/%E5%B7%A5%E5%85%B7/Windows_terminal/</url>
      
        <content type="html"><![CDATA[<p>开始尝试使用windows terminal ,遇到有些问题记录下来<br>1.在termianl 进入Ubuntu 继续使用 windows安装的程序</p><ul><li>首先在 ~/.bashrc 中添加可执行程序的路径所在</li><li>使用 chmod +x 标识 可执行程序 可执行</li></ul><p>2.配置 <a href="https://www.addictivetips.com/windows-tips/powershell-command-history-windows-10/" target="_blank" rel="noopener">命令补全</a></p><ul><li>借助 PSReadline</li><li>在 powershell profile 文件中 配置自动化脚本</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> windows terminal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Paxos</title>
      <link href="/2019/08/12/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Paxos/"/>
      <url>/2019/08/12/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Paxos/</url>
      
        <content type="html"><![CDATA[<p>博客列表：</p><ul><li><a href="https://www.cnblogs.com/hugb/p/8955505.html" target="_blank" rel="noopener">图解分布式一致性协议Paxos</a></li></ul><p>相关概念</p><ul><li>拜占庭模型:<ul><li><a href="https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98" target="_blank" rel="noopener">wiki 拜占庭问题</a></li><li>分布式对等网路容错问题：在分布式对等网络中需要按照共同一致策略协作的成员计算机即为问题中的将军，而各成员计算机赖以进行通讯的网络链路即为信使。拜占庭将军问题描述的就是某些成员计算机或网络链路出现错误、甚至被蓄意破坏者控制的情况。</li></ul></li><li>非拜占庭模型：<ul><li>指可能出现故障，但是不会伪造信息的情况(即，要么收不到信息，要么收到真实的信息)</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Distributed System 一致性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git 学习</title>
      <link href="/2019/07/22/%E5%B7%A5%E5%85%B7/Git/"/>
      <url>/2019/07/22/%E5%B7%A5%E5%85%B7/Git/</url>
      
        <content type="html"><![CDATA[<h3 id="简介">简介</h3><p>GIT 可以分为本地的内容寻址系统(content-addressable filesystem) 和 远程的分布式的版本控制系统(version control system)</p><blockquote><p>在本地其核心可以看做一个简单的键值对数据存储系统,value 是实际存储的文件(.git/objects 目录下),key是文件的SHA-1值,因而我们用key 找回(retrieve) 历史内容<br>远程内容待补充</p></blockquote><h3 id="目录解析">目录解析</h3><p>.git<br>├── COMMIT_EDITMSG<br>├── FETCH_HEAD<br>├── HEAD<br>├── config<br>├── description<br>├── index<br>├── hooks//以下是文件夹<br>├── info<br>├── logs<br>├── objects<br>└── refs</p><p>1.git/COMMIT_EDITMSG</p><blockquote><p>记录commit附带的说明，经测试只记录最新的commit 说明</p></blockquote><p>2.git/FETCH_HEAD</p><blockquote><p>记录从远程仓库fetch的各分支的Head</p></blockquote><p>3.git/HEAD</p><blockquote><p>表示当前分支的Head</p></blockquote><p>4.git/config</p><blockquote><p>当前 git仓库的配置文件。保存这 git仓库的远程地址,远程仓库分支等</p></blockquote><p>5.git/index</p><blockquote><p>暂存区:存储时间戳,文件名,文件的SHA值等元数据<br>每当我们执行 git add操作的时候， git会给添加的每个文件的内容创建一个对象，然后把这个文件的路径和生成的对象进行映射，存放到 .git/index文件中。等到后期新的命令（比如：git add、 git rm或者 git mv）执行的时候，又会重新更新索引。</p></blockquote><p>6.git/hook</p><blockquote><p>伴随着git的命令所触发的处理脚本,通常在 git init 时拷贝到新目录<br>具体脚本可分为客户端和服务端两种,待补充</p></blockquote><p>7.git/info</p><blockquote><p>关于仓库的的其他信息<br>例如.git/info/exclude 可以排除本地本人不想提交的文件,只与自己相关,该文件也不会上传,可用于排除私人的某些配置等,注意与全局的 .gitignore 文件区别</p></blockquote><p>8.git/logs</p><blockquote><p>记录仓库各分支上提交的commit操作/修改,可以通过 git log 查看</p></blockquote><p>9.git/objects</p><blockquote><p>真正保存代码的地方。其中分成两种类型的文件，一种是 pack，另外的是 blob文件。其中 pack是根据定位内容非常相似的全部文件，然后为他们之一存储整个内容。之后计算相似文件之间的差异并且只存储差异。而 blob文件就是记录差异。blob是“二进制大对象”（ binary largeobject）的简写，是计算机领域常用术语，用来指代某些可以包含任意数据的变量或文件<br>.git/objects:三种类型</p><blockquote><p>blob :实际存储的文件,<a href="https://www.git-scm.com/book/en/v2/Git-Internals-Git-Objects" target="_blank" rel="noopener">具体详情</a><br>tree : 当前project的一个快照,存储多个实体/数据结构(由blob object的git mode,类型,SHA-1值,文件名构成),记录了当前tree下所有文件所指向的blob object<br>commit: 记录所产生的tree object,作者,时间,commit msg,上一个commit object<br>tag: 根据我查看的文件结构与commit相同,但引用博客中说没有记录tree object,而记录创建tag 所在的commit object,是因为更新了？</p></blockquote></blockquote><blockquote><p>.git/objects/info 关于object的其他信息<br>.git/objects/pack 在git gc  或者 git push 时,git 会将松散的object文件打包压缩,降低存储空间 <a href="https://www.git-scm.com/book/en/v2/Git-Internals-Packfiles" target="_blank" rel="noopener">详情</a></p></blockquote><p>10.git/refs</p><blockquote><p>引用文件<br>.git/refs/heads 记录本地各分支最新状态(文件中存储git object 的SHA-1值),即指向最后一次commit提交只有产生的git object<br>.git/refs/tags<br>.git/refs/remotes 记录远程各分支最新状态(文件中存储git object 的SHA-1值),同样指向本地的git object(每次fetch或者pull会拉去远程的更新)</p></blockquote><h3 id="常见命令及其解析">常见命令及其解析：</h3><ul><li>git &lt;命令&gt; --help</li></ul><blockquote><p>git 查看该命令以及相关参数说明</p></blockquote><ul><li>git add/commit/push/fetch/merge/pull/config</li></ul><blockquote><p>git add <filename><br><code>git fetch origin [branchName]</code><br>拉取远程分支的最新commit记录到本地，并把FETCH_HEAD 设置为 最新的commit，等待merge<br><code>git merge </code> <a href="https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging" target="_blank" rel="noopener">解析</a></filename></p></blockquote><ul><li><p>本地分支 和 合并分支 是前后继 的关系：Git 指针移动即可</p></li><li><p>本地分支 和 合并分支 不是前后继的关系：例如master与branch1,此处有两个快照(snapshots) 分别为master和branch1的最新节点以及两者的共同最近祖先,祖先依照时间(一次观察是如此,未找到其他依据)接受 master 和 branch1 相对与祖先的修改,如果master与branch1的修改没有冲突,就形成了一个新快照,Git 会自动创建一次commit 指向它,同时其的祖先节点有两个分别为 master和branch1的最新节点;如果 有冲突,GIT暂时不提供智能化合并,需要手工操作</p></li><li></li><li><p>git checkout</p></li></ul><blockquote><p><code>git checkout &lt;branch-name&gt;</code> 更改分支<br><code>git check -- &lt;path&gt;</code> 将路径下所有文件重置回index状态/最近的commit状态</p></blockquote><ul><li>git clean</li></ul><blockquote><p>从工作目录中删除所有没有track过的文件,常与git reset --hard 一起用</p></blockquote><ul><li>git reset</li></ul><blockquote><p>reset 只影响 被track的文件<br><code>git reset --hard/mixed/soft</code>???</p></blockquote><ul><li>git log</li></ul><blockquote><p>查看 git commit 的历史记录及其 HASH ID</p></blockquote><ul><li>git cat-files</li></ul><blockquote></blockquote><ul><li>回退分支 git checkout VS git reset</li></ul><blockquote></blockquote><h3 id="常见git场景">常见git场景</h3><h4 id="撤销修改">撤销修改</h4><blockquote><p>已修改,未 <code>git add</code> : <code>git checkout  -- &lt;filepathname&gt;</code> 撤销 某文件未 git add提交的缓存,例如 <code>git checkout --</code> .撤销当前目录所有文件的未add 缓存</p></blockquote><blockquote><p>已 <code>git add</code>,未 <code>git commit</code>: <code>git reset HEAD filepathname</code> 可以撤销 <code>git add</code>命令，回退到 已修改,未 <code>git add</code> 状态</p></blockquote><blockquote><p>已 <code>git commit</code>,未 <code>git push</code>: <code>git reset --soft HEAD^</code> 可回退到上次commit的的状态,保持git add 的状态,也可以使用 <code>git reset --soft  &lt;commitid&gt;</code> 回退到任意版本,但是如果使用<code>git reset --hard &lt;commitid&gt;</code> 会丢失之前的修改信息,文件内容直接回退到commitid版本所对应的状态</p></blockquote><h4 id="分支相关">分支相关</h4><blockquote><p>增加分支<br>删除分支<br>更新远程分支git remote update origin -p<br>更新远程分支状态<br><code>git fetch --all</code> 追踪所有远程分支<br><code>git fetch -p/--prune</code> 对远程分支中已删除的,本地同样删除</p></blockquote><p>跟随态 VS 游离态</p><ul><li>跟随态：test</li><li>游离态:test</li></ul><p>参考：<br>1.<a href="https://www.siteground.com/tutorials/git/directory-structure/" target="_blank" rel="noopener">Git Directory</a><br>2.<a href="https://www.git-scm.com/book/en/v2/Git-Internals-Git-References" target="_blank" rel="noopener">Git Ref</a><br>3.<a href="https://www.git-scm.com/docs/githooks" target="_blank" rel="noopener">Git hooks</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> git  file </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lua</title>
      <link href="/2019/07/10/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/lua/"/>
      <url>/2019/07/10/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/lua/</url>
      
        <content type="html"><![CDATA[<p><br>因为决定学习开发网关kong的插件，所以需要学习lua语言，正在从<a href="https://www.runoob.com/lua/" target="_blank" rel="noopener">Lua 菜鸟教程</a>学习<br><br>关于kong插件开发的博客 <a href="https://www.jianshu.com/p/68457b42b84f" target="_blank" rel="noopener">链接1</a><br><br>发现一个很有意思的lua 模块  :openresty 的lua-resty-template 模块，提供模板渲染的功能<br><br>准备在网关处进行对于token的检验工作，由于没有使用已有的oauth server 插件，所以需要自己写个额外插件<br>在这个插件中主要需要完成的工作是从cookie 中 提取出 token ,并以此为凭借到oauth  server 进行相关检验，如果检验成功，应当返回id 以及这个token的ttl ,网关处获得id 应当 将之体现在日志里(插件逻辑处新建header,在nginx日志处自定义日志格式,指明该id或者在网关处建立与oauth server相同的用户体系，起码账户名一致，这样根据id 可以从数据库中提取出相应的consumer credential ,这样的话可以用于后续的基于用户的限流等操作)<br>主要点在于1.Lua中进行http 操作  ,<a href="https://github.com/ledgetech/lua-resty-http#request" target="_blank" rel="noopener">Github 源码文档</a><br>2.考虑对token进行缓存,[‘token’,‘id’,ttl],这样无需多次存取(可能带来的问题有，注销登录后如何通知网关注销token：这又分为两种注销后不再登录和重新登陆，对于后者可以下次请求经过网关时,注销相同id的键值对)<br><a href="https://github.com/openresty/lua-resty-redis/" target="_blank" rel="noopener">Github lua-resty-redis</a><br><a href="https://github.com/Kong/kong/blob/master/kong/plugins/rate-limiting/policies/init.lua" target="_blank" rel="noopener">Kong rate-limiting 插件</a>中涉及对于redis的操作,可以观摩下</p><p><br>目前在网关处验证用户身份成功后，在后端为避免再次检验身份的需要，因此需要网关提供给后端身份凭据，认可这次身份凭据，同时应当提供某种验证手段，让后端验证请求是否身份凭据是否是真的/是否是伪造<br>方案1 ：利用某种对称加密算法,网关对用户身份进行加密,后端以相同的密钥进行解密,得到身份<br>确定使用AES算法<a href="https://github.com/openresty/lua-resty-string/" target="_blank" rel="noopener">Github 示例</a>,在网关处使用CBC加密，相同的偏移向量,结果转化为hex格式，传输到python后端，对结果转发，解密，但是解密始终得不到正确的结果，怀疑是<a href="https://blog.csdn.net/diodosu/article/details/51923670" target="_blank" rel="noopener">博客</a>中提到的问题，但是我在测试中设置的加密字段,加密密钥，偏移向量都是16位的，看起来应该不会有填充的问题才对，但是解密仍然失败<br>方案2 ：采取非对称加密算法，在网关处向后端传递两个header：userid,encrypted 在网关处按照某种方法加密得到 encrypt header,后端使用同样的方法加密，如果结果相同，则认为 userid 经过了网关的认证，同时加密内容应当是网关与后端之间相互约定的动态的内容</p><p><br>2020-1-10 代码更新，把硬编码信息改为插件的配置输入<br>curl -i -X POST <a href="http://localhost:8001/plugins" target="_blank" rel="noopener">http://localhost:8001/plugins</a> <br>–data “name=kong-plugin-myplugin” <br>–data “config.sso_domain=SS0_DOMAIN” <br>–data “config.check_path=CHECK_PATH” <br>–data “config.front_domain=FRONT_DOMAIN” <br>–data “config.client=CLIENT_JSON”</p><p>其中需要注意的是，kong网关对于插件配置的输入中对于字符 ‘&amp;’ 的支持不好，而使用’\&amp;‘的话，网关处接收后会转化为’\\&amp;’,看起来很不舒服，然后我 使用 ‘\a’ 字符代表 ‘&amp;’,在插件处理逻辑处再替换回来(需要注意的是如果单个的’'存在，会影响 string 转化为 json)</p>]]></content>
      
      
      
        <tags>
            
            <tag> lua </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动态规划学习</title>
      <link href="/2019/07/10/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/dp/"/>
      <url>/2019/07/10/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/dp/</url>
      
        <content type="html"><![CDATA[<p>参考资料：</p><ul><li><a href="https://wenku.baidu.com/view/cd5dc88ef80f76c66137ee06eff9aef8951e4854.html" target="_blank" rel="noopener">百度文库资料</a></li><li><a href="https://www.cnblogs.com/Renyi-Fan/p/9285495.html" target="_blank" rel="noopener">博客</a></li></ul><p>动态规划(dynamic programming)<br>条件：</p><ol><li>最优子问题结构</li><li>子问题重叠性质</li><li>无后效性</li></ol><p>动态规划分类</p><ul><li>线性型<ul><li>简介：在线性空间上的递推dp</li><li>思路：</li><li>例子：最长上升子序列(LIS)、最长公共子序列(LCS)、最大子序列和</li></ul></li><li>区间型<ul><li>简介：区间dp就是在区间上进行动态规划，求解一段区间上的最优解。可以是二维的也可以是三维的，一般情况下为二维；</li><li>思路：主要是通过合并小区间的 最优解进而得出整个大区间上最优解的dp算法</li><li>例子：</li></ul></li><li>背包型<ul><li>简介：</li><li>思路：</li><li>例子：0-1背包、完全背包、分组背包、多重背包</li></ul></li><li>树型<ul><li>简介：建立在树这种数据结构上的dp</li><li>思路：一般可以通过dfs维护从根到叶子或从叶子到根的状态转移</li></ul></li><li>其他<ul><li>矩阵型</li><li>序列型</li><li>双序列型</li><li>划分型</li><li>状态压缩型</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> dp  algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>regex</title>
      <link href="/2019/07/09/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/regex/"/>
      <url>/2019/07/09/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/regex/</url>
      
        <content type="html"><![CDATA[<p>最近需要从nginx header中提取出变量，需要学习正则表达式相关知识<br><a href="https://www.runoob.com/regexp/regexp-tutorial.html" target="_blank" rel="noopener">菜鸟教程 正则表达式</a></p><blockquote><p>可以使用 $1 $2 $3等来表示匹配的变量<br>例如 对于字符串  A90B3C  ,正则表达式  /A(\d+)B(\d+)C/  匹配的 $1=90 $2=3<br>亦或者 对于正则表达式 /A((\d+)B)(\d+)C/  匹配的 $1=90B  $2=90  $3=3</p></blockquote><br>>对实际应用可以匹配  $http_cookie ~ token=([a-z0-9]*);api_key=([a-z0-9]*)在实际搜素中发现有人使用 {variable}以及<variable> 来匹配变量 variable ，但是在查询文档中没有发现这种用法，也欸有试过是否能用</variable>]]></content>
      
      
      
        <tags>
            
            <tag> 正则表达式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nginx</title>
      <link href="/2019/06/29/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/nginx/"/>
      <url>/2019/06/29/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/nginx/</url>
      
        <content type="html"><![CDATA[<blockquote><p>rewrite规则必须匹配对应的域名才能生效，比如是server_name <a href="http://xn--aa-tz2c.com" target="_blank" rel="noopener">为aa.com</a> 下的rewrite 规则，则必须访问时前缀是 <a href="http://aa.com" target="_blank" rel="noopener">aa.com</a> ，rewrite规则才能生效</p></blockquote><p>在 nginx 反向代理处直接拒绝不携带token的请求</p><blockquote><p>在 server 内 ，loaction 前对于所有请求 判断cookie内是否携带token(先不管token是否有效)，其中排除对包含code/oauth/static的请求，如果不携带，则使之跳转到授权服务器，登录后自动跳转到首页</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">// if ( $request_uri ~* (.*)210.14.118.96(.*))</span><br><span class="line"> // &#123;  rewrite ^/(.*)$  http://localhost:80/$1 break; &#125;</span><br><span class="line">  set $flag 1;</span><br><span class="line"></span><br><span class="line">  if ( $http_cookie ~* (.*)token=(.*) )</span><br><span class="line">  &#123; set $flag 0; &#125;</span><br><span class="line"></span><br><span class="line">  if ( $request_uri ~* (.*)code=(.*))</span><br><span class="line">  &#123; set $flag 0; &#125;</span><br><span class="line"></span><br><span class="line">  if ( $request_uri ~* (.*)oauth(.*))</span><br><span class="line">  &#123; set $flag 0; &#125;</span><br><span class="line"></span><br><span class="line">  if ( $request_uri ~* (.*)static(.*))</span><br><span class="line">  &#123; set $flag 0; &#125;</span><br><span class="line"></span><br><span class="line">  if ( $request_uri ~* (.*)/js/(.*))</span><br><span class="line">  &#123; set $flag 0; &#125;</span><br><span class="line"></span><br><span class="line">  if ( $request_uri ~* (.*)/css/(.*))</span><br><span class="line">  &#123; set $flag 0; &#125;</span><br><span class="line"></span><br><span class="line">  if ( $http_referer = &quot;http://210.14.118.96/&quot; )</span><br><span class="line">  &#123; set $flag 0; &#125;</span><br><span class="line"></span><br><span class="line">  if ( $http_referer = &quot;&quot; )</span><br><span class="line">  &#123; set $flag 0; &#125;</span><br><span class="line"></span><br><span class="line">  if ( $flag = 1)&#123;</span><br><span class="line">  //rewrite ^(.*)$ http://111.203.146.69/oauth/authorize?client_id=kexie&amp;redirect_uri=http://210.14.118.96/ep/cookie.html&amp;response_type=code&amp;scope=read permanent;# redirect;</span><br><span class="line">  return 301  http://111.203.146.69/oauth/authorize?client_id=kexie&amp;redirect_uri=http://210.14.118.96/ep/cookie.html&amp;response_type=code&amp;scope=read;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是 从网上博客看，/etc/nginx/nginx.conf 的优先级比 /etc/nginx/conf.d/* 以及/etc/nginx/sites-enables/*优先级高，  但是如果后面的配置中标明了default_server，那么优先级应该是更高的(实际效果，没有去网上查找核实);导致后者的server_name:_  覆盖了前者的server_name:210.14.118.96</p></blockquote><p>在vue项目中 ，全局配置使得请求携带cookie<br>修改 ./src/main.js 添加 <a href="https://github.com/pagekit/vue-resource/issues/191" target="_blank" rel="noopener">相关问题连接</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import Vue from &quot;vue&quot;;</span><br><span class="line">import VueAwesomeSwiper from &apos;vue-awesome-swiper&apos;</span><br><span class="line">import &apos;swiper/dist/css/swiper.css&apos;</span><br><span class="line">import App from &quot;./App.vue&quot;;</span><br><span class="line">import router from &quot;@/router/index&quot;;</span><br><span class="line">import store from &quot;@/store/index&quot;;</span><br><span class="line">import ElementUI from &quot;element-ui&quot;</span><br><span class="line">import &apos;element-ui/lib/theme-chalk/index.css&apos;</span><br><span class="line">import echarts from &quot;echarts&quot;;</span><br><span class="line">import &#123; debounce &#125; from &quot;@/assets/scripts/util&quot;;</span><br><span class="line">import starSky from &quot;@/assets/scripts/common/canvas.js&quot;;</span><br><span class="line">import echartTheme from &quot;@/constant/chalk.project.json&quot;</span><br><span class="line">//添加内容-开始</span><br><span class="line">import VueResource from &apos;vue-resource&apos;</span><br><span class="line">Vue.use(VueResource)</span><br><span class="line">Vue.http.options.xhr = &#123; withCredentials: true &#125;;</span><br><span class="line">//添加内容-结束</span><br><span class="line">echarts.registerTheme(&quot;chalk&quot;, echartTheme);</span><br><span class="line">Vue.config.productionTip = false;</span><br><span class="line">Vue.use(VueAwesomeSwiper)</span><br><span class="line">Vue.use(ElementUI)</span><br><span class="line">Vue.prototype.$charts = echarts;</span><br><span class="line">Vue.prototype.$debounce = debounce;</span><br><span class="line">Vue.prototype.$starSky = starSky;</span><br><span class="line">new Vue(&#123;</span><br><span class="line">  router,</span><br><span class="line">  store,</span><br><span class="line">  render: h =&gt; h(App)</span><br><span class="line">&#125;).$mount(&quot;#app&quot;);</span><br></pre></td></tr></table></figure><p>此外报错，需要安装插件</p><blockquote><p>npm install --save vue-resource</p></blockquote><blockquote><p>清除cookie 使用</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">document.cookie = &quot;token=;expires=Thu, 01 Jan 1970 00:00:00 GMT; path=/&quot;; </span><br><span class="line">document.cookie = &quot;token=;expires=Thu, 01 Jan 1970 00:00:00 GMT; path=/ep&quot;;</span><br></pre></td></tr></table></figure><p>而 setCookie()不能删除不同域下cookie</p><blockquote><p>当使用 upstream 代指 上游 多个可用服务器，nginx会根据 error  timeout 来自动替换选择 可用服务器，但是不支持对于有状态码的返回，此外我们可以配置自动检查后端情况以及相应处理 ,<a href="https://www.nginx.com/resources/wiki/modules/healthcheck/" target="_blank" rel="noopener">Nginx ngx_http_healthcheck_module</a>  <a href="https://github.com/cep21/healthcheck_nginx_upstreams/blob/master/README" target="_blank" rel="noopener">Github healthcheck_nginx_upstreams</a><br>而在目前项目中，由于前端nginx调用后面网关 ，所以需要已具有某些状态码来决定是否轮替， 例如</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">upstream backends &#123;</span><br><span class="line">server 192.2.0.1;</span><br><span class="line">server 192.2.0.2;</span><br><span class="line">…</span><br><span class="line">&#125;</span><br><span class="line">server&#123;</span><br><span class="line">  location / &#123;</span><br><span class="line">  proxy_pass http://backends;</span><br><span class="line">  proxy_next_upstream error timeout http_404 http_502 http_500;#依据状态码确定轮替，此外在 多个nginx转发情况下使用 timeout，会导致其它一些问题，简单的方式是除去timeout </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>出于实际需要，需要在kong网关处进行添加自定义插件，其中逻辑需要添加自定义header，使用 ngx.request.set_header(name,value)<br>但是发现自己在网关处添加的header无法传递到(Django)后端,遍历httprequest.MEAT也没有发现，最终经过查询发现 nginx 默认(可以通过配置 underscores_in_headers  on)不允许 header name 中携带 下划线,可以除去下划线或者用’-‘代替’<em>’,但是好奇的是在网关处 带下划线的header 仍然可以使用<br>可以使用 ngx.req.get_header(name) 查询，以及在日志中也可以配置 http_name得到值，或许只是不能够传出去??</em></p>]]></content>
      
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>postgresql</title>
      <link href="/2019/06/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/psql/"/>
      <url>/2019/06/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/psql/</url>
      
        <content type="html"><![CDATA[<p>按照官网教程安装postgresql数据库<br><a href="https://www.postgresql.org/download/linux/redhat/" target="_blank" rel="noopener">https://www.postgresql.org/download/linux/redhat/</a><br>输入</p><blockquote><p>su - postgres<br>进入 postgresql 用户<br>输入<br>psql<br>进入数据库<br>输入<br>\c kong<br>切换数据库<br>输入<br>select * from pg_tables where schemaname = ‘public’;<br>查询该数据库的所有表</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>go</title>
      <link href="/2019/06/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Go/"/>
      <url>/2019/06/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Go/</url>
      
        <content type="html"><![CDATA[<h2 id="go语言学习">Go语言学习</h2><h3 id="注意点">注意点</h3><h4 id="变量类型">变量类型</h4><ol><li>切片和指针都是引用类型</li><li>实际存储的字符的ascii值,没有char,取而代之的是byte(uint8),rune(int32)</li><li>raw string？？</li><li>fmt.Println 与 println的区别</li><li>list.List 与 list.New() 的[区别]](<a href="https://golang.org/pkg/container/list/" target="_blank" rel="noopener">https://golang.org/pkg/container/list/</a>)<a href="https://blog.csdn.net/xxx9001/article/details/52574501" target="_blank" rel="noopener">CSDN</a><br>list.List 返回的是一个结构体值类型,list.New()返回的是一个初始化的结构体的指针类型,区别在于1.作为函数参数传入时,list.List不可更改,而指针类型可更改2.传入参数需要与函数定义相同,即函数定义的是值类型,那么只能传入值类型</li></ol><h4 id="方法-与-函数-的-区别">方法 与 函数 的 区别</h4><p>方法区别于函数的点在于,方法有一个接受者(值接受者 或者 指针接受者).<br>值接受者会拷贝副本.</p><h4 id="函数名或者变量首字母大写">函数名或者变量首字母大写</h4><p>变量或函数的首字母大写时,才可以从包中导出/包外部可见</p><h4 id="接口转型">接口转型</h4><p>两种方式</p><ul><li>instance, ok := 接口对象.(实际类型).可以配合if…else if使用</li><li>接口对象.(type).实际类型被赋值到type,配合switch…case使用.</li></ul><h4 id="fmtstringer">fmt.Stringer</h4><p>Stringer 接口包含 String() 方法，定义如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type Stringer interface &#123;</span><br><span class="line">    String() string</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>任何类型只要实现了 String() 方法,在进行Print 输出时，可以使用 其实现 String() 中的定义。</p><h4 id="sync"><a href="https://docs.studygolang.com/pkg/sync/" target="_blank" rel="noopener">sync</a></h4><p>sync 包提供基础的同步功能，例如互斥锁。除了Once、WaitGroup类型，大多数应用于底层链接库。一般借助 channel 和 通信 实现 高层次同步。<br>不建议复制 sync 中类型的值。<br>常用的类型包括：</p><ul><li>Locker</li><li>Map</li><li>Mutex</li><li>Once</li><li>WaitGroup</li><li>Cond</li><li>Pool</li><li>RWMutex</li></ul><p>Once 是一个只会执行一个动作的对象。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">type Once struct &#123;</span><br><span class="line">    // contains filtered or unexported fields</span><br><span class="line">&#125; </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">Example</span><br></pre></td></tr></table></figure><p>func main() {<br>var once sync.Once<br>onceBody := func() {<br>fmt.Println(“Only once”)<br>}<br>done := make(chan bool)<br>for i := 0; i &lt; 10; i++ {<br>go func() {<br><a href="http://once.Do" target="_blank" rel="noopener">once.Do</a>(onceBody)<br>done &lt;- true<br>}()<br>}</p><pre><code>for i := 0; i &lt; 10; i++ {&lt;-done}</code></pre><p>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">一个 WaitGroup 是一个待完成的 go 协程集合。主协程通过 Add 方法 设置等待的协程的数量。每个协程结束之后调用 Done 方法。同时，Wait 方法可以用于阻塞当前协程直至所有协程都完成。</span><br></pre></td></tr></table></figure><p>type httpPkg struct{}</p><p>func (httpPkg) Get(url string) {}</p><p>var http httpPkg</p><p>func main() {<br>var wg sync.WaitGroup<br>var urls = []string{<br>“<a href="http://www.google.org/" target="_blank" rel="noopener">http://www.google.org/</a>”,<br>“<a href="http://www.google.com/" target="_blank" rel="noopener">http://www.google.com/</a>”,<br>“<a href="http://www.somestupidname.com/" target="_blank" rel="noopener">http://www.somestupidname.com/</a>”,<br>}<br>for _, url := range urls {<br>// Increment the WaitGroup counter.<br>wg.Add(1)<br>// Launch a goroutine to fetch the URL.<br>go func(url string) {<br>// Decrement the counter when the goroutine completes.<br>defer wg.Done()<br>// Fetch the URL.<br>fmt.Println(url)<br>http.Get(url)<br>}(url)<br>}<br>// Wait for all HTTP fetches to complete.<br>wg.Wait()<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">#### [reflect](https://docs.studygolang.com/pkg/reflect/)</span><br><span class="line">refelct 包继承运行时反射接口，允许程序操作任何类型的对象。</span><br><span class="line">常用的方法是 利用一个有静态类型 interface&#123;&#125; 的值 并 通过调用TypeOf方法(返回Type)抽取出它的动态信息。</span><br><span class="line"></span><br><span class="line">ValueOf 方法返回 实时数据的值。Zero 方法返回一个当前类型的 零值的 Type类型。</span><br><span class="line"></span><br><span class="line">#### [runtime](https://docs.studygolang.com/pkg/runtime/)</span><br><span class="line">runtime包 包含与Go运行时系统交互的相关操作，例如函数控制协程。也包含reflect包使用的底层信息。</span><br><span class="line"></span><br><span class="line">## 分布式系统学习第一弹</span><br><span class="line">[MIT 6.824](https://pdos.csail.mit.edu/6.824/labs/lab-1.html)</span><br><span class="line">按照课程要求,下载源码</span><br><span class="line">修改一：添加日志,在 go  init 函数更改日志格式,使得输出时带位置</span><br></pre></td></tr></table></figure><p>//init log format<br>func init(){<br>log.SetFlags(log.Ldate| log.Lshortfile |log.Ltime |log.LUTC)<br>}<br>//样例输出<br>2019/07/22 07:34:41 master_splitmerge.go:23: Merge: open mrtmp.test-res-0: no such file or directory</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## cache2go 学习</span><br><span class="line">[项目结构 简介](https://blog.csdn.net/notbaron/article/details/52008155)</span><br><span class="line">[Go缓存库cache2go介绍](https://blog.csdn.net/zhizhengguan/article/details/84257338)</span><br><span class="line"></span><br><span class="line">## go 语言</span><br><span class="line">实现长度为变量的二维数组</span><br></pre></td></tr></table></figure><p>var status [][]int<br>for i := 0; i &lt; len(variable1); i++ {<br>var statu = make([]int, len(variable2))<br>status = append(status, statu)<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">range</span><br></pre></td></tr></table></figure><p>for <em>, num := range nums {<br>sum += num<br>}<br>fmt.Println(“sum:”, sum)<br><a href="//xn--rangeindex-ui2p8juc93qtubz0fd4gy8mvkdkvs21ywk1cotxe1g4b0r3f.xn--fhqg0gu0bbvdcx4ogsht7stuhdmkwx3dkyd162abo6b38hn3u7f0a8tb">//在数组上使用range将传入index和值两个变量.上面那个例子我们不需要使用该元素的序号</a>,所以我们使用空白符&quot;</em>&quot;省略了.有时侯我们确实需要知道它的索引.<br>for i, num := range nums {<br>if num == 3 {<br>fmt.Println(“index:”, i)<br>}<br>}</p><pre><code>make vs new</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> MIT6.824 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>系统配置</title>
      <link href="/2019/06/19/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/"/>
      <url>/2019/06/19/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>安装mysql，按照官网教程来即可 <a href="https://dev.mysql.com/doc/refman/8.0/en/linux-installation-yum-repo.html" target="_blank" rel="noopener">官网连接</a><br>在 windows 下安装MySQL时会出现错误</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">D:\Software\Mysql-8.0.17-winx64\bin&gt;net start MySQL</span><br><span class="line">服务没有响应控制功能。</span><br><span class="line">请键入 NET HELPMSG 2186 以获得更多的帮助。</span><br></pre></td></tr></table></figure><p>解决方法：在windows 服务控制中，设置MySQL服务的属性-&gt;登陆-&gt;登陆身份  中设置身份为此身份，身份应当有Administration权限<br>安装java</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bwg</title>
      <link href="/2019/06/17/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/bwg/"/>
      <url>/2019/06/17/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/bwg/</url>
      
        <content type="html"><![CDATA[<p>今天尝试给bwg上的vpn安装上支持 IPV4,IPV6和多端口（即监听来自IPV4,ipv6的多个端口的访问）<br>弄了半天，把多端口访问的问题，弄好了，但是同时允许IPV4，IPv6的不行，被恶心了（有空再折腾这个）<br>暂且记录下流程</p><ul><li>寻找多端口的方法；由于我的配置是基于openvpn，只能设置一个端口；多端口的话，可以安装基于python实现的shadowsocks</li><li>进行最后一步发现，都是对ssserver的配置</li><li>尝试配置监听IPV4,IPV6访问，尝试过各种配置发现，最后找到以为博主的方法，从方法逻辑上看，是可以的，但是实际中不行，可能是我的其他配置问题（例如防火墙？），但下次再折腾这个，再次列出 <a href="http://jinke.me/2015-12-20-shadowsocks/" target="_blank" rel="noopener">链接</a>,因为比较敏感，以防丢失，暂且记录下思路；大概是分别存在IPv4与ipv6的配置文件，并启动shadowsocks 分配给不同的进程</li><li>由于基于python的shadowsocks很久都没有更新了，看github上的讨论，基于c语言的shadowsocks可以实现ipv4v6共存，因而尝试安装基于c语言的shadowsocks；</li><li>发现安装shadowsocks-libev 需要很多依赖，而且依赖循环依赖，很恶心，尝试了一阵后，因为马上有事，就暂且放弃</li><li>步骤1:在https://pkgs.org/上寻找需要的centosrpm包，下载，安装 ；步骤2：重复步骤1</li><li>注意点：下载rpm包时，注意与自己服务器的系统对应（比如 我的系统是centos6，下载的7，/(ㄒoㄒ)/~~）； 留心该命令  yum install --downloadonly --downloaddir=/root/rpm <package-name> 以及<a href="https://blog.csdn.net/xuxile/article/details/88699910" target="_blank" rel="noopener">链接</a>，似乎可以避免循环依赖的问题,但是尝试失败；在使用yum repolist all 查看时发现很多源都被禁止，不知道为什么？下次有空探究下；</package-name></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> vpn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跨域问题小结</title>
      <link href="/2019/05/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98%E5%B0%8F%E7%BB%93/"/>
      <url>/2019/05/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98%E5%B0%8F%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>最近在做项目时经常遇到跨域问题，经历过这种折腾，最终有两种比较可行的方法，但总体而言都是代理转发</p><ul><li>在nginx上部署相关请求的代理转发，在将请求指向同域名的nginx服务器</li><li>将请求转发给网关，由网关做代理</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> cross_domain </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务授权</title>
      <link href="/2019/05/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8E%88%E6%9D%83/"/>
      <url>/2019/05/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8E%88%E6%9D%83/</url>
      
        <content type="html"><![CDATA[<p>目前准备使用外部授权认证服务与kong结合，kong可能制作简单的限流任务；<br>经过查询，发现kong在这里提供两个插件<br><a href="https://docs.konghq.com/hub/kong-inc/oauth2/" target="_blank" rel="noopener">OAuth 2.0 Authentication</a><br>和 <a href="https://docs.konghq.com/hub/kong-inc/oauth2-introspection/" target="_blank" rel="noopener">OAuth 2.0 Introspection</a><br>前者主要可以提供Oauth 认证服务，而后者支持第三方的授权认证服务器，不过仅支持企业版<br>最后找到一个github同仁自己基于 lua开发的相关插件，<a href="https://github.com/mogui/kong-external-oauth" target="_blank" rel="noopener">链接</a></p><p>安装 这个额外插件，重新启动kong 时，luarock 需要luacrypto 去完成加密相关操作，故直接即可  sudo luarocks install luacrypto（从源码配置有点麻烦）</p><p>Spring Security 源码分析系列博客<br><a href="https://niocoder.com/categories/#Security" target="_blank" rel="noopener">链接1</a><br><a href="http://www.liuhaihua.cn/%E5%8F%B2%E4%B8%8A%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84-springcloud-%E6%95%99%E7%A8%8B" target="_blank" rel="noopener">链接2</a></p><p>spring 讲解<br><a href="https://www.cnblogs.com/RunForLove/p/4641672.html" target="_blank" rel="noopener">链接1</a></p><p>spring 默认配置<br><a href="https://www.jianshu.com/p/b02691ff4093" target="_blank" rel="noopener">链接1</a></p><p>springboot+springsecurity+oauth2整合(并用mysql数据库实现持久化客户端数据 <a href="https://blog.csdn.net/Victor_An/article/details/81510874" target="_blank" rel="noopener">链接1</a></p><p>spring登录认证 与 token<br><a href="https://www.huangyunkun.com/2016/03/02/spring-security-form-to-token/" target="_blank" rel="noopener">链接1</a><br><a href="https://www.jianshu.com/p/19059060036b" target="_blank" rel="noopener">链接2</a><br><a href="https://www.jianshu.com/p/68779236aa23" target="_blank" rel="noopener">链接3</a><br><a href="https://www.cnblogs.com/xifengxiaoma/p/10043173.html" target="_blank" rel="noopener">链接4 个人觉得最详细</a><br>access_token 获取过程 <a href="https://www.cnblogs.com/lexiaofei/p/7152326.html?utm_source=itdadao&amp;utm_medium=referral" target="_blank" rel="noopener">链接1</a></p><p>access_token 更改返回 <a href="https://www.jianshu.com/p/d9a35facff6f" target="_blank" rel="noopener">链接1</a></p><p>oauth2数据库 表的说明 <a href="https://www.cnblogs.com/donglu/articles/10218348.html" target="_blank" rel="noopener">链接1</a><br><a href="https://www.bbsmax.com/A/qVdeeNmndP/" target="_blank" rel="noopener">链接2</a><br><a href="http://www.andaily.com/spring-oauth-server/db_table_description.html" target="_blank" rel="noopener">链接3</a></p><p>oauth2 授权过程说明 来自知乎<a href="https://www.zhihu.com/question/19781476" target="_blank" rel="noopener">链接1</a><br><a href="http://andaily.com/spring-oauth-server/db_table_description.html" target="_blank" rel="noopener">链接2</a></p><p>接口测试链接(备用)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">POST http://localhost:8082/oauth/token?grant_type=client_credentials&amp;client_id=curl_client&amp;client_secret=user</span><br><span class="line"></span><br><span class="line">GET http://localhost:8082/oauth/check_token?grant_type=client_credentials&amp;token=445d302d-4fa1-49c4-8800-617bd72dd1e9</span><br></pre></td></tr></table></figure><p>在直接使用JdbcClientDetailsService 直接查询数据时，出现变量为null<br>即在非controller 层使用 @AUtowired时，无法取得变量<br>使用 如下方法 解决  <a href="https://blog.csdn.net/u013294097/article/details/84192367" target="_blank" rel="noopener">链接</a></p><p>error</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data too long for oauth_code column &apos;authentication&apos;</span><br><span class="line">这是在oauth服务器中获取oauth_code时往数据库插入值时，发生的意外，在网上找到许多奇奇怪怪的方法，行不通，最后发现自己在数据库oauth建表是oauth_code 表 authentication 表项为 VARBINARY 而实际应该是 LONG VARBINARY</span><br></pre></td></tr></table></figure><p>2019-5-21</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">目前，打算借助oauth2 实现SSO ,利用client_credential 来识别不同系统或者应用，只不过比较困惑的是如何定义用户的权限(目前做demou先不考虑)</span><br></pre></td></tr></table></figure><p>2019-5-23<br>认证流程<br>1.系统A检测是否有token，没有跳转</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8082/oauth/authorize?client_id=test&amp;redirect_uri=http://127.0.0.1&amp;response_type=code&amp;scope=read</span><br></pre></td></tr></table></figure><p>2.填写用户名与密码（图片不对，待更换）<br><img src="https://github.com/walkdeadtobe/picture/raw/master/code_check_token.png" alt="登录_png"><br>3.返回相应code 到系统A，系统A根据code到授权服务器申请token（部分图片错误，待更改）</p><blockquote><p>获取code<br><img src="https://github.com/walkdeadtobe/picture/raw/master/code_check_token.png" alt="获取code_png"></p></blockquote><blockquote><p>根据code获取token<br><img src="https://github.com/walkdeadtobe/picture/raw/master/code_token.png" alt="获取token_png"></p></blockquote><p>4.系统检测到token后，需要到授权系统检测该token对应的用户权限</p><blockquote><p>获取token所对应用户权限<br><img src="https://github.com/walkdeadtobe/picture/raw/master/code_check_token.png" alt="检测token_png"></p></blockquote><p>2019-7-24<br>最近涉及到单点登陆系统记住用户所登陆的系统，下次访问默认登陆,经过思考可以在cookie里面添加tag字段,在接受登陆请求之后标志所登陆的系统,下次登陆时可以以此作为标志,此外应当保证登陆另外一个系统时，字段值更改(js),这就需要后端向前端传值,由于sprig boot里传递的是modelandview 所以不采用在url链接链接里附上参数的方法，转而 controller层通过Model对象传值到对应的返回页面，返回页面获得相应的参数来做处理;<br>前端页面我 使用 thymeleaf模板引擎 渲染,其也有相应的方法取值<br>后端：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@RequestMapping(&quot;/login&quot;)</span><br><span class="line">    public ModelAndView loginPage(HttpServletRequest request, HttpServletResponse response) &#123;</span><br><span class="line">        RequestCache requestCache= new HttpSessionRequestCache();</span><br><span class="line">        SavedRequest savedrequest = requestCache.getRequest(request,response);</span><br><span class="line">        ModelAndView model = new ModelAndView(&quot;login&quot;);</span><br><span class="line">        model.addObject(&quot;from&quot;, &quot;all&quot;);</span><br><span class="line">       return model;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>前端：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">var s_from = [[$&#123;from&#125;]];</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;p  th:text=&quot;#&#123;from&#125;&quot;&gt;&lt;/p&gt;</span><br></pre></td></tr></table></figure><p>此外，由于需要获得服务启动时服务本身的端口号，需要配置读取 Application.yml 的配置信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># @ConfigurationProperties 注解依赖</span><br><span class="line">&lt;dependency&gt;  </span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  </span><br><span class="line">    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;  </span><br><span class="line">    &lt;optional&gt;true&lt;/optional&gt;  </span><br><span class="line">&lt;/dependency&gt;  </span><br><span class="line"></span><br><span class="line">#Application.yml 部分内容</span><br><span class="line">server:</span><br><span class="line">  port: 80</span><br><span class="line">  address: 0.0.0.0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置类</span><br><span class="line">package com.aak.configuration;</span><br><span class="line"></span><br><span class="line">import org.springframework.boot.context.properties.ConfigurationProperties;</span><br><span class="line">import org.springframework.context.annotation.Bean;</span><br><span class="line">import org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line">@Component</span><br><span class="line">@ConfigurationProperties(prefix=&quot;server&quot;) //接收application.yml中的server下面的属性</span><br><span class="line">public class MyApplication &#123;</span><br><span class="line">    public String address;</span><br><span class="line">    public String port;</span><br><span class="line">    public String getUrl() &#123;</span><br><span class="line">        return address;</span><br><span class="line">    &#125;</span><br><span class="line">    public void setUrl(String Url) &#123;</span><br><span class="line">        this.address = Url;</span><br><span class="line">    &#125;</span><br><span class="line">    public String getPort() &#123;</span><br><span class="line">        return port;</span><br><span class="line">    &#125;</span><br><span class="line">    public void setPort(String port) &#123;</span><br><span class="line">        this.port = port;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#使用</span><br><span class="line">@Autowired</span><br><span class="line">private MyApplication myApplication ;</span><br><span class="line">String port=myApplication.getPort();</span><br><span class="line">log.info(&quot;port:&quot;+port);</span><br></pre></td></tr></table></figure><p>2019-8-5<br>spring security oauth2 authorization code模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[Spring Security Oauth 相关配置默认实现](https://docs.spring.io/spring-security/oauth/apidocs/org/springframework/security/oauth2/provider/endpoint/package-summary.html),其中包含(后期重新排版)</span><br><span class="line">AuthorizationEndpoint:Implementation of the Authorization Endpoint from the OAuth2 specification.</span><br><span class="line">CheckTokenEndpoint:Controller which decodes access tokens for clients who are not able to do so (or where opaque token values are used).</span><br><span class="line">DefaultRedirectResolver:Default implementation for a redirect resolver.</span><br><span class="line">ExactMatchRedirectResolver:Strict implementation for a redirect resolver which requires an exact match between the registered and requested redirect_uri.</span><br><span class="line">FrameworkEndpointHandlerMapping:A handler mapping for framework endpoints (those annotated with @FrameworkEndpoint).</span><br><span class="line">TokenEndpoint:Endpoint for token requests as described in the OAuth2 spec.</span><br><span class="line">TokenEndpointAuthenticationFilter:An optional authentication filter for the TokenEndpoint.</span><br><span class="line">TokenKeyEndpoint:OAuth2 token services that produces JWT encoded token values.</span><br><span class="line">WhitelabelApprovalEndpoint:Controller for displaying the approval page for the authorization server.</span><br><span class="line">WhitelabelErrorEndpoint:Controller for displaying the error page for the authorization server.</span><br><span class="line"></span><br><span class="line">最近需要在单点登录系统中实现在登录完成之后.跳转回系统跳转登录的页面</span><br><span class="line">code 模式下, </span><br><span class="line">1.跳转 http://localhost:8080/oauth/authorize?client_id=test2&amp;redirect_uri=http://127.0.0.1/oauth/code&amp;response_type=code&amp;scope=read</span><br><span class="line">2.登录成功之后返回code即重定向至http://127.0.0.1/oauth/code?code=CODE</span><br><span class="line">3.http://127.0.0.1/oauth/code?code=CODE获取code,传至后端,后端由此可以根据code获取token以Set-Cookie的方式返回response到页面</span><br><span class="line"></span><br><span class="line">AuthorizationEndpoint 实现 /oauth/authorize 接口,[实现流程](https://www.cnblogs.com/xifengxiaoma/p/10043173.html)中首先检验相关信息正确,之后在code模式下会生成code,并跳转回 redirect_uri?code=CODE</span><br><span class="line">最初以为需要重写 [AuthorizationEndpoint 实现](http://www.javased.com/?source_dir=spring-security-oauth/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/provider/endpoint/AuthorizationEndpoint.java) 下面 /oauth/authorize 接口,使得最终重定向到redirect_uri后在链接中添加上跳转发生时来源的网址.经过调查没有找到重写 AuthorizationEndpoint 类的方法(spring security 没有提供接口,使得重写类覆盖默认类, 发生作用)</span><br><span class="line">后来发现 跳转时 是 由 window.location.href 实现的,但是无法像request请求一样 拥有 referer header ,即使能够重写 AuthorizationEndpoint 类,也不能从保存的请求中获取 相关header,只能在跳转链接中附上相关信息(暂时没有调研,是否可以在跳转的同时携带相关信息);</span><br><span class="line">问题在于 跳转回redirect_uri是在AuthorizationEndpoint 实现的,具体的地址已经配置好,而且没有找到相关的filter可以在这处理发生后拦截,进行相关逻辑处理,之后想到可以把 redirect_u redirect_uri 中,即redirect_uri=/oauth/code?back_to=原本处理code的地址</span><br><span class="line">以及可以在 跳转链接上 附上 window.location 信息(refer=window.location),然后在 login 中保存相关信息到 当前session,然后在接口中/oauth/code 接口实现中,提取出back_to和 code值,以及附上从session 获得的refer,返回,告知back_to获得token 后应当跳转的地址</span><br><span class="line">完整链接如下:</span><br><span class="line">window.location.href=&apos;http://localhost:8080/oauth/authorize?client_id=test2&amp;redirect_uri=/oauth/code?back_to=http://127.0.0.1/oauth/code&amp;response_type=code&amp;scope=read&amp;refer=&apos;+window.location</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>watch_dog</title>
      <link href="/2019/05/21/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/watch_dog/"/>
      <url>/2019/05/21/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/watch_dog/</url>
      
        <content type="html"><![CDATA[<p>由于需要某些程序一直运行，或者能够自动重启，由此接触到看门狗程序这一概念</p>]]></content>
      
      
      
        <tags>
            
            <tag> script </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring</title>
      <link href="/2019/05/15/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/Spring/"/>
      <url>/2019/05/15/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/Spring/</url>
      
        <content type="html"><![CDATA[<p>Spring Security 核心功能</p><ul><li>认证</li><li>授权</li><li>攻击防护</li></ul><p>其实质是一组过滤器链,项目启动后会自动配置</p><ul><li>UserNamePassWord Authentication Filter</li><li>Basic Authentation Filter</li><li>Exception Transaction Filter</li><li>FilterSecurity Interceptor</li></ul><p>创建配置类</p><blockquote><p>SecurityConfig继承自WebSecurityConfigurerAdapter,重写config 方法 在里面可以配置 登录重定向的地址以及提交登录表单的地址 以及可以直接访问的url<br>获取认证信息<br>继承UserDetailSevice接口,实现loadUserByUsername方法,实现用户名和密码的匹配,验证通过之后返回经过验证的用户信息(包含权限等信息)</p></blockquote><p>spring security 和 oauth 认证中涉及的环节<br>‘’’<br>UsernamePasswordAuthenticationToken继承AbstractAuthenticationToken实现Authentication<br>所以当在页面中输入用户名和密码之后首先会进入到UsernamePasswordAuthenticationToken验证(Authentication)，<br>然后生成的Authentication会被交由AuthenticationManager来进行管理<br>而AuthenticationManager管理一系列的AuthenticationProvider，<br>而每一个Provider都会通UserDetailsService和UserDetail来返回一个<br>以UsernamePasswordAuthenticationToken实现的带用户名和密码以及权限的Authentication<br><a href="https://www.cnblogs.com/softidea/p/6716807.html" target="_blank" rel="noopener">参考博客</a><br>‘’’</p><p>Spring Aop</p><blockquote><p><a href="https://www.jianshu.com/p/5b9a0d77f95f" target="_blank" rel="noopener">参考1</a><br>面向切面编程，在程序开发中主要用来解决一些系统层面上的问题即公用模块，比如日志，事务，权限等待，Struts2的拦截器设计就是基于AOP的思想;在不改变原有的逻辑的基础上，增加一些额外的功能。代理也是这个功能，读写分离也能用aop来做<br>应用(注解)：Authentication logging, tracing,Transactions</p></blockquote><p>Spring IOC/DI<br><a href="https://juejin.im/post/6867526780916334605" target="_blank" rel="noopener">Spring IOC核心理论</a></p><blockquote><p>Inversion of Control 控制反转 依赖注入<br>IOC ，就是由 Spring IOC 容器来负责对象的生命周期和对象之间的关系<br>Mybatic<a href="https://www.w3cschool.cn/mybatis/" target="_blank" rel="noopener">参考</a><br>支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。<br>dao mapper<br>Mybatis的功能架构分为三层：</p></blockquote><ul><li>API接口层：提供给外部使用的接口API，开发人员通过这些本地API来操纵数据库。接口层一接收到调用请求就会调用数据处理层来完成具体的数据处理。</li><li>数据处理层：负责具体的SQL查找、SQL解析、SQL执行和执行结果映射处理等。它主要的目的是根据调用的请求完成一次数据库操作。</li><li>基础支撑层：负责最基础的功能支撑，包括连接管理、事务管理、配置加载和缓存处理，这些都是共用的东西，将他们抽取出来作为最基础的组件。为上层的数据处理层提供最基础的支撑。</li></ul><p>Filter过滤器 VS Interceptor拦截器 VS AOP</p><ul><li>过滤器拦截web访问url地址。 严格意义上讲，filter只是适用于web中，依赖于Servlet容器，利用Java的回调机制进行实现</li><li>拦截器拦截以 .action结尾的url，拦截Action的访问。 Interfactor是基于Java的反射机制（APO思想）进行实现，不依赖Servlet容器</li></ul><p><a href="https://blog.csdn.net/qq_30257149/article/details/88224879" target="_blank" rel="noopener">Spring源码之ApplicationContext</a></p><p><a href="https://segmentfault.com/a/1190000019560001" target="_blank" rel="noopener">深入理解SpringApplication</a></p><p><a href="https://juejin.im/post/6844903844917280781" target="_blank" rel="noopener">Spring源码之注解扫描Component-scan</a></p><h2 id="spring-security">Spring Security</h2><p>BeanDefinitionReader 读取配置，创建BeanDefinition 注册到BeanDefinitionRegister</p><p>Spring Boot 启动流程<br><a href="https://segmentfault.com/a/1190000019560001" target="_blank" rel="noopener">深入理解SpringApplication</a></p><ul><li>入口函数</li></ul><blockquote><p>启动类 main 函数 SpringApplication.run(*.class,args)</p></blockquote><blockquote><p>两个参数：第一个参数为Spring容器配置类,第二个参数 命令行参数,将参数转给SpringApplication 类,通过命令行参数对java应用做一些配置<br>SpringApplication 会完成以下事项来启动应用：</p><ul><li>为应用创建合适的ApplicationContext</li><li>注册一个CommandLinePropertySource,通过CommandPropertySource可以对外暴露命令行参数,并将命令行参数与应用的properties 联系起来</li><li>启动ApplicationContext</li><li>执行所有CommandLineRunner类型的Bean</li></ul></blockquote><blockquote><p>@SpringBootApplication 注解 包含 @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan<br>@ComponentScan 默认会扫描 被 @Service @Component @Repository @Controller 注解的类,并注册进容器</p></blockquote><ul><li>初始化 SpringApplication</li></ul><blockquote><p>new SpringApplication(primarySources).run(args)<br>Spring的初始化流程</p><ul><li>初始化Spring容器的配置类 primarySources</li><li>推断应用程序的类型,进而根据类型 创建不同的ApplicationContext<ul><li>根据classpath下面存在org.springframework.web.reactive.DispatcherHandler 类,则应用类型是REACTIVE,需启动内嵌 web Server;对应AnnotationConfigReactiveWebServerApplicationContext</li><li>如果存在 org.springframework.web.servlet.DispatcherServlet 类,则应用类型 是SERVLET,需要启动内嵌的web server;对应AnnotationConfigServletWebServerApplicationContext</li><li>都不存在,则是NONE类型,无需 内嵌 web server;对应AnnotationConfigApplicationContext</li></ul></li><li>初始化指定的ApplicationContextInitializatier列表<ul><li>借助SpringFactoryiesLoader 读取jar包中 META-INF/spring.factories 配置文件完成初始化</li></ul></li><li>初始化指定的ApplicationListener 类<ul><li>借助SpringFactoryiesLoader 读取jar包中 META-INF/spring.factories 配置文件完成初始化</li></ul></li><li>推断main class 的类名称<ul><li>通过遍历异常堆栈,获取方法名为main的元素,确认该元素对应的类为主类</li></ul></li></ul></blockquote><ul><li>运行</li></ul><blockquote><ul><li>新建StopWatch 对象,记录应用启动的时间</li><li>利用SpringFactoriesLoader的机制加载所有的SpringRunListener(啥用？),并封装为SpringRunListeners</li><li>listeners.start()</li><li>根据ApplicationType,创建并配置SpringApplication要是用的Environment(包括propertySource和Profile)</li><li>listener.environmentPrepared()</li><li>根据ApplicationType 创建 ApplicationContext.</li><li>调用ApplicationContextIniatializer完成ApplicationContext的初始化</li><li>listeners.contextPrepared()</li><li>向ApplicationContext加载所有Bean</li><li>listeners.contextLoaded()</li><li>调用ApplicationContext的refresh方法(干啥),完成最后一道手续</li><li>listeners.startedContext()</li><li>检查当前Spring容器是否有ApplicationRunner 和 CommandLineRunner 类型的bean,如果有便利执行</li><li>listeners.running(context)<br>完成启动</li></ul></blockquote><ul><li>扫描</li></ul><blockquote><p>会扫描 启动类所在包以及子路径下的所有编译产生的class文件,然后 判断是否满足要求,对于满足要求的注解进容器<br>class 包含的数据结构包括 源文件,常量池,接口,字段,方法,属性(包含了接口的种类)</p></blockquote><p>bean 的生命周期<br><img src="/images/spring-bean-live-procedure.jpg" alt="用来描述图片的关键词"></p><blockquote><ol><li>Spring 对bean进行实例化</li><li>Spring 将值以及对Bean的引用注入bean 对应的属性中</li><li>如果bean 实现了BeanNmaeAware 接口,Spring 将bean的ID传递给setBeanName()方法</li><li>如果bean实现了BeanFactoryAware 接口 Spring 将调动setBeanFactory()方法，将beanFactory 容器实例传入</li><li>如果 bean实现了ApplicationContextAware 接口，Spring 将调用setApplicationContext方法，将bean所在应用的上下文的引用传入进来;</li><li>如果bean实现了BeanPostProcessor 接口，Spring将调用它们的postProcessBeforeInitialization() 方法</li><li>如果bean 实现了 InitializatingBean 接口,Spring  将调用它们的afterPropertiesSet 方法,类似的 如果 bean使用了 init-method 声明了初始化方法,该方法也会被调用</li><li>如果bean 实现了 BeanPostProcessor 接口,Spring 将调用了它们的postProcessAfterInitialization() 方法</li><li>此时 Bean 已经准备就绪,可以被应用程序使用, 他们将一直驻留在应用上下文中,直至该上下文被销毁</li><li>如果bean实现了 DisposableBean 接口,Spring将调用它的destroy() 接口。同样,如果bean 使用了destroy—method 声明了销毁方法,该方法也会被调用。</li></ol></blockquote><p>Bean的注册和填充</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Spring组件按其所承担的角色可以划分为两类：</span><br><span class="line">1）物料组件：Resource、BeanDefinition、PropertyEditor以及最终的Bean等，它们是加工流程中被加工、被消费的组件，就像流水线上被加工的物料；</span><br><span class="line">2）加工设备组件：ResourceLoader、BeanDefinitionReader、BeanFactoryPostProcessor、InstantiationStrategy以及BeanWrapper等组件像是流水线上不同环节的加工设备，对物料组件进行加工处理</span><br></pre></td></tr></table></figure><blockquote><p>Spring提供了BeanFactory对Bean进行获取，但Bean的注册和管理并不是在BeanFactory中进行的，而是在BeanDefinitionRegistry中进行的<br>通过定义BeanDefination(AnnotationBeanDefination) 绑定了beanclass 和bean的其他一些信息(scope,autowiredMode,factorybeanName:获得BeanFactory 创建Bean)<br>BeanDefinitionRegistry中的CocurrentHashMap 存储了 beanName 与 BeanDefination</p></blockquote><blockquote><p>SingletonObject (CocurrentMap) 存储 beanName 和 BeanInstance的映射</p></blockquote><p>bean 实例化</p><blockquote><p>实例化阶段主要是通过反射或者CGLIB对bean进行实例化，在这个阶段Spring又给我们暴露了很多的扩展点：</p><ul><li>各种的Aware接口，比如 BeanFactoryAware，MessageSourceAware，ApplicationContextAware</li><li>BeanPostProcessor接口,实例化bean时Spring会帮我们调用接口中的方法：</li><li>InitializingBean:@PostConstruct 和 @PreDestroy</li><li>DisposablegBean</li></ul></blockquote><p>单例bean的效率和安全性</p><blockquote><p>默认单例bean<br>通过ThreadLocal实现对于bean中局部变量的多线程共享访问,互不干扰, 安全且高效<br>对于bean中的全局或者静态变量,可以声明scope为原型模式</p></blockquote><p>原型模式    VS      工厂模式</p><blockquote><p>抽象工厂模式：通常由工厂方法模式来实现。但一个工厂中往往含有多个工厂方 法生成一系列的产品。这个模式强调的是客户代码一次保证只使用一个系列的产品。当要切换为另一个系列的产品，换一个工厂类即可。<br>原型模式：工厂方法的最大缺点就是，对应一个继承体系的产品类，要有一个同 样复杂的工厂类的继承体系。我们可以把工厂类中的工厂方法放到产品类自身之 中吗？如果这样的话，就可以将两个继承体系为一个。这也就是原型模式的思想，原型模式中的工厂方法为clone，它会返回一个拷贝（可以是浅拷贝，也可以是深拷贝，由设计者决定）。为了保证用户代码中到时可以通过指针调用 clone 来动 态绑定地生成所需的具体的类。这些原型对象必须事先构造好。<br>原型模式想对工厂方法模式的另一个好处是，拷贝的效率一般对构造的效率要高</p></blockquote><p>Spring 事物传播<br><a href="https://blog.csdn.net/qq_26323323/article/details/81908955" target="_blank" rel="noopener">参考1</a></p><blockquote><p>事物保证操作的原子性,不保证正确率<br>事务在多个方法的调用中是如何传递的，是重新创建事务还是使用父方法的事务？父方法的回滚对子方法的事务是否有影响？这些都是可以通过事务传播机制来决定的。</p><ul><li>Propagation.REQUIRED：如果有事务则加入事务，如果没有事务，则创建一个新的(默认值)</li><li>NOT_SUPPORTED: 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</li><li>REQUIRES_NEW:不管是否存在事务，都创建一个新的事务，原来的方法挂起，新的方法执行完毕后，继续执行老的事务</li><li>MANDATORY:必须在一个已有的事务中执行，否则报错</li><li>NEVER:必须在一个没有的事务中执行，否则报错(可能会导致已存在的事物回滚)</li><li>SUPPORTS:是否使用事务取决于调用方法者是否有事务，如果有则直接用，如果没有则不使用事务</li><li>NESTED:如果当前存在事务，则在<a href="http://blog.chinaunix.net/uid-10289334-id-2964925.html" target="_blank" rel="noopener">嵌套事务</a>内执行。如果当前没有事务，则执行与REQUIRED类似的操作;嵌套事物相当于在一个事物中嵌入一个子事物,子事物依赖于父事物,嵌入点为savePoint,子事物失败可以会滚回savePoint,</li></ul></blockquote><p>Spring 自动装配策略</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public interface AutowireCapableBeanFactory&#123;</span><br><span class="line">    //无需自动装配：默认配置,对所有Bean不自动装配,除非Bean配置了autowire 属性 </span><br><span class="line">    int AUTOWIRE_NO = 0;</span><br><span class="line"></span><br><span class="line">    //按名称自动装配bean属性:把与Bean的属性具备相同名字的其他Bean 填充到该Bean的对应属性中</span><br><span class="line">    int AUTOWIRE_BY_NAME = 1;</span><br><span class="line"></span><br><span class="line">    //按类型自动装配bean属性:把与Bean的属性具备相同类型的Bean自动装配到Bean的对应属性中</span><br><span class="line">    int AUTOWIRE_BY_TYPE = 2;</span><br><span class="line"></span><br><span class="line">    //按构造器自动装配：根据Bean的构造器入参类型,寻找具有相同类型的其他Bean 对应参数 入参</span><br><span class="line">    int AUTOWIRE_CONSTRUCTOR = 3;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>@Autowired 流程</p><blockquote><p>@Inject @Value<br>注入时间:在Spring容器启动后,加载类,Bean 实例化之后通过实现AutowiredAnnotationPostProcessor实现注入<br>@Autowired, @Inject, @Resource, and @Value annotations are handled by Spring BeanPostProcessor implementations which in turn means that you cannot apply these annotations within your own BeanPostProcessor or BeanFactoryPostProcessor types (if any). These types must be ‘wired up’ explicitly via XML or using a Spring @Bean method.</p></blockquote><p>参考：</p><ul><li><a href="https://segmentfault.com/a/1190000018077152" target="_blank" rel="noopener">Spring源码分析：@Autowired注解原理分析</a></li><li><a href="https://www.cnblogs.com/zhmlearn/p/12247073.html" target="_blank" rel="noopener">记录一次追踪@AutoWired的过程</a></li><li><a href="https://docs.spring.io/spring/docs/4.3.22.RELEASE/spring-framework-reference/htmlsingle/#beans-autowired-annotation" target="_blank" rel="noopener">官网doc</a><br>注解的流程</li></ul><p>三段式事务提交</p><p>数据库锁</p><blockquote></blockquote><p><a href="https://zhshuixian.github.io/learn-spring-boot-2/#/06-SpringSecurity" target="_blank" rel="noopener">Spring Security</a></p><blockquote><p>对于 Web 系统来说，对页面和 API 接口的访问权限进行安全控制是必须的，例如需要阻止非系统用户的访问，控制不同页面或接口的访问权限。在 Java 开发中，常用的安全框架有 Spring Security 和 Apache Shiro<br>Spring Security 主要包括如下两个部分：</p></blockquote><ul><li>登录认证（Authentication）</li><li>访问授权（Authorization）</li></ul><p>使用 Spring Security ，只需要实现 UserDetailsService 接口和继承 WebSecurityConfigurerAdapter</p><ul><li>loadUserByUsername：通过重写 UserDetailsService 接口的 loadUserByUsername 方法，给 Spring Security 传入用户名、用户密码、用户角色。</li><li>BCryptPasswordEncoder ：通过 BCrypt 强哈希方法加密存储密码。对于 Web 系统来说，几乎不会明文存储密码。Spring Security 提供的 BCryptPasswordEncoder 类实现密码加密的功能。BCrypt 强哈希方法每次加密的结果是不同的。</li></ul><p>@PreAuthorize 表示这个 URL 需要某种角色权限才能访问</p><p>Spring Security (Token)登录和注册</p><p>在分布式系统中，不同机器上服务可能同时访问共享数据资源，如果出现多个服务同时写入、读取就会发生不同客户端获取的数据不一致的情况，最终的数据也会出错；对于这些情况，需要引入 分布式锁 ，保证同一时刻只有一个服务访问操作共享数据，使用跨 JVM 的互斥机制控制共享资源的访问。分布式锁有多种实现方式，例如基于数据库、Zookeeper、Redis、Memcached、Chubby。</p><p>分布式锁应当具备如下条件：</p><ul><li>互斥性：保证同一资源在同一时间只能被一个线程访问</li><li>高可用、高性能：获取锁与释放锁的高可用与高性能</li><li>锁失效机制：防止拿到锁的线程挂了没有释放锁导致死锁</li><li>非阻塞锁：没有获得锁直接返回失败，而不是等待直到获得锁</li><li>可重入性：锁过期或释放后，其线程可以继续获得锁，而不会发生数据错误</li></ul><p>RocketMQ</p><p>Spring bean 分类</p><p>什么是Spring MVC ？简单介绍下你对springMVC的理解?</p><p>SpringMVC的流程？<br>Springmvc的优点:</p><p>Spring MVC的主要组件？<br><a href="https://blog.csdn.net/a745233700/article/details/80963758" target="_blank" rel="noopener">SpringMVC常见面试题总结</a></p><p><a href="https://blog.csdn.net/a745233700/article/details/80959716" target="_blank" rel="noopener">Spring常见面试题总结</a></p><p>注解<br>@Repository：用于标注数据访问组件,即dao组价<br>@Primary、@Qualifier</p><h3 id="aop">AOP</h3><p>面向切面编程</p><h4 id="基本概念">基本概念</h4><p>Aspect</p><blockquote><p>通知与切入点的集合</p></blockquote><p>pointCut</p><blockquote><p>定义在什么类的什么方法执行,确定具体插入的Advice的地方</p></blockquote><p>joinPoint</p><blockquote><p>插入Advice的地方,spring aop中方法的前后都可以成为连接点,但具体哪里成为需要切点确定<br>一般不涉及明确的代码</p></blockquote><p>advice</p><blockquote><p>增强,所需要的完成的工作,在pointCut已确定的基础上,决定在切点出现的位置</p></blockquote><ul><li>Before:前置通知,方法调用前执行</li><li>After：后置通知 方法调用后执行</li><li>After-returning ：在方法调用后有结果时执行,有结果的话优先级高于after</li><li>After-throwing：方法执行抛出异常时执行</li><li>Aroud：相当于before+after的加强版,在其中调用joinpoint.procced()完成具体连接点方法的执行,也可以不执行,在执行前后可以添加逻辑,代替了连接点</li></ul><p>织入</p><blockquote><p>将切面与切入点结合这是个逻辑过程</p><ul><li>编译期织入，这要求使用特殊的Java编译器。</li><li>类装载期织入，这要求使用特殊的类装载器。</li><li>动态代理织入，在运行期为目标类添加增强生成子类的方式。</li></ul></blockquote><p>@Order</p><blockquote><p>标识启动的优先级,可以用于多个切换同时涉及一个连接点时,定义优先级<br>数字越小优先级越高,默认最低优先级,数字为Integer.Max_Value</p></blockquote><p>JDK动态代理为什么不能代理类</p><blockquote><p>已经继承了Proxy,不能多继承</p></blockquote><h3 id="jdk-动态代理">JDK 动态代理</h3><p>Proxy类<br>InvocationHandler接口<br>其他涉及类 ProxyUtil ProxyGenerator AdvisedSupport  DefautAdvisorChainFacotry JdkDynamicAopProxy Cglib2AopProxy<br>AdviseSUpport ProxyFactory<br><a href="https://my.oschina.net/u/3687664/blog/4267525" target="_blank" rel="noopener">参考0：Spring AOP执行流程源码解析</a><br><a href="https://my.oschina.net/u/3687664/blog/4267549" target="_blank" rel="noopener">参考0-1：pring中通过JDK代理执行aop目标方法流程解析</a><br><a href="https://blog.csdn.net/paincupid/article/details/89714862" target="_blank" rel="noopener">参考1:源码通透-spring-AOP-4-spring-AOP-invoke调用过程</a><br><a href="https://my.oschina.net/u/4317546/blog/3527274" target="_blank" rel="noopener">参考2：pring AOP 多个切点实现:JdkDynamicAopProxy</a></p><p>AOP流程<br><a href="https://www.jianshu.com/p/2250b24a3f7d" target="_blank" rel="noopener">BeanPostProcessor里，有一个AnnotationAwareAspectJAutoProxyCreator，spring会在该类的 postProcessBeforeInitialization 里进行Advisor的初始化</a><br>就是遍历所有的 没有Pointcut注解的方法，调用getAdvisor生成对应的Advisor(包含ascect order信息 ),并缓存<br>然后在执行bean对象的方法时,会<a href="https://my.oschina.net/u/4317546/blog/3527274" target="_blank" rel="noopener">根据方法名和类名去寻找</a>相应的advisor,从<a href="https://blog.csdn.net/chao_19/article/details/51843352" target="_blank" rel="noopener">AdvisedSupport</a>中寻找;<br>在 getInterceptorsAndDynamicInterceptionAdvice 里 他会遍历所有的advisor如果和method以及class符合那么将其中的inteceptor都添加进list并返回,将list作为参数构建<a href="https://my.oschina.net/u/2518341/blog/3073722" target="_blank" rel="noopener">ReflectiveMethodInvocation</a> 然后调用其proceed方法执行</p><p>对于实现接口A的类B动态代理</p><blockquote><p>以类B 和 加载器作为参数,Proxy.getProxyClass 生成class对象(文件存储在/com/sun/proxy);</p><ul><li>首先在缓存中寻找,没有则生成</li><li>会递归实现所有接口中包含的方法以及默认方法比如hashcode tostring equal等<br>然后获取构造器以invocationHandle的实现类invoke0作为参数产生实例Proxy0<br>proxy0的所有调用 调用invoke0.invoke,调用其实现的方法</li></ul></blockquote><p>AOP实现 基于JDK的实现(JdkDynamicAopProxy继承aopProxy,InvocationHandle;)</p><blockquote><p>利用JdkDynamicAopProxy 实现代理类class的生成<br>在newInstance中 invocationHandle的实例指向本身<br>JdkDynamicAopProxy 内部invoke实现中,</p><ul><li>会首先判断是常用方法比如toString hashcode Equal 或者没有增强方法就直接返回</li><li>如果有,会以方法为key 获取出 切入链条,然后调用(如何获得链条？<a href="https://my.oschina.net/u/3687664/blog/4267525" target="_blank" rel="noopener"></a> 从bean中遍历获取)</li></ul></blockquote><p><a href="https://my.oschina.net/u/3687664/blog/4267480" target="_blank" rel="noopener">Spring Bean的生命周期</a></p><h3 id="spring-mvc">Spring MVC</h3><h4 id="什么是spring-mvc-简单介绍下你对springmvc的理解">什么是Spring MVC ？简单介绍下你对springMVC的理解</h4><p>Spring MVC是一个基于Java的实现了MVC设计模式的请求驱动类型的轻量级Web框架，通过把Model，View，Controller分离，将web层进行职责解耦，把复杂的web应用分成逻辑清晰的几部分，简化开发，减少出错，方便组内开发人员之间的配合</p><h4 id="springmvc的流程">SpringMVC的流程？</h4><ul><li>用户发送请求至前端控制器DispatcherServlet；</li><li>DispatcherServlet收到请求后，调用HandlerMapping处理器映射器，请求获取Handle；</li><li>处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet；</li><li>DispatcherServlet 调用 HandlerAdapter处理器适配器；</li><li>HandlerAdapter 经过适配调用 具体处理器(Handler，也叫后端控制器)；</li><li>Handler执行完成返回ModelAndView；</li><li>HandlerAdapter将Handler执行结果ModelAndView返回给DispatcherServlet；</li><li>DispatcherServlet将ModelAndView传给ViewResolver视图解析器进行解析；</li><li>ViewResolver解析后返回具体View；</li><li>DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）</li><li>DispatcherServlet响应用户。</li></ul><h4 id="spring-mvc-的优点">spring mvc 的优点</h4><ul><li>清晰的角色分配：前端控制器(dispatcherServlet) , 请求到处理器映射（handlerMapping), 处理器适配器（HandlerAdapter), 视图解析器（ViewResolver）</li><li>与Spring框架集成（如IoC容器、AOP等）</li></ul><h4 id="spring-mvc-的主要组件">Spring MVC 的主要组件</h4><ul><li>前端控制器 DispatcherServlet(接收请求、响应结果，相当于转发器，有了DispatcherServlet 就减少了其它组件之间的耦合度)</li><li>处理器映射器HandlerMapping:根据请求的URL来查找Handler(根据RequestMapping注解获得url和handle的映射)</li><li>处理器适配器HandlerAdapter:在编写Handler的时候要按照HandlerAdapter要求的规则去编写，这样适配器HandlerAdapter才可以正确的去执行Handler</li></ul><blockquote><p>SpringMVC的Handler有多种实现方式（Controller，HttpRequestHandler，Servlet等），例如继承Controller接口的形式，基于注解@Controller控制器方式的，HttpRequestHandler方式的。由于实现方式不一样，调用方式就不确定</p></blockquote><ul><li>处理器Handler(Controller Bean)</li><li>视图解析器 ViewResolver:进行视图的解析，根据视图逻辑名解析成真正的视图（view）</li><li>视图View:View是一个接口， 它的实现类支持不同的视图类型（jsp，freemarker，pdf等等）</li></ul><h4 id="springmvc怎么样设定重定向和转发的">SpringMVC怎么样设定重定向和转发的？</h4><ul><li>转发：在返回值前面加&quot;forward:&quot;，譬如&quot;forward:user.do?name=method4&quot;</li><li>重定向：在返回值前面加&quot;redirect:&quot;，譬如&quot;redirect:<a href="http://www.baidu.com" target="_blank" rel="noopener">http://www.baidu.com</a>&quot;</li></ul><h4 id="springmvc怎么和ajax相互调用的">SpringMvc怎么和AJAX相互调用的？</h4><p>通过Jackson可以将json数据转化为Object,@RequestBody等</p><h4 id="springmvc的控制器是不是单例模式如果是有什么问题怎么解决">SpringMvc的控制器是不是单例模式,如果是,有什么问题,怎么解决？</h4><p>是单例模式,所以在多线程访问的时候有线程安全问题,不要用同步,会影响性能的,解决方案是在控制器里面不能写字段</p><h4 id="springmvc常用的注解有哪些">SpringMVC常用的注解有哪些？</h4><p>@RequestMapping：用于处理请求 url 映射的注解，可用于类或方法上。用于类上，则表示类中的所有响应请求的方法都是以该地址作为父路径。<br>@PathVariable<br>@RequestBody：注解实现接收http请求的json数据，将json转换为java对象。<br>@ResponseBody：注解实现将conreoller方法返回对象转化为json对象响应给客户。</p><h4 id="注解原理">注解原理：</h4><blockquote><p>注解本质是一个继承了Annotation的特殊接口，其具体实现类是Java运行时生成的动态代理类。我们通过反射获取注解时，返回的是Java运行时生成的动态代理对象。通过代理对象调用自定义注解的方法，会最终调用AnnotationInvocationHandler的invoke方法。该方法会从memberValues这个Map中索引出对应的值。而memberValues的来源是Java常量池</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Spring 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维</title>
      <link href="/2019/05/15/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%BF%90%E7%BB%B4/"/>
      <url>/2019/05/15/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%BF%90%E7%BB%B4/</url>
      
        <content type="html"><![CDATA[<p>为了测试整个系统的稳定性，写了一个脚本，模仿整个登录过程，中间出错就报错<br>了解到一个好工具 selenium<br><a href="https://blog.csdn.net/wkb342814892/article/details/81591394" target="_blank" rel="noopener">如何在centos上安装使用selenium-1</a><br><a href="https://www.bbsmax.com/A/A2dmRBKWze/" target="_blank" rel="noopener">如何在centos上安装使用selenium-2</a></p><p>为了更为精确的监控网页，考虑使用selenium模拟打开每个页面去检查其中网络请求是否正常获得，最终的目标是获取类似chrome开发者模式中Network中的效果，但是经调查发现，selenium中没有对这部分进行实现(或者与其最初目标无关，不考虑实现)，找到的可行的方案是使用 selenium + browsermob-proxy,<br><a href="https://browsermob-proxy-py.readthedocs.io/en/latest/" target="_blank" rel="noopener">browsermob-proxy 官方文档</a><br><a href="https://github.com/webmetrics/browsermob-proxy/downloads" target="_blank" rel="noopener">browsermob-proxy 下载</a></p><p><a href="https://stackoverflow.com/questions/48979520/chrome-headless-proxy-server" target="_blank" rel="noopener">示例代码</a></p><p>记录下中间遇到的问题：</p><blockquote><ol><li>端口冲突，报错</li></ol></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;use_for_temporary.py&quot;, line 160, in &lt;module&gt;</span><br><span class="line">    selenium_example()</span><br><span class="line">  File &quot;use_for_temporary.py&quot;, line 81, in selenium_example</span><br><span class="line">    proxy=server.create_proxy()</span><br><span class="line">  File &quot;/root/anaconda3/lib/python3.7/site-packages/browsermobproxy/server.py&quot;, line 40, in create_proxy</span><br><span class="line">    client = Client(self.url[7:], params)</span><br><span class="line">  File &quot;/root/anaconda3/lib/python3.7/site-packages/browsermobproxy/client.py&quot;, line 38, in __init__</span><br><span class="line">    self.port = jcontent[&apos;port&apos;]</span><br><span class="line">KeyError: &apos;port&apos;</span><br></pre></td></tr></table></figure><p>经过查看源码，大约猜测是网络端口的问题(后来发现在产生的server.log 中把问题说的很清楚 ( ╯□╰ ))，查看相关文档确定 browsermob-proxy 启动的端口默认是8080 <a href="https://cloud.tencent.com/developer/news/365789" target="_blank" rel="noopener">相关文档</a> ,而服务器中已经使用的端口包括这个，考虑更改其启动的配置参数，按照上述文档的方法下修改，无效报错，经过查看与browsermob-proxy 版本对应 的官方文档<a href="https://browsermob-proxy-py.readthedocs.io/en/latest/server.html" target="_blank" rel="noopener">Server 初始化</a> 以及相应解析源码，重新修改配置<br>为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server=Server(&quot;/root/download/browsermob-proxy-2.0-beta-6/bin/browsermob-proxy&quot;,&#123;&quot;host&quot;:&quot;localhost&quot;,&quot;port&quot;:9000&#125;)</span><br></pre></td></tr></table></figure><p>成功</p><blockquote><ol start="2"><li>文件引用问题</li></ol></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;use_for_temporary.py&quot;, line 159, in &lt;module&gt;</span><br><span class="line">    selenium_example()</span><br><span class="line">  File &quot;use_for_temporary.py&quot;, line 79, in selenium_example</span><br><span class="line">    server.start()</span><br><span class="line">  File &quot;/root/anaconda3/lib/python3.7/site-packages/browsermobproxy/server.py&quot;, line 122, in start</span><br><span class="line">    raise ProxyServerError(message)</span><br><span class="line">browsermobproxy.exceptions.ProxyServerError: The Browsermob-Proxy server process failed to start. Check &lt;_io.TextIOWrapper name=&apos;/root/py_auto/Gateway_auto/server.log&apos; mode=&apos;w&apos; encoding=&apos;UTF-8&apos;&gt;for a helpful error message.</span><br><span class="line"># server.log</span><br><span class="line">错误: 找不到或无法加载主类 org.browsermob.proxy.Main</span><br></pre></td></tr></table></figure><p>原因：我将browsermob-proxy解压后，将其中bin目录下browsermobproxy专门提取出来，放在一个专门目录下(以为是可执行文件)，引用之，后来发现它和windows下使用的browsermobproxy.bat 一样都是个脚本文件，需要在项目的固定位置<br>解决：将引用目录指向目录文件下的browsermobproxy</p><blockquote><ol start="3"><li>工具版本适配问题</li></ol></blockquote><p>问题：使用browsermob-proxy +selenium 时候，出现网络请求异常，在查看browsermob-proxy 产生的har记录文件时发现某些网路请求异常，返回-999(no response)或者0,不是正常的返回，但是单独用requests 模块去做请求时，又没有问题，于是考虑是因为webdriver结束过早，考虑过强制sleep,以及 driver.implict_wait(),但是都起不到作用，或者不够明显。<br>后来思考了下，我想要做的事情是判断页面是否加载正常，静态数据大多没有太多问题，主要是动态数据，即我所关注或者担心的大部属分请求都是ajax异步请求，前面那些方法可能没有太多作用，于是查找是否有有相关手段使selenium 等待所有ajax请求结束，其中提到了selenium的三种等待方式：强制等待(sleep等方法)，隐式等待(driver.implict_wait(),全局效果)，显式等待(在一定时间内等待某一元素的出现)<br>最终采取的是第三种方法，</p><blockquote><p>WebDriverWait(driver, 30).until(lambda s: s.execute_script(“return jQuery.active == 0”))</p></blockquote><p>参考<a href="https://www.cnblogs.com/aoyede/articles/5804184.html" target="_blank" rel="noopener">博客</a></p><p>但是在centos服务器上加上这行代码会出现<br>jQuery/$(如果使用 $.active)  no defined<br>最开始考虑类似与之前的方法，是因为这段脚本在jQuery加载之前执行引起的错误，后来尝试过强制等待后添加这行代码，无论等待多长时间都没有效果 ,开始怀疑是因为服务器环境的特殊性，于是在window笔记本,ubuntu台式机上尝试都没有异常，然后开始怀疑是环境配置的问题，其中包含的环境配置主要有selenium ,chromdriver,google-chrome,browsermob-proxy<br>由于selenium都是用pip安装的最新的，不考虑<br>然后发现centos服务器上的google-chrome是最新版76.0.3809.12   ,而windows上是75.0.3770.8，ubuntu上chromium是 v74.0.3729.6然后依据windowsde 配置调整了chromdriver,google-chrome的配置，但是仍然没有效果，最后发现centos 上的browsermob-proxy 是2.0-beta版本，而其他两个是2.14版本，最后调整之后，发现运行没有问题(暂时弄不明白为什么)<br>记录下正确的版本配置：<br>selenium: 3.141.0<br>chromdriver:75.0.3770.90<br>google-chrome: 75.0.3770.142<br>browsermob-proxy:2.1.4</p><blockquote><p>日志增长的问题</p></blockquote><p>考虑到网关日志增长过大的可能性，考虑到使用脚本定期定量切割日志,重命名，创建新文件，后来发现linux系统中有现成工具 logrotate 可以对日志进行切割，里面的配置完全可以满足个人需求<br>可以使用 man  logrotate 查看配置信息 或者  <a href="https://linux.die.net/man/8/logrotate" target="_blank" rel="noopener">logrotate Linxu 官网档案</a></p><blockquote><p>个人配置</p></blockquote><pre><code>位置：/etc/logrotate.d/kong<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/kong/logs/access.log &#123;</span><br><span class="line">    missingok</span><br><span class="line">    rotate 200</span><br><span class="line">    size 10M</span><br><span class="line">    compress</span><br><span class="line">    delaycompress</span><br><span class="line">    notifempty</span><br><span class="line">    create 644 root root</span><br><span class="line">    dateext</span><br><span class="line">    sharedscripts</span><br><span class="line">    postrotate</span><br><span class="line">            if [ -f /var/run/nginx.pid ]; then</span><br><span class="line">                    kill -USR1 `cat /usr/local/kong/pids/nginx.pid`</span><br><span class="line"></span><br><span class="line">            fi</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></code></pre><p>原本为 cat /var/run/nginx.pid 后来发现,kong的pid信息存放在/usr/local/kong/pids/nginx.pid<br>kill -USR1 在这里指重新加载配置信息，重新建立对日志文件的连接<br>详情 man kill/kill -l 或者查看 <a href="http://www.man7.org/linux/man-pages/man2/kill.2.html" target="_blank" rel="noopener">Linux kill 文档</a>  [Linux  signal 文档](<a href="http://www.man7.org/linux/man-pages/man7/signal.7.html" target="_blank" rel="noopener">http://www.man7.org/linux/man-pages/man7/signal.7.html</a></p><p>包装 elastisearch API接口，简化经网关转发提供给外部使用<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.0/index.html" target="_blank" rel="noopener">Elastisearch 官网开放API 文档</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">获取某一时间 ddj 服务的访问次数</span><br><span class="line">GET /_count</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">      &quot;bool&quot;:&#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">                &quot;range&quot;: &#123;</span><br><span class="line">                  &quot;@timestamp&quot;: &#123;</span><br><span class="line">                    &quot;gte&quot;: &quot;now-100h/h&quot;,</span><br><span class="line">                    &quot;lte&quot;: &quot;now/h&quot;,</span><br><span class="line">                    &quot;format&quot;: &quot;epoch_millis&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            ,</span><br><span class="line">        &quot;must&quot;: &#123;</span><br><span class="line">                &quot;match&quot;: &#123;</span><br><span class="line">                  &quot;request&quot;: &#123;</span><br><span class="line">                    &quot;query&quot;: &quot;*ddj*&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">获取某一时间 ddj 服务的访问信息，相比于上者更为详细</span><br><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">      &quot;bool&quot;:&#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">                &quot;range&quot;: &#123;</span><br><span class="line">                  &quot;@timestamp&quot;: &#123;</span><br><span class="line">                    &quot;gte&quot;: &quot;now-100h/h&quot;,</span><br><span class="line">                    &quot;lte&quot;: &quot;now/h&quot;,</span><br><span class="line">                    &quot;format&quot;: &quot;epoch_millis&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            ,</span><br><span class="line">        &quot;must&quot;: &#123;</span><br><span class="line">                &quot;match&quot;: &#123;</span><br><span class="line">                  &quot;request&quot;: &#123;</span><br><span class="line">                    &quot;query&quot;: &quot;*ddj*&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,&quot;aggs&quot;: &#123;</span><br><span class="line">            &quot;dateAgg&quot;: &#123;</span><br><span class="line">              &quot;date_histogram&quot;: &#123;</span><br><span class="line">                &quot;field&quot;: &quot;@timestamp&quot;,</span><br><span class="line">                &quot;time_zone&quot;: &quot;Europe/Amsterdam&quot;,</span><br><span class="line">                &quot;interval&quot;: &quot;1m&quot;,</span><br><span class="line">                &quot;min_doc_count&quot;: 1</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>本来想自己开发一个插件，似乎<a href="https://docs.konghq.com/hub/" target="_blank" rel="noopener">Kong Hub</a>上提供的第三方插件 <a href="https://docs.konghq.com/hub/stone-payments/kong-plugin-template-transformer/" target="_blank" rel="noopener">Template Transformer</a> 可以满足需要，<a href="https://github.com/stone-payments/kong-plugin-template-transformer" target="_blank" rel="noopener">源码</a>可以观摩下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST http://localhost:8001/routes/4f240596-9f55-4b90-a2be-2329be72391e/plugins --data &quot;name=kong-plugin-template-transformer&quot;   --data &quot;config.request_template=&apos; &#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">      &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">                &quot;range&quot;: &#123;</span><br><span class="line">                  &quot;@timestamp&quot;: &#123;</span><br><span class="line">                    &quot;gte&quot;: &quot;now-&#123;&#123;headers.gt&#125;&#125;h/h&quot;,</span><br><span class="line">                    &quot;lte&quot;: &quot;now/h&quot;,</span><br><span class="line">                    &quot;format&quot;: &quot;epoch_millis&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            ,</span><br><span class="line">        &quot;must&quot;: &#123;</span><br><span class="line">                &quot;match&quot;: &#123;</span><br><span class="line">                  &quot;request&quot;: &#123;</span><br><span class="line">                    &quot;query&quot;: &quot;*&#123;&#123;headers.department&#125;&#125;*&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&quot;</span><br><span class="line">&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;filter&quot;: &#123;&quot;range&quot;: &#123;&quot;@timestamp&quot;:&#123;&quot;gte&quot;: &quot;now-&#123;&#123;headers.gt&#125;&#125;h/h&quot;,&quot;lte&quot;: &quot;now/h&quot;,&quot;format&quot;: &quot;epoch_millis&quot;&#125;&#125;&#125;&#125;&#125;,&quot;size&quot;:0,&quot;aggs&quot;:&#123;&quot;test&quot;:&#123;&quot;terms&quot;:&#123; &quot;field&quot;: &quot;user.keyword&quot;,&quot;size&quot;:&#123;&#123;headers.size&#125;&#125;&#125;&#125;&#125;&#125;&quot;</span><br><span class="line">/api/v1/data/es/list_user</span><br><span class="line">curl -X POST http://localhost:8001/routes/&#123;route&#125;/plugins --data &quot;name=kong-plugin-template-transformer&quot;   --data</span><br><span class="line">&quot;config.request_template=&#123;</span><br><span class="line">      \&quot;query\&quot;: &#123;</span><br><span class="line">        \&quot;bool\&quot;: &#123;</span><br><span class="line">          \&quot;filter\&quot;: &#123;</span><br><span class="line">            \&quot;range\&quot;: &#123;</span><br><span class="line">              \&quot;@timestamp\&quot;: &#123;</span><br><span class="line">                \&quot;gte\&quot;: \&quot;now-&#123;&#123;headers.gt&#125;&#125;h/h\&quot;,</span><br><span class="line">                \&quot;lte\&quot;: \&quot;now/h\&quot;,</span><br><span class="line">                \&quot;format\&quot;: \&quot;epoch_millis\&quot;</span><br><span class="line">                &#125;</span><br><span class="line">               &#125;</span><br><span class="line">              &#125;</span><br><span class="line">             &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">      \&quot;size\&quot;:0,  </span><br><span class="line">      \&quot;aggs\&quot;: &#123;</span><br><span class="line">        \&quot;test\&quot;:&#123;</span><br><span class="line">          \&quot;terms\&quot;:&#123; </span><br><span class="line">          \&quot;field\&quot;: \&quot;user.keyword\&quot;,</span><br><span class="line">          \&quot;size\&quot;:&#123;&#123;headers.size&#125;&#125;</span><br><span class="line">          &#125; </span><br><span class="line">         &#125;  </span><br><span class="line">        &#125;</span><br><span class="line">      &#125;&quot;</span><br><span class="line"></span><br><span class="line">/api\/v1\/data\/es\/history</span><br><span class="line">curl -X POST http://localhost:8001/routes/&#123;route&#125;/plugins --data &quot;name=kong-plugin-template-transformer&quot;   --data</span><br><span class="line">&quot;config.request_template=&#123;</span><br><span class="line">  \&quot;size\&quot;: &#123;&#123;headers.size&#125;&#125;,</span><br><span class="line">  \&quot;query\&quot;: &#123;</span><br><span class="line">    \&quot;bool\&quot;: &#123;</span><br><span class="line">      \&quot;must\&quot;: [</span><br><span class="line">        &#123; \&quot;match\&quot;: &#123;  \&quot;user\&quot;: \&quot;&#123;&#123;headers.name&#125;&#125;\&quot;  &#125; &#125;, </span><br><span class="line">        &#123; \&quot;match\&quot;: &#123; \&quot;_index\&quot;:\&quot;system-syslog*\&quot; &#125; &#125;]    </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;,</span><br><span class="line">  \&quot;_source\&quot;: &#123;</span><br><span class="line">    \&quot;includes\&quot;: [\&quot;@timestamp\&quot;,\&quot;referer\&quot;,\&quot;request\&quot;,\&quot;user\&quot;]</span><br><span class="line">    &#125;,  </span><br><span class="line">  \&quot;sort\&quot;: [</span><br><span class="line">    &#123;\&quot;@timestamp\&quot;:&#123;\&quot;order\&quot;:\&quot;desc\&quot; ,\&quot;unmapped_type\&quot;:\&quot;date\&quot; &#125; &#125;,    </span><br><span class="line">    &#123;\&quot;_score\&quot;:&#123;\&quot;order\&quot;:\&quot;asc\&quot; &#125; &#125;  </span><br><span class="line">    ]</span><br><span class="line">    &#125;&quot;</span><br></pre></td></tr></table></figure><p>2019-9-24  更改为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST   --url http://localhost:8001/services/-search/routes  --data &apos;paths=/api/v1/data/es/history&apos;</span><br><span class="line">curl -X POST http://localhost:8001/routes/&#123;route_id&#125;/plugins --data &quot;name=kong-plugin-template-transformer&quot;   --data &quot;config.request_template=&#123;</span><br><span class="line">    \&quot;query\&quot;: &#123;</span><br><span class="line">      \&quot;bool\&quot;: &#123;</span><br><span class="line">      \&quot;filter\&quot;: &#123;</span><br><span class="line">                \&quot;range\&quot;: &#123;</span><br><span class="line">                  \&quot;@timestamp\&quot;: &#123;</span><br><span class="line">                    \&quot;gte\&quot;: \&quot;now-&#123;&#123;headers.gt&#125;&#125;h/h\&quot;,</span><br><span class="line">                    \&quot;lte\&quot;: \&quot;now/h\&quot;,</span><br><span class="line">                    \&quot;format\&quot;: \&quot;epoch_millis\&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            ,</span><br><span class="line">        \&quot;must\&quot;: &#123;</span><br><span class="line">                \&quot;match\&quot;: &#123;</span><br><span class="line">                  \&quot;request\&quot;: &#123;</span><br><span class="line">                    \&quot;query\&quot;: \&quot;*&#123;&#123;headers.department&#125;&#125;*\&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST   --url http://localhost:8001/services/-search/routes  --data &apos;paths=/api/v1/data/es/history&apos;</span><br><span class="line">&#123;</span><br><span class="line">  \&quot;size\&quot;: &#123;&#123;headers.size&#125;&#125;,</span><br><span class="line">  \&quot;query\&quot;: &#123;</span><br><span class="line">   \&quot;bool\&quot;: &#123;</span><br><span class="line">      \&quot;must\&quot;: [</span><br><span class="line">        &#123; \&quot;match\&quot;: &#123;  \&quot;user\&quot;: \&quot;&#123;&#123;headers.name&#125;&#125;\&quot;  &#125; &#125;,</span><br><span class="line">        &#123; \&quot;match\&quot;: &#123; \&quot;_index\&quot;:\&quot;system-syslog*\&quot; &#125; &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  \&quot;_source\&quot;: &#123;</span><br><span class="line">    \&quot;includes\&quot;: [</span><br><span class="line">     \&quot;@timestamp\&quot;,</span><br><span class="line">      \&quot;referer\&quot;,</span><br><span class="line">      \&quot;request\&quot;,</span><br><span class="line">      \&quot;user\&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  \&quot;sort\&quot;: [</span><br><span class="line">    &#123;\&quot;@timestamp\&quot;:&#123;\&quot;order\&quot;:\&quot;desc\&quot; ,\&quot;unmapped_type\&quot;:\&quot;date\&quot; &#125; &#125;,</span><br><span class="line">    &#123;\&quot;_score\&quot;:&#123;\&quot;order\&quot;:\&quot;asc\&quot; &#125; &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST   --url http://localhost:8001/services/-search/routes  --data &apos;paths=/api/v1/data/es/list_user&apos;</span><br><span class="line">curl -X POST http://localhost:8001/routes/ad0226f7-0877-4557-b81b-f30cd227cf61/plugins --data &quot;name=kong-plugin-template-transformer&quot;   --data &quot;config.request_template=&#123;</span><br><span class="line">    \&quot;query\&quot;: &#123;</span><br><span class="line">      \&quot;bool\&quot;: &#123;</span><br><span class="line">      \&quot;filter\&quot;: &#123;</span><br><span class="line">                \&quot;range\&quot;: &#123;</span><br><span class="line">                  \&quot;@timestamp\&quot;: &#123;</span><br><span class="line">                    \&quot;gte\&quot;: \&quot;now-&#123;&#123;headers.gt&#125;&#125;h/h\&quot;,</span><br><span class="line">                    \&quot;lte\&quot;: \&quot;now/h\&quot;,</span><br><span class="line">                    \&quot;format\&quot;: \&quot;epoch_millis\&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">  \&quot;size\&quot;:0,</span><br><span class="line">  \&quot;aggs\&quot;: &#123;</span><br><span class="line">    \&quot;test\&quot;: &#123;</span><br><span class="line">      \&quot;terms\&quot;: &#123;</span><br><span class="line">        \&quot;field\&quot;: \&quot;user.keyword\&quot;,</span><br><span class="line">        \&quot;size\&quot;:&#123;&#123;headers.size&#125;&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&quot;</span><br></pre></td></tr></table></figure><p>luarocks make<br>luarocks pack kong-plugin-myplugin 0.1.0-1<br>luarocks install kong-plugin-myplugin-0.1.0-1.all.rock<br>kong restart</p>]]></content>
      
      
      
        <tags>
            
            <tag> python,爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>authen_server</title>
      <link href="/2019/05/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/authen-server/"/>
      <url>/2019/05/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/authen-server/</url>
      
        <content type="html"><![CDATA[<p>2019-5-14 尝试将spring oauth server安装到 实验室服务器上（虽然是初版），做一下记录<br>如何用idea 打包 maven项目<br>‘’’<br>用idea中maven 打开项目，点击idea 右侧的 Maven Projects，<br>点击 LIfecycle -&gt; install -&gt; run maven build 即可<br>‘’’<br>之后 将该项目scp至服务器<br>使用 java -jar *.jar 运行<br>在运行时出现一些错误，如下</p><p>‘’’<br>2019-05-14 17:06:35.986 ERROR 1180706 — [ost-startStop-1] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Exception during pool initialization.</p><p>com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure</p><p>The last packet successfully received from the server was 199 milliseconds ago.  The last packet sent successfully to the server was 192 milliseconds ago.<br>at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.8.0_181]<br>at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[na:1.8.0_181]<br>…<br>…<br>… 154 common frames omitted<br>Caused by: java.security.cert.CertPathValidatorException: Path does not chain with any of the trust anchors<br>at sun.security.provider.certpath.PKIXCertPathValidator.validate(PKIXCertPathValidator.java:154) ~[na:1.8.0_181]<br>at sun.security.provider.certpath.PKIXCertPathValidator.engineValidate(PKIXCertPathValidator.java:80) ~[na:1.8.0_181]<br>at java.security.cert.CertPathValidator.validate(CertPathValidator.java:292) ~[na:1.8.0_181]<br>at com.mysql.jdbc.ExportControlled$X509TrustManagerWrapper.checkServerTrusted(ExportControlled.java:295) ~[mysql-connector-java-5.1.46.jar!/:5.1.46]<br>… 156 common frames omitted</p><p>‘’’<br>经查询(<a href="https://www.jianshu.com/p/b3151ca89def" target="_blank" rel="noopener">https://www.jianshu.com/p/b3151ca89def</a> ）发现是因为SSL配置的原因（暂时没有细究），在源代码 application.yml 文件中将useSSL=true 改为 false即可，重新打包，scp，运行</p><p>在查询过程中发现之后可能会出现的另一个问题，即在长时间未连接mysql时会报类似的 Communications link failure 错误，不过这里是因为mysql默认配置 无连接最长等待时间是8小时，可以通过修改配置文件 mysql.ini 去解决这个错误</p><p>在此之前需要在服务器安装mysql<br>按照官网教程(下面的是Ubuntu下的，如果安装在redhat上，会有一些区别 ，具体参照官方教程 <a href="https://dev.mysql.com/doc/mysql-yum-repo-quick-guide/en/" target="_blank" rel="noopener">https://dev.mysql.com/doc/mysql-yum-repo-quick-guide/en/</a>)</p><ul><li>wget <a href="https://dev.mysql.com/get/mysql-apt-config_0.8.13-1_all.deb" target="_blank" rel="noopener">https://dev.mysql.com/get/mysql-apt-config_0.8.13-1_all.deb</a></li><li>也可以选择检查 文件传输中是否出错 md5sum mysql-apt-config_0.8.13-1_all.deb</li><li>之后运行 dpkg -i mysql-apt-config_0.8.13-1_all.deb，选择你所需要安装的mysql版本，程序会将之添加到apt源中</li><li>运行 sudo apt-get update （–fix-missing）</li><li>自动下载之后需要配置用户名与密码，需要与你在spring程序中配置的一致</li></ul><p>进入数据库 mysql -u root -p ,之后输入密码</p>]]></content>
      
      
      
        <tags>
            
            <tag> oauth </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Machine_learning_course</title>
      <link href="/2019/05/01/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Machine_learning_course/"/>
      <url>/2019/05/01/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Machine_learning_course/</url>
      
        <content type="html"><![CDATA[<p>2019-5-10<br>机器学习布置作业，6-15前交，内容未知<br>基于主成分分析方法的人脸识别方法</p><ul><li>之前是寻找空间特征，某一局部点</li><li>人脸识别的核心问题是提取特征(人脸的相关性打，冗余信息多？如何去除：主成分分析，如何将一个矩阵变成一个向量)</li><li>PCA方法的优缺点：从压缩能量的角度，PCA是最有效率的，可以用于维度压缩</li><li>PCA  FisherDiscriminant analysis or LDA</li><li>kErnel PCA</li><li>KFDA</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP</title>
      <link href="/2019/04/28/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP/"/>
      <url>/2019/04/28/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP/</url>
      
        <content type="html"><![CDATA[<p>2019-4-28 周日下午<br>NLP aligment</p>]]></content>
      
      
      
        <tags>
            
            <tag> 自然语言处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人脸识别</title>
      <link href="/2019/04/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"/>
      <url>/2019/04/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p>PCA方法学习：解释得比较清楚<br><a href="https://blog.csdn.net/qq_32865355/article/details/80809835" target="_blank" rel="noopener">https://blog.csdn.net/qq_32865355/article/details/80809835</a></p><p>github 开源方案<br><a href="https://github.com/ahhda/Face-Recogntion" target="_blank" rel="noopener">https://github.com/ahhda/Face-Recogntion</a><br><a href="https://github.com/ageitgey/face_recognition" target="_blank" rel="noopener">https://github.com/ageitgey/face_recognition</a></p><p>相关论文<br><a href="https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/83155487" target="_blank" rel="noopener">https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/83155487</a></p><p>CNN 实现 人脸识别<br><a href="https://blog.csdn.net/u012162613/article/details/43277187" target="_blank" rel="noopener">https://blog.csdn.net/u012162613/article/details/43277187</a><br><a href="https://blog.csdn.net/zouxy09/article/details/8781543" target="_blank" rel="noopener">https://blog.csdn.net/zouxy09/article/details/8781543</a></p><p>相关github 代码<br><a href="https://github.com/wepe/MachineLearning" target="_blank" rel="noopener">https://github.com/wepe/MachineLearning</a></p><p>faceCascade.detectMultiScale 从图像中找出人脸<br>theano.shared可以看作是将变量设置为全局变量，其值可以在多个函数中共用<br>theano.tensor.dot(X, Y) 简单的看做XY 矩阵相乘 或者说 内积<br>maxpooling 、average_pooling ？？</p><p>tensor库函数解释<br><a href="http://deeplearning.net/software/theano/library/tensor/basic.html" target="_blank" rel="noopener">http://deeplearning.net/software/theano/library/tensor/basic.html</a></p><p>损失函数的分类（交叉熵） <a href="https://www.jianshu.com/p/47172eb86b39" target="_blank" rel="noopener">https://www.jianshu.com/p/47172eb86b39</a></p><p>神经网络 数学公式 表达 <a href="https://blog.csdn.net/sinat_35821976/article/details/80615612" target="_blank" rel="noopener">https://blog.csdn.net/sinat_35821976/article/details/80615612</a></p><p>分类器用的是softmax  <a href="https://www.cnblogs.com/python-frog/p/9380290.html" target="_blank" rel="noopener">https://www.cnblogs.com/python-frog/p/9380290.html</a><br>，LeNet5用的是rbf？？</p>]]></content>
      
      
      
        <tags>
            
            <tag> 模式识别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树</title>
      <link href="/2019/04/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
      <url>/2019/04/27/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<p>今天上课提及了决策树，随机森林，Dropout，Deepforest(周志华)<br>目前而言，决策树指对于一个集合，依此以某种确定特征作为分类标准，从而将该集合分为若干类(每个节点都代表一个分类或者一种决策标准)<br>随机森林，指在每个节点，随机选择某个特征从而构建一个线性分类器，将样本分为几部分</p><p>Boosted Cascades VS 随机森林<br>前者是一个不平衡的树，适合不均匀的分类问题</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>slice_window</title>
      <link href="/2019/04/23/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/slide_window/"/>
      <url>/2019/04/23/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/slide_window/</url>
      
        <content type="html"><![CDATA[<p>返回滑动窗口的最大值(考虑极端情况起码考虑 空 )<br>给定一个输入序列（数组)，返回窗口范围内的最大值，每次移动一次窗口，并返回一个最大值</p><ul><li>方法1：大顶堆（MaxHeap）  删除离开的元素，加入新的元素，排序  时间复杂度<br>$$ N log^{k} $$</li><li>deque(双端 Queue)</li><li>–入队列</li><li>–维护队列：对于长度为K 的窗口，将窗口范围内最大值之前的数全部删除（忽略），因为在最大值之前的数必然不会成为最大值</li></ul><ul>  <li>JavaScript    <ol>      <li>        第一章        <ul>          <li>const</li>          <li>let</li>        </ul>      </li>      <li>        第二章sdisjfosdklsjfkdddddldddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd        <ul>          <li>function</li>          <li>object</li>        </ul>      </li>    </ol>  </li>  <li>Java    <ol>      <li>        第一章        <ul>          <li>class</li>          <li>package</li>        </ul>      </li>      <li>        第二章        <ul>          <li>private</li>          <li>public</li>        </ul>      </li>    </ol>  </li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>map_and_set</title>
      <link href="/2019/04/23/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/map_and_set/"/>
      <url>/2019/04/23/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/map_and_set/</url>
      
        <content type="html"><![CDATA[<p>哈希函数，哈希表，哈希碰撞(单个节点变成链表来解决：拉链法)<br>List VS Map VS Set</p><ul><li>List：由数组或者链表实现，插入O(1)，查找O(N)，可重复</li><li>Map ：键值对Key-value</li><li>Set :用哈希表或者二叉树实现；相对于List不允许重复</li></ul><p>HashMap VS TreeMap<br>HashSet VS TreeSet<br>在查询时，哈希表实现 O(1) ，Tree实现 O(log_{n})<br>但是 哈希表的实现是无序的，而树的实现是有序的</p><p>题目：242（Leetcode） Valid Anagrant<br>题意：对给定的两个字符串，判断是否是同一单词的错位变换</p><ul><li>方法1：给两个字符串排序，判断是否相同 算法复杂度 ：<br>$$ O(Nlog^N) $$</li><li>方法2：构造Map，比较Map是否相同算法复杂度<br>$$ O(N) $$</li></ul><p>题目：Two Sum(Three Sum)<br>题意：给定一个数组，以及value，输出数组中和为value的元素下标</p><ul><li>方法1：暴力方法时间复杂度<br>$$<br>O(N^2)<br>$$</li><li>方法2：Set;对于数组的任意元素x，如果元素 value-x 存在，则输出 时间复杂度<br>$$<br>O(N)<br>$$</li></ul><p>那么对于ThreeSum</p><ul><li>方法1：暴力 时间复杂度<br>$$<br>O(N^3)<br>$$</li><li>方法2：枚举a+b,在Set里查询c 时间复杂度<br>$$<br>O(N^2)<br>$$</li><li>方法3：首先排序，枚举a,在剩下的子数组中，b和c各位于最左和最右，根据a+b+c&gt;0/&lt;0 ,来判断移动b或者c 虽然空间复杂度是常数级别的，但修改了原数组 ，时间复杂度<br>$$<br>O(N^2)<br>$$</li><li>方法4：应用ThreeSum的方法,递归(4=1+3;3=1+2) 时间复杂度<br>$$<br>O(N^2)<br>$$</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>小技巧总结</title>
      <link href="/2019/04/22/%E5%B7%A5%E5%85%B7/%E5%B0%8F%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"/>
      <url>/2019/04/22/%E5%B7%A5%E5%85%B7/%E5%B0%8F%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>1.git commit 由于没有添加 -m 而进入 vim界面，无法退出，在一个博文找到方法（<a href="https://blog.csdn.net/weixin_42197191/article/details/87015837%EF%BC%89" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42197191/article/details/87015837）</a><br>Ctrl + v + 命令键 实现命令</p><p>2.由于两个电脑同时修改自己的blog markdown文件，导致文件有差异，如何解决，暂时没有找到思路，将某一个电脑的master回退，会导致他的修改丢失（或者提前保存其修改，或许这就是多分支存在的理由）<br>git log 查看最近commit的记录<br>git reset --hard (HEAD～n)/(commit_id)   会退到当前(之前的n个提交记录)/(在git log 中的某个提交记录)<br>git push --force 将当前分支提交<br>it branch --set-upstream-to=<remote origin>/<remote branch> <local branch>  绑定当前本地分支与某个远程分支</local></remote></remote></p><ol start="3"><li>获得 包含某个字符串的进程ID 并且将之作为参数，删除相应进程<br>kill -9 $(ps -ef|grep id | grep -v grep|awk ‘{print $2}’ )。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>manacher</title>
      <link href="/2019/04/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/manacher/"/>
      <url>/2019/04/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/manacher/</url>
      
        <content type="html"><![CDATA[<p>马拉车算法，解决最大回文串问题，有点意思，感觉有点像KMP算法</p>]]></content>
      
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代理</title>
      <link href="/2019/04/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E4%BB%A3%E7%90%86/"/>
      <url>/2019/04/22/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>代理给通信带来更多的功能</p><ul><li>拦截：代理可以选择性拦截传输的网络流量，比如一些公司限制员工在上班的时候不能访问某些游戏或者电商网站，再比如把我们和世界隔离开来的 GFW，还有在数据中心中拒绝恶意访问的网关。</li><li>统计：既然所有的流量都经过代理，那么代理也可以用来统计网络中的数据信息，比如了解哪些人在访问哪些网站，通信的应答延迟等。</li><li>缓存：如果通信双方比较”远“，访问比较慢，那么代理可以把最近访问的数据缓存在本地，后面的访问不用访问后端来做到加速。CDN 就是这个功能的典型场景。</li><li>分发(负载均衡)：如果某个通信方有多个服务器后端，代理可以根据某些规则来选择如何把流量发送给多个服务器，也就是我们常说的负载均衡功能，比如著名的 Nginx 软件。</li><li>跳板：如果 A、B 双方因为某些原因不能直接访问，而代理可以和双方通信，那么通过代理，双方可以绕过原来的限制进行通信。VPN，内网穿透。</li><li>注入：既然代理可以看到流量，那么它也可以修改网络流量，可以自动在收到的流量中添加一些数据，比如有些宽带提供商的弹窗广告。</li></ul><p>ssr速度不行安装v2ray<br>参考<a href="https://www.stackcc.com/2019/04/02/v2raysetup/" target="_blank" rel="noopener">网站1</a><a href="https://tlanyan.me/v2ray-tutorial/" target="_blank" rel="noopener">网站2</a><br><a href="https://www.hijk.pw/v2rayn-config-tutorial/" target="_blank" rel="noopener">网站3</a></p><p><a href="https://www.v2rayssr.com/v2raynginx.html" target="_blank" rel="noopener">V2RAY+Nginx+Ws+Tls+Host+Path</a></p><ol><li>域名购买：<a href="https://dcc.godaddy.com/" target="_blank" rel="noopener">狗爹</a><br>[godaddy 域名解析]whetstone.xyz</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">yum install -y socat</span><br><span class="line">curl  https://get.acme.sh | sh</span><br><span class="line">source ~/.bashrc</span><br><span class="line">export CF_Token=&quot;Wl6tf8wsQ1wFCOowI4tdCetZLE68eaZ3aJaGR0cm&quot;</span><br><span class="line"></span><br><span class="line">acme.sh --issue --dns dns_cf -d whetstone.xyz -d www.whetstone.xyz -k ec-256</span><br><span class="line">cat ~/.acme.sh/whetstone.xyz_ecc/fullchain.cer &gt; /etc/nginx/ssl/whetstone.xyz.crt</span><br><span class="line">cat ~/.acme.sh/whetstone.xyz_ecc/whetstone.xyz.key &gt; /etc/nginx/ssl/whetstone.xyz.key</span><br><span class="line">systemctl start nginx</span><br><span class="line">acme.sh --installcert -d whetstone.xyz -d www.whetstone.xyz --fullchainpath /etc/nginx/ssl/whetstone.xyz.crt --keypath /etc/nginx/ssl/whetstone.xyz.key --ecc --reloadcmd &quot;systemctl reload nginx&quot;</span><br></pre></td></tr></table></figure><p>更换vltur服务器,重新安装遇到的问题</p><ol><li>域名解析失败,523</li></ol><blockquote><p>新服务器防火墙屏蔽了一些端口</p></blockquote><ol start="2"><li>直接使用ip/TCP成功,使用websocket/域名伪装失败</li></ol><blockquote><p>初步定为在nginx问题,尝试过很多方法,未能精确定位错误原因,可能是ws伪装仍然发出http请求,而nginx未配置http强转https导致无法命中</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Microservice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注解</title>
      <link href="/2019/04/20/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E6%B3%A8%E8%A7%A3/"/>
      <url>/2019/04/20/%E5%B7%A5%E4%BD%9C%E6%B1%82%E8%81%8C/%E6%B3%A8%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="元注解">元注解</h2><blockquote><p>可以用于修饰注解的注解,称之为元注解</p></blockquote><p>@Retention(RetentionPolicy.VALUE)</p><blockquote><p>确定所修饰注解的生命周期范围</p></blockquote><ul><li>@Retention(RetentionPolicy.CLASS)修饰的注解，表示注解的信息被保留在class文件(字节码文件)中当程序编译时，但不会被虚拟机读取在运行的时候；</li><li>@Retention(RetentionPolicy.SOURCE )修饰的注解,表示注解的信息会被编译器抛弃，不会留在class文件中，注解的信息只会留在源文件中；</li><li>@Retention(RetentionPolicy.RUNTIME )修饰的注解，表示注解的信息被保留在class文件(字节码文件)中当程序编译时，会被虚拟机保留在运行时，所以他们可以用反射的方式读取。RetentionPolicy.RUNTIME 可以让你从JVM中读取Annotation注解的信息，以便在分析程序的时候使用.</li></ul><p>@Traget({ElementType.VALUE,… })</p><blockquote><p>确定所修饰的注解 修饰的对象范围</p></blockquote><ul><li>ElementType.CONSTRUCTOR:用于描述构造器</li><li>ElementType.FIELD:用于描述域</li><li>ElementType.LOCAL_VARIABLE:用于描述局部变量</li><li>ElementType.METHOD:用于描述方法</li><li>ElementType.PACKAGE:用于描述包</li><li>ElementType.PARAMETER:用于描述参数</li><li>ElementType.TYPE:用于描述类、接口(包括注解类型) 或enum声明</li></ul><p>@Bean<br>(@Set @Get)</p><p>@AutoWire<br>public class cla/public void set(class cla)</p><ul><li>自动装配即是，让spring自动满足bean依赖的一种方法，在满足依赖的过程中，会在spring的上下文中匹配某个bean需要的bean;@AutoWire可以注解方法或者变量</li></ul><p>@Component(“name”)</p><ul><li>目前的了解是，加上该注解，就无需告知spring为该类创建Bean;如果有括号，并将该Bean ID标识（命名）为里面的字符串</li></ul><p>@Name</p><ul><li>spring 支持其代替 @Component ，唔，但不了解</li></ul><p>@ComponentScan<br>@ComponentScan(“name”)<br>@ComponentScan(basePackages=“name”/{“name”,“name1”})</p><ol><li>注解:在spring里开启组件扫描，默认扫描与配置类相同的包，扫描所在包以及子包中所有带有@Component注解的类</li><li>注解:指明基础包，可以指明多个基础包</li></ol><p>@ContextConfiguration(classes=*.class)</p><ul><li>从指明的class里加载配置</li></ul><p>@interface</p><blockquote><p>@interface Annotation{ } 定义一个注解 @Annotation，一个注解是一个类</p></blockquote><p>@Pointcut(表达式)</p><blockquote><p>Pointcut表示式(expression)和Pointcut签名(signature),signature 可用于 需要的注解找到该pointcut<br>//Pointcut表示式<br>@Pointcut(“execution(* com.savage.aop.MessageSender.*(…))”)<br>//Point签名<br>private void log(){}</p></blockquote><p>Pointcut 表达式</p><ul><li>execution：用于匹配方法执行的连接点；</li><li>within：用于匹配指定类型内的方法执行；</li><li>this：用于匹配当前AOP代理对象类型的执行方法；注意是AOP代理对象的类型匹配，这样就可能包括引入接口也类型匹配；</li><li>target：用于匹配当前目标对象类型的执行方法；注意是目标对象的类型匹配，这样就不包括引入接口也类型匹配；</li><li>args：用于匹配当前执行的方法传入的参数为指定类型的执行方法；</li><li>@within：用于匹配所以持有指定注解类型内的方法；</li><li>@target：用于匹配当前目标对象类型的执行方法，其中目标对象持有指定的注解；</li><li>@args：用于匹配当前执行的方法传入的参数持有指定注解的执行；</li><li>@annotation：用于匹配当前执行方法持有指定注解的方法；</li></ul><blockquote><p>execution 表达式<br>@Pointcut(execution(modifiers-pattern? ret-type-pattern declaring-type-pattern? name-pattern(param-pattern)throws-pattern?) )</p></blockquote><ul><li>修饰符匹配（modifier-pattern?）:public/private</li><li>返回值匹配（ret-type-pattern）可以为*表示任何返回值,全路径的类名等</li><li>类路径匹配（declaring-type-pattern?）</li><li>方法名匹配（name-pattern）可以指定方法名 或者 <em>代表所有, set</em> 代表以set开头的所有方法</li><li>参数匹配（(param-pattern)）可以指定具体的参数类型，多个参数间用“,”隔开，各个参数也可以用“<em>”来表示匹配任意类型的参数，如(String)表示匹配一个String参数的方法；(</em>,String) 表示匹配有两个参数的方法，第一个参数可以是任意类型，而第二个参数是String类型；可以用(…)表示零个或多个任意参数</li><li>异常类型匹配（throws-pattern?）</li><li>其中后面跟着“?”的是可选项</li></ul><p>2019-6-27 更新<br>今天在给spring 添加新restful接口时，发现无法访问；最后发现，接口如果不设置访问方法。默认访问方式是GET，奇怪的是，如果设置为POST方式，那么将无法访问，重定位回登录页面？？</p><p>在学习微服务构建时，需要看java代码，看到注解 时十分迷惑，暂时没有自己的见解<br>但是 这边博客说的不错<br><a href="https://blog.csdn.net/briblue/article/details/73824058" target="_blank" rel="noopener">https://blog.csdn.net/briblue/article/details/73824058</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Java 工作求职 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>stack+queue</title>
      <link href="/2019/04/15/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/stack-queue/"/>
      <url>/2019/04/15/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/stack-queue/</url>
      
        <content type="html"><![CDATA[<p>##stack：<br>先进后出；有压栈，出栈等操作<br>算法题：判断输入字符创是否符合规范，比如“【（）】”和“【（{”，利用栈去做比较好（需要存储正确对应的Map，比如 map={&quot;{&quot;:&quot;}&quot;}）,还可以选择重复循环消除“{}”、“（）”、“【】”等组合</p><p>##Queue：<br>先进先出；</p><p>如何用stack实现queue 以及如何使用Queue 实现stack<br>思路：负负得正；两个stack实现 Queue<br>利用两个栈的之间的元素的转移，实现元素顺序的反转</p><p>##Priority Queue<br>正常进入，按照优先级出<br>实现机制：Heap（二叉堆、多项式堆、斐波拉契堆）、二叉搜索树</p>]]></content>
      
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linked_list</title>
      <link href="/2019/04/12/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/linked-list/"/>
      <url>/2019/04/12/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/linked-list/</url>
      
        <content type="html"><![CDATA[<p>链表相关问题<br>双链表 反转<br>链表交换相邻元素<br>判断链表是否有环</p><ul><li>暴力遍历，如果陷入循环中，那么永远无法结束（设置时间1s即可）</li><li>利用多余的数据结构判断是否经过同一个节点</li><li>快慢指针</li></ul><p>$$  \frac{1}{1+sin(x)}   $$</p>]]></content>
      
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>island_count</title>
      <link href="/2019/04/11/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/island-count/"/>
      <url>/2019/04/11/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/island-count/</url>
      
        <content type="html"><![CDATA[<p>算法体：被河流围的若干岛屿分别用0和1表示，求岛屿个数以及可能的岛屿面积<br>第一种方法：染色（我更愿意理解为聚类删除）<br>即找到每一个1身边所有的1并将之删除（这符合岛屿的规定，即由1连在一起的集合），可以使用DFS或者BFS来进行删除<br>第二种方法：并查集<br>遍历数组，对于第一个遇到的1 ，将之作为队长，由此BFS/DFS建立 建立并查集，将同一个岛屿的1属于同一个集合；</p><p>应用：朋友圈</p>]]></content>
      
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bullon_filter</title>
      <link href="/2019/04/11/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/bullon-filter/"/>
      <url>/2019/04/11/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/bullon-filter/</url>
      
        <content type="html"><![CDATA[<p>极客时间<br>哈希函数：将key隐射到一维数组的特殊位置（很少有错）<br>即使有错也可以 采取二维数组，减小错误率<br>类似于 计算机组成原理 内存与cache映射 中 组相联（还有直接隐射，全相联）</p><p>布隆过滤器：将key分解为若干元素组成，比如说连续的二进制<br>每输入一个key，将相应二进制位赋值为1，由此可以简单的判断不在，但是不能确定是否在，需要进一步判断（比如到后面数据库再核实）</p>]]></content>
      
      
      
        <tags>
            
            <tag> algrithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nlp-2019-4-5</title>
      <link href="/2019/04/06/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/nlp-2019-4-5/"/>
      <url>/2019/04/06/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/nlp-2019-4-5/</url>
      
        <content type="html"><![CDATA[<p>隐藏马尔科夫模型<br>EM算法 （迭代计算）</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>machine_learning_website</title>
      <link href="/2019/03/31/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/machine-learning-website/"/>
      <url>/2019/03/31/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/machine-learning-website/</url>
      
        <content type="html"><![CDATA[<p>上机器学习课程时候，检索的网站，备注一下，以后需要学习<br><a href="https://blog.csdn.net/qq_33273962/article/details/83547342" target="_blank" rel="noopener">https://blog.csdn.net/qq_33273962/article/details/83547342</a></p><p><a href="https://www.cnblogs.com/baiting/p/6101981.html" target="_blank" rel="noopener">https://www.cnblogs.com/baiting/p/6101981.html</a></p><p><a href="https://m.leiphone.com/news/201902/biIqSBpehsaXFwpN.html?uniqueCode=OTEsp9649VqJfUcO" target="_blank" rel="noopener">https://m.leiphone.com/news/201902/biIqSBpehsaXFwpN.html?uniqueCode=OTEsp9649VqJfUcO</a></p><p><a href="https://blog.csdn.net/u014665013/article/details/78970184" target="_blank" rel="noopener">https://blog.csdn.net/u014665013/article/details/78970184</a></p><p><a href="https://m.baidu.com/from=1019471a/s?word=k+s+%E6%A3%80%E9%AA%8C++%E6%8B%9F%E5%90%88&amp;sa=bb&amp;ts=8918111&amp;t_kt=0&amp;ie=utf-8&amp;rsv_t=9789dDDxyBbDgg8gANiHbFLNiH9iyPv%252FBZ08a7iihLsR2SpKsNsS0G5sZ3o5A14&amp;rsv_pq=8183285748722183729&amp;ss=110&amp;tj=1&amp;rqlang=zh&amp;rsv_sug4=7460&amp;inputT=334&amp;oq=k%2Bs%2B%E6%A3%80%E9%AA%8C" target="_blank" rel="noopener">https://m.baidu.com/from=1019471a/s?word=k+s+检验++拟合&amp;sa=bb&amp;ts=8918111&amp;t_kt=0&amp;ie=utf-8&amp;rsv_t=9789dDDxyBbDgg8gANiHbFLNiH9iyPv%2FBZ08a7iihLsR2SpKsNsS0G5sZ3o5A14&amp;rsv_pq=8183285748722183729&amp;ss=110&amp;tj=1&amp;rqlang=zh&amp;rsv_sug4=7460&amp;inputT=334&amp;oq=k%2Bs%2B检验</a></p><p><a href="https://www.cnblogs.com/yunfeifei/p/4019504.html" target="_blank" rel="noopener">https://www.cnblogs.com/yunfeifei/p/4019504.html</a></p><p><a href="https://blog.csdn.net/qq_42686550/article/details/81514233" target="_blank" rel="noopener">https://blog.csdn.net/qq_42686550/article/details/81514233</a></p><p><a href="https://www.cnblogs.com/zackstang/p/8232921.html" target="_blank" rel="noopener">https://www.cnblogs.com/zackstang/p/8232921.html</a></p><p><a href="https://www.cnblogs.com/lianyingteng/p/7755545.html" target="_blank" rel="noopener">https://www.cnblogs.com/lianyingteng/p/7755545.html</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>log_read</title>
      <link href="/2019/03/29/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/log-read/"/>
      <url>/2019/03/29/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/log-read/</url>
      
        <content type="html"><![CDATA[<p>今天搭建对于kong log读取的系统，来源与师兄的经验，一些坑就可以避免了<br>这套系统由4部分组成</p><p>Logstash是一个开元数据收集引擎，具备实时管道功能；Logstash可以动态的将俩字不同来源的数据统一起来，并将数据标准化至你所选择的目的地。这里我们选择的Elasricearch</p><p>Elastricearch 是一个分布式可扩展的实时搜索的分析引擎，一个建立在全文搜索引擎Apache Lucene 基础上的搜索引擎，Elastricsearch 不仅包括全文搜索功能，还可以进行</p><ul><li>分布式实时文件存储，将每一个字段都编入索引，使之可以被搜索</li><li>实时分析的分布式搜索引擎</li><li>可以扩展到上百台服务器上，处理PB级别的结果或者非结构化数据</li></ul><p>FIleBeat  是一个日志文件托运工具，在服务器安装客户端后，FIlebeat可以监控日志目录或者指定的日志文件，追踪读取这些文件（追踪文件的变化，不停的读），并且转发这些信息到elasticsearch或者logstarsh中存放。</p><p>Metricbeat可以定期收集操作系统和服务器的运行指标（CPU，内存，硬盘，IO,读写速度，进程等等），Metricbeat可以将收集到的指标和数据发送到你指定的输出，比如：elasticsearch，最终达成监视服务器的目标。</p><p>Kibana是一个开源的分析和可视化平台，设计用于和Elasticsearch一起工作。你用Kibana来搜索，查看，并和存储在Elasticsearch索引中的数据进行交互。你可以轻松地执行高级数据分析，并且以各种图标、表格和地图的形式可视化数据。Kibana使得理解大量数据变得很容易。它简单的、基于浏览器的界面使你能够快速创建和共享动态仪表板，实时显示Elasticsearch查询的变化。</p><p>在安装的过程中，踩了一些坑，备注一下</p><p><font size="6">kong</font></p><p>Log format</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">log_format json_log escape=json &apos;&#123; &quot;@timestamp&quot;: &quot;$time_iso8601&quot;, &apos;  &apos;&quot;remote_addr&quot;: &quot;$remote_addr&quot;, &apos;  &apos;&quot;referer&quot;: &quot;$http_referer&quot;, &apos;  &apos;&quot;request&quot;: &quot;$request&quot;, &apos;  &apos;&quot;status&quot;: $status, &apos;  &apos;&quot;bytes&quot;:$body_bytes_sent, &apos;  &apos;&quot;agent&quot;: &quot;$http_user_agent&quot;, &apos;  &apos;&quot;user&quot;: &quot;$http_username&quot;, &apos; &apos;&quot;x_forwarded&quot;: &quot;$http_x_forwarded_for&quot;, &apos;  &apos;&quot;upstr_addr&quot;: &quot;$upstream_addr&quot;,&apos;  &apos;&quot;upstr_host&quot;: &quot;$upstream_http_host&quot;,&apos;  &apos;&quot;ups_resp_time&quot;: &quot;$upstream_response_time&quot; &#125;&apos;;</span><br><span class="line">access_log logs/access.log json_log;</span><br></pre></td></tr></table></figure><p>在配置logstash时，配置数据输入为json ；之后配置filebeat 时同样配置输入json格式数据，之后出现乱码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">syslog &#123;</span><br><span class="line">     type =&gt; &quot;logs&quot;</span><br><span class="line">     port =&gt; 9044</span><br><span class="line">       &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>之后出现乱码，例如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;message&quot; =&gt; &quot;%P\\u001A(%\\xBDi\\t\\x83,\\u001FϘ\\xF5H\\x8E$ofw\\x98\\x9F\\xDD\\xFB\\\&quot;&#123;f7\\x9B\\r%W\\u0003\\x9A\\xE3\\xA3\\xF3\\u&#123;7CBF2&#125;\\xDFnnn\\xBE\\xBB\\xB9\\xF9\\xFE\\xDF\\u0013\\xBC&gt;`P\\x9D\\n&quot;,</span><br></pre></td></tr></table></figure><p>错误提示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[0] &quot;_grokparsefailure_sysloginput&quot;,</span><br><span class="line">[1] &quot;_jsonparsefailure&quot;</span><br><span class="line">An unexpected error occurred! &#123;:error=&gt;#&lt;Errno::EBADF: Bad file descriptor - Bad file descriptor&gt;, :backtrace=&gt;[&quot;org/jruby/RubyIO.java:3565:in `each&apos;&quot;, &quot;/home/LAB/chengr/ELK/logstash-5.6.3/vendor/bundle/jruby/1.9/gems/logstash-input-syslog-3.2.2/lib/logstash/inputs/syslog.rb:182:in `tcp_receiver&apos;&quot;, &quot;/home/LAB/chengr/ELK/logstash-5.6.3/vendor/bundle/jruby/1.9/gems/logstash-input-syslog-3.2.2/lib/logstash/inputs/syslog.rb:167:in `tcp_listener&apos;&quot;]&#125;</span><br></pre></td></tr></table></figure><p>本来以为是因为 配置filebeat时，对于json输入的配置与logstash的配置出现冲突，以及 FIleBeat中encoding配置的问题，修改之后无效，查看错误时候发现 logstash输入类型和filebeat输出不一致，解析出错(<a href="https://blog.csdn.net/momoudong/article/details/82017852" target="_blank" rel="noopener">https://blog.csdn.net/momoudong/article/details/82017852</a>)<br>最终 logstash 配置 test.conf|filebeat_kong.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">input&#123;</span><br><span class="line">   # file &#123;</span><br><span class="line">   #         path =&gt; &quot;/home/LAB/chengr/kong_log/file.log&quot;</span><br><span class="line">   #      &#125;</span><br><span class="line">   beats &#123;</span><br><span class="line">        type =&gt; &quot;nginx-log&quot; #&quot;logs&quot;</span><br><span class="line">        port =&gt; 9044</span><br><span class="line">          &#125;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">filter&#123;</span><br><span class="line">    json&#123; #获取nginx log日志</span><br><span class="line">        source =&gt; &quot;message&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    mutate&#123;# 删去logstash转化后保留的messegae字段</span><br><span class="line">            remove_field =&gt; [&quot;message&quot;]</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">output&#123;</span><br><span class="line">    stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;10.1.1.46:9200&quot;]</span><br><span class="line">        index =&gt; &quot;system-syslog-%&#123;+YYYY.MM&#125;&quot;</span><br><span class="line">        #document_type =&gt; &quot;logs&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>开启 logstash 命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ELK目录下</span><br><span class="line">ELK/logstash-5.6.3/bin/logstash -f /usr/local/ELK/logstash-5.6.3/config/test.conf(或filebeat_kong.conf)</span><br></pre></td></tr></table></figure><p>错误2：<br>更改完上一个错误后 发现报如下错误</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2019-04-01T21:45:13,592][WARN ][logstash.outputs.elasticsearch] Could not index event to Elasticsearch. &#123;:status=&gt;400, :action=&gt;[&quot;index&quot;, &#123;:_id=&gt;nil, :_index=&gt;&quot;system-syslog-2019.04&quot;, :_type=&gt;&quot;log&quot;, :_routing=&gt;nil&#125;, 2019-04-01T13:45:00.925Z bd46 %&#123;message&#125;], :response=&gt;&#123;&quot;index&quot;=&gt;&#123;&quot;_index&quot;=&gt;&quot;system-syslog-2019.04&quot;, &quot;_type&quot;=&gt;&quot;log&quot;, &quot;_id&quot;=&gt;&quot;Cf0l2WkB8VUaRp2hlmvH&quot;, &quot;status&quot;=&gt;400, &quot;error&quot;=&gt;&#123;&quot;type&quot;=&gt;&quot;illegal_argument_exception&quot;, &quot;reason&quot;=&gt;&quot;Rejecting mapping update to [system-syslog-2019.04] as the final mapping would have more than 1 type: [log, logs]&quot;&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure><p>百度后有人是因logstash输出类型与elasticsearch 要求不同导致，即更改logstash输出类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">document_type =&gt; &quot;logs&quot;</span><br></pre></td></tr></table></figure><p>filebeat 配置filebeat.yml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">filebeat.prospectors:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- input_type: log</span><br><span class="line"> # encoding: UTF-8</span><br><span class="line">  paths:</span><br><span class="line">    - /home/LAB/chengr/kong_log/file.log</span><br><span class="line">  json.keys_under_root: true #在一次部署中发现这一行不能识别，最终注释之解决</span><br><span class="line">  #json.add_error_key: true</span><br><span class="line">  #json.message_key: log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">output.logstash:</span><br><span class="line">  #The Logstash hosts</span><br><span class="line">  hosts: [&quot;10.1.1.46:9044&quot;]</span><br></pre></td></tr></table></figure><p>开启filebeat 命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ELK/filebeat-5.6.4-linux-x86_64/filebeat -path.config /usr/local/ELK/filebeat-5.6.4-linux-x86_64/</span><br></pre></td></tr></table></figure><p>elastcisearch 配置 config/elasticsearch.yml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cluster.name: my-es-cluster</span><br><span class="line">node.name: es-node-1</span><br><span class="line">path.data: /home/LAB/chengr/ELK/data/data-es</span><br><span class="line">path.logs: /home/LAB/chengr/ELK/log/log-es</span><br><span class="line">network.host: 10.1.1.46</span><br><span class="line">http.port: 9200</span><br></pre></td></tr></table></figure><p>开启 elastcisearch 命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ELK/elasticsearch-6.4.2/bin/elasticsearch</span><br></pre></td></tr></table></figure><p>kibana 配置 config/kibana.yml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server.port: 5601</span><br><span class="line">elasticsearch.url: &quot;http://10.1.1.46:9200&quot;</span><br></pre></td></tr></table></figure><p>开启 kibana 命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ELK/kibana-6.4.2-linux-x86_64/bin/kibana</span><br></pre></td></tr></table></figure><p>10.1.1.45   10.1.1.46 两台服务器以及192.168.1.242 主机（可显示）搭配<br>filebeat 两台服务器 上各配置一个，指向在10.1.1.46 上的 logstash ，logstash指向10.1.1.46上的elasticsearch ，指向 192.168.1.242上的kibana</p><p>2019-5-8<br>部署在实际机器上时将配置中ip改为对应的IP</p><p>kibana 添加邮件预警</p><ul><li><a href="http://www.cnblogs.com/small-k/p/8551960.html" target="_blank" rel="noopener">http://www.cnblogs.com/small-k/p/8551960.html</a></li><li><a href="https://blog.51cto.com/10546390/2051676" target="_blank" rel="noopener">https://blog.51cto.com/10546390/2051676</a></li></ul><p>2019-5-19 Error</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">2019-05-19 16:46:00.000highemail html alarmwatcher_titleActionError: html email action : obligatory options in email: from and to </span><br><span class="line">&#123;</span><br><span class="line">  &quot;@timestamp&quot;: &quot;2019-05-19T08:46:00.031Z&quot;,</span><br><span class="line">  &quot;error&quot;: true,</span><br><span class="line">  &quot;report&quot;: false,</span><br><span class="line">  &quot;watcher&quot;: &quot;watcher_title&quot;,</span><br><span class="line">  &quot;action&quot;: &quot;email html alarm&quot;,</span><br><span class="line">  &quot;level&quot;: &quot;high&quot;,</span><br><span class="line">  &quot;message&quot;: &quot;ActionError: html email action : obligatory options in email: from and to&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;sentinl-alarm&quot;,</span><br><span class="line">  &quot;_index&quot;: &quot;watcher_alarms-2019.05.19&quot;,</span><br><span class="line">  &quot;id&quot;: &quot;ClxEz2oBFTrgm4Wv5XBg&quot;</span><br><span class="line">#原因：这是由于在action 的Email属性中没有指明 to与 from 的邮箱</span><br></pre></td></tr></table></figure><p>配置kong日志格式更改  /etc/kong/kong.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">nigin_http_log_format= log_json &apos;&#123; &quot;@timestamp&quot;: &quot;$time_iso8601&quot;, &apos;</span><br><span class="line">&apos;&quot;remote_addr&quot;: &quot;$remote_addr&quot;, &apos;</span><br><span class="line">&apos;&quot;referer&quot;: &quot;$http_referer&quot;, &apos;</span><br><span class="line">&apos;&quot;request&quot;: &quot;$request&quot;, &apos;</span><br><span class="line">&apos;&quot;status&quot;: $status, &apos;</span><br><span class="line">&apos;&quot;bytes&quot;:$body_bytes_sent, &apos;</span><br><span class="line">&apos;&quot;agent&quot;: &quot;$http_user_agent&quot;, &apos;</span><br><span class="line">&apos;&quot;x_forwarded&quot;: &quot;$http_x_forwarded_for&quot;, &apos;</span><br><span class="line">&apos;&quot;upstr_addr&quot;: &quot;$upstream_addr&quot;,&apos;</span><br><span class="line">&apos;&quot;upstr_host&quot;: &quot;$upstream_http_host&quot;,&apos;</span><br><span class="line">&apos;&quot;ups_resp_time&quot;: &quot;$upstream_response_time&quot; &#125;&apos;;</span><br><span class="line"></span><br><span class="line">nginx_proxy_access_log logs/access.log log_json;</span><br></pre></td></tr></table></figure><p>ps:<a href="https://docs.konghq.com/0.13.x/configuration/?_ga=2.242544130.102618566.1558236281-1173907870.1558236281#proxy_access_log" target="_blank" rel="noopener">kong 相关配置文件</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Kong</title>
      <link href="/2019/03/26/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/kong/"/>
      <url>/2019/03/26/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/kong/</url>
      
        <content type="html"><![CDATA[<h2 id="kong">Kong</h2><p><a href="https://konghq.com/" target="_blank" rel="noopener">官网</a></p><h2 id="相关概念">相关概念</h2><p>consumer</p><blockquote></blockquote><p>service</p><blockquote></blockquote><p>route</p><blockquote></blockquote><p>upstream</p><blockquote></blockquote><p>plugin</p><blockquote><p><a href="https://docs.konghq.com/hub/" target="_blank" rel="noopener">官网</a> 包含 官方插件以及第三方插件<br><a href="https://github.com/walkdeadtobe/my_kong_plugin" target="_blank" rel="noopener">个人自定义插件</a></p></blockquote><h2 id="相关操作">相关操作</h2><p>创造 consumers</p><blockquote><p>curl -i -X POST  --url <a href="http://localhost:8001/consumers" target="_blank" rel="noopener">http://localhost:8001/consumers</a> --data “username=dzk”<br>给相应consumer 添加 basic-auth<br>curl -i -X POST  --url <a href="http://localhost:8001/consumers/e2dacbf6-117d-404f-8c40-58c305e4e669/basic-auth" target="_blank" rel="noopener">http://localhost:8001/consumers/e2dacbf6-117d-404f-8c40-58c305e4e669/basic-auth</a> --data “username=dzk” --data “password=dzk”<br>添加 ACL<br>curl -X POST <a href="http://localhost:8001/consumers/e2dacbf6-117d-404f-8c40-58c305e4e669/acls" target="_blank" rel="noopener">http://localhost:8001/consumers/e2dacbf6-117d-404f-8c40-58c305e4e669/acls</a> --data “group=group2”</p></blockquote><p>给相应服务添加 basic-auth ACL</p><blockquote><p>curl -X POST <a href="http://localhost:8001/services/ddj/plugins" target="_blank" rel="noopener">http://localhost:8001/services/ddj/plugins</a> --data “name=basic-auth” --data “config.hide_credentials=true”<br>curl -X POST <a href="http://localhost:8001/services/ddj/plugins" target="_blank" rel="noopener">http://localhost:8001/services/ddj/plugins</a> --data “name=acl” --data “config.whitelist=group1” --data “config.hide_groups_header=true”</p></blockquote><p>为kong添加 访问 admin 的外部服务</p><blockquote><p><a href="https://docs.gelato.io/guides/advanced-kong-integration" target="_blank" rel="noopener">https://docs.gelato.io/guides/advanced-kong-integration</a><br>curl -i -X POST  --url <a href="http://localhost:8001/services/" target="_blank" rel="noopener">http://localhost:8001/services/</a>  --data ‘name=admin’ --data ‘url=http://localhost:8001’<br>curl -i -X POST   --url <a href="http://localhost:8001/services/admin/routes" target="_blank" rel="noopener">http://localhost:8001/services/admin/routes</a>  --data ‘paths=/admin’ --data ‘strip_path=true’</p></blockquote><p>kong发送的信息不含用户consumer信息，使用datadog的log功能进行统计</p><p>datadog-agent 相关命令</p><blockquote><p>/etc/init.d/datadog-agent restart、stop<br>sudo datadog-agent check kong/status<br>systemctl start datadog-agent</p></blockquote><p>kong 数据库操作</p><blockquote><p>su - postgres<br>pslq<br>\c kong 切换数据库kong<br>select * from pg_tables 查看当前数据库所有的表</p></blockquote><p>更新 2019-4-18<br>给服务ACL 服务whitelist 添加 多个 group<br>出现问题，提交bug，kong开发大佬解决 ，附链接 <a href="https://github.com/Kong/kong/issues/4523" target="_blank" rel="noopener">https://github.com/Kong/kong/issues/4523</a><br>给插件 CORS 添加多个header<br>curl -X PATCH <a href="http://localhost:8001/plugins/8f407ede-33d2-43c3-b528-cb1f8a4ebec1" target="_blank" rel="noopener">http://localhost:8001/plugins/8f407ede-33d2-43c3-b528-cb1f8a4ebec1</a> <br>–data “config.headers=Origin” <br>–data “config.headers=X-Requested-With” <br>–data “config.headers=Content-Type” <br>–data “config.headers=Authorization” <br>–data “config.headers=Accept” <br>–data “config.headers=Accept-Version” <br>–data “config.headers=Content-Length” <br>–data “config.headers=Content-MD5” <br>–data “config.headers=Date” <br>–data “config.headers=X-Auth-Token”</p><p>更新 2019-6-22<br>在查询kong的服务数目时，发现postgresql数据库的services数目与 curl <a href="http://localhost:8001/services" target="_blank" rel="noopener">http://localhost:8001/services</a> 数目不同，最后在github源码中发现 在api中设置最大返回值为100;唔在考虑从源码编译修改，但是安装会很蛋疼</p><h2 id="插件使用">插件使用</h2><p>kong_datadog_agent</p><blockquote><p>更爱配置文件后出现</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2019/03/27 22:48:13 config.load While parsing config: yaml: line 291: did not find expected key</span><br><span class="line">Cannot setup config, exiting: unable to load Datadog config file: While parsing config: yaml: line 291: did not find expected key</span><br><span class="line">Error: unable to load Datadog config file: While parsing config: yaml: line 291: did not find expected key</span><br></pre></td></tr></table></figure><blockquote><p>最终发现是因为 更改配置时，没有对齐行开始（坑爹）</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> kong plugin consumer service route </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bp+rbf+lstm</title>
      <link href="/2019/03/23/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/bp-rbf-lstm/"/>
      <url>/2019/03/23/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/bp-rbf-lstm/</url>
      
        <content type="html"><![CDATA[<p>fisher +感知器  属于   线性分类器</p><p>人工神经网络（DP）  对比    径向基函数（RBF：神经元不只是感知器）<br>LSTM<br>模式识别 思考题 5000男+5000女 特征 分类</p>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ABAC</title>
      <link href="/2019/03/20/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/ABAC/"/>
      <url>/2019/03/20/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/ABAC/</url>
      
        <content type="html"><![CDATA[<p>ABAC:Attribute Based Access Control<br>abaC 介绍视频： <a href="https://www.youtube.com/watch?v=cgTa7YnGfHA" target="_blank" rel="noopener">https://www.youtube.com/watch?v=cgTa7YnGfHA</a><br>+<br><a href="https://www.youtube.com/watch?v=gskKUIa0_6A" target="_blank" rel="noopener">https://www.youtube.com/watch?v=gskKUIa0_6A</a><br>An Attribute Based Access Control Model for RESTful Service：一篇相关论文，其视频：<a href="https://www.youtube.com/watch?v=hDlr66-4paI" target="_blank" rel="noopener">https://www.youtube.com/watch?v=hDlr66-4paI</a></p><p>相关概念延伸：XACML</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>多元正态分布密度</title>
      <link href="/2019/03/18/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Multivariate-normal-distribution-density/"/>
      <url>/2019/03/18/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Multivariate-normal-distribution-density/</url>
      
        <content type="html"><![CDATA[<p>公式推到 建议 word<br><a href="https://blog.csdn.net/qq_23869697/article/details/80610361" target="_blank" rel="noopener">https://blog.csdn.net/qq_23869697/article/details/80610361</a><br><a href="https://baike.baidu.com/item/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/9822183?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/协方差矩阵/9822183?fr=aladdin</a></p><p>$$ \varphi ([u_{1},u_{2}…,u_{d}]^{T})\begin{cases}<br>&amp; \text{1       if } \left | u_{j} \right |\leq \frac{1}{2} \space , \space j=1,2,…,d \<br>&amp; \text{0       esle }<br>\end{cases} $$</p><p>$$ x\in R^{d} $$</p><p>$$ V=h^{d} $$</p>]]></content>
      
      
      
        <tags>
            
            <tag> 模式识别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>素数问题：艾拉欧拉筛法</title>
      <link href="/2019/03/18/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%B4%A0%E6%95%B0%E9%97%AE%E9%A2%98%EF%BC%9A%E8%89%BE%E6%8B%89%E6%AC%A7%E6%8B%89%E7%AD%9B%E6%B3%95/"/>
      <url>/2019/03/18/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%B4%A0%E6%95%B0%E9%97%AE%E9%A2%98%EF%BC%9A%E8%89%BE%E6%8B%89%E6%AC%A7%E6%8B%89%E7%AD%9B%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>参考博客</p><p><a href="https://blog.csdn.net/hzaukotete/article/details/81103528" target="_blank" rel="noopener">https://blog.csdn.net/hzaukotete/article/details/81103528</a></p><p><a href="https://blog.csdn.net/qq_39763472/article/details/82428602" target="_blank" rel="noopener">https://blog.csdn.net/qq_39763472/article/details/82428602</a></p><p>$$  J_\alpha(x) = \sum_{m=0}^\infty \frac{(-1)^m}{m! \Gamma (m + \alpha + 1)} {\left({ \frac{x}{2} }\right)}^{2m + \alpha} \text {，行内公式示例}  $$<br>$ \ \ \ $<br>$$ \int_{0}^{1}{\frac{\pi}{2}}\sin(x)\space dx $$<br>$$ \int_{0}^{} $$<br>$$ \space{12pt}  $$</p>]]></content>
      
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>microservice-about-resource</title>
      <link href="/2019/03/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BE%AE%E6%9C%8D%E5%8A%A1/microservice-about-resource/"/>
      <url>/2019/03/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BE%AE%E6%9C%8D%E5%8A%A1/microservice-about-resource/</url>
      
        <content type="html"><![CDATA[<p>Ouath 2.0 授权协议 相关 <a href="http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html</a>   + <a href="https://www.cnblogs.com/flashsun/p/7424071.html" target="_blank" rel="noopener">https://www.cnblogs.com/flashsun/p/7424071.html</a></p><p>MOngodb 数据库操作<br><a href="http://www.runoob.com/mongodb/mongodb-analyzing-queries.html" target="_blank" rel="noopener">http://www.runoob.com/mongodb/mongodb-analyzing-queries.html</a><br>+<br><a href="https://docs.spring.io/spring-data/mongodb/docs/current/reference/html/#mongodb-connectors" target="_blank" rel="noopener">https://docs.spring.io/spring-data/mongodb/docs/current/reference/html/#mongodb-connectors</a></p><p>API 网关测试<br><a href="https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2018/11/08/kong-features-06-production-and-benchmark.html#%E4%BB%8E%E8%AF%B7%E6%B1%82%E7%AB%AF%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AEpod" target="_blank" rel="noopener">https://www.lijiaocn.com/项目/2018/11/08/kong-features-06-production-and-benchmark.html#从请求端直接访问pod</a><br>+<br><a href="https://www.codercto.com/a/48944.html" target="_blank" rel="noopener">https://www.codercto.com/a/48944.html</a></p><p>微服务授权（服务注册与发现等） 以及系列化 博客<br><a href="https://segmentfault.com/a/1190000007689560" target="_blank" rel="noopener">https://segmentfault.com/a/1190000007689560</a><br>+<br><a href="https://www.cnblogs.com/bluedoctor/p/8967951.html" target="_blank" rel="noopener">https://www.cnblogs.com/bluedoctor/p/8967951.html</a><br>+<br><a href="http://emacoo.cn/arch/microservice-overview/" target="_blank" rel="noopener">http://emacoo.cn/arch/microservice-overview/</a></p><p>单点登录<br><a href="https://yq.aliyun.com/articles/636281" target="_blank" rel="noopener">https://yq.aliyun.com/articles/636281</a></p><p>kong网关<br><a href="http://www.blogjava.net/coolfiry/archive/2018/01/05/433005.html" target="_blank" rel="noopener">http://www.blogjava.net/coolfiry/archive/2018/01/05/433005.html</a></p><p>$$ \int_{0}^{1}{\frac{\pi}{2}}\sin(x)\space dx $$</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>KNN</title>
      <link href="/2019/03/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/KNN/"/>
      <url>/2019/03/14/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/KNN/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">def knearestEstimate(sampleSet,k):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    K近邻非参数估计方法</span><br><span class="line">    Args:</span><br><span class="line">        sampleSet:样本向量的集合</span><br><span class="line">        k:用于计算近邻数Kn的常数</span><br><span class="line">    Returns:</span><br><span class="line">        估计的概率密度函数</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    n,d=np.shape(sampleset)</span><br><span class="line">    m=(k*n**0.5)</span><br><span class="line">    def probability(sample):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        K近邻非参数估计得到的概率密度函数</span><br><span class="line">        Args:</span><br><span class="line">            sampleSet:概率密度待估计的样本向量</span><br><span class="line">        Returns:</span><br><span class="line">            估计的概率密度</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        dist=[]</span><br><span class="line">        for p in sampleSet-sample:</span><br><span class="line">            dist.append((np.sum(p**2))**0.5)</span><br><span class="line">        np.sort(np.array(dist))</span><br><span class="line">        r=dist[int(m)]</span><br><span class="line">        v=math.pi**(d/2)*r**d/math.gamma(d/2+1)</span><br><span class="line">        return m/n/v</span><br><span class="line">    return probability</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.sum(p**2))**0.5</span><br></pre></td></tr></table></figure><p>即  $$ \sqrt{(x_{1}-y_{1})^2+(x_{2}-y_{2})^2} $$</p><p>n纬球体的体积公式为(<a href="https://spaces.ac.cn/archives/3154" target="_blank" rel="noopener">https://spaces.ac.cn/archives/3154</a>) $$ V_{n}®= \frac{2\pi^{\frac{n}{2}}}{ \Gamma (\frac{n}{2})}r^{n-1} $$</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>service discovery and register</title>
      <link href="/2019/03/13/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/service-discovery-and-register/"/>
      <url>/2019/03/13/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/service-discovery-and-register/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/uzGF5b4sn1DeSc1F1FOGRA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/uzGF5b4sn1DeSc1F1FOGRA</a></p><p>微信 上关于微服务发现的推文<br>服务发现背后的基本思想是对于服务的每一个新实例（或应用程序），能够识别当前环境和存储相关信息。存储的注册表信息本身通常采用键/值对的格式，由于服务发现经常用于分布式系统，所以要求这些信息可伸缩、支持容错和分布式集群中的所有节点</p><p>做到服务发现之前首先需要做到的是提供服务注册表，供服务消毒费查询<br>同时注册表应当保持高可用，大多以键值对的形式存在</p><p>Zookeeper</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>openresty_source_compile</title>
      <link href="/2019/03/08/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/openresty-source-compile/"/>
      <url>/2019/03/08/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/openresty-source-compile/</url>
      
        <content type="html"><![CDATA[<p>最近调研APIGateway，目前主要在研究 kong 的东西，打算在服务器上布置环境，测试其性能<br>系统环境：<br>操作系统版本：Linux version 4.4.0-134-generic (buildd@lgw01-amd64-033) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.10) )</p><p>用户目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">×××@bd45:~$ tree -L 1  </span><br><span class="line">.  </span><br><span class="line">|-- apr  </span><br><span class="line">|-- apr-1.4.5  </span><br><span class="line">|-- apr-1.4.5.tar.gz  </span><br><span class="line">|-- apr-util  </span><br><span class="line">|-- apr-util-1.3.12  </span><br><span class="line">|-- apr-util-1.3.12.tar.gz  </span><br><span class="line">|-- download_file?file_path=dists%2Fkong-community-edition-1.0.3.xenial.all.deb </span><br><span class="line">|-- httpd  </span><br><span class="line">|-- httpd-2.4.38  </span><br><span class="line">|-- httpd-2.4.38.tar.gz  </span><br><span class="line">|-- kong  </span><br><span class="line">|-- kong_source  </span><br><span class="line">|-- lua-5.3.4  </span><br><span class="line">|-- lua-5.3.4.tar.gz  </span><br><span class="line">|-- luarocks  </span><br><span class="line">|-- nginx  </span><br><span class="line">|-- nginx-1.15.9  </span><br><span class="line">|-- nginx-1.15.9.tar.gz  </span><br><span class="line">|-- openresty  </span><br><span class="line">|-- openresty-1.13.6.2  </span><br><span class="line">|-- openresty-1.13.6.2.tar.gz</span><br><span class="line">|-- openssl</span><br><span class="line">|-- openssl-1.0.2r</span><br><span class="line">|-- openssl-1.0.2r.tar.gz</span><br><span class="line">|-- pcre</span><br><span class="line">|-- pcre-8.43</span><br><span class="line">|-- pcre-8.43.tar.gz</span><br><span class="line">|-- postgresql</span><br><span class="line">|-- postgresql-11.2</span><br><span class="line">|-- postgresql-11.2.tar.gz</span><br><span class="line">|-- siege</span><br><span class="line">|-- siege-4.0.4</span><br><span class="line">`-- siege-4.0.4.tar.gz</span><br></pre></td></tr></table></figure><p>安装pcre</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -# -O  https://ftp.pcre.org/pub/pcre/pcre-8.43.tar.gz</span><br><span class="line">./configure --prefix=/home/LAB/chengr/pcre </span><br><span class="line">./configure --prefix=/home/LAB/chengr/nginx --with-pcre=/home/LAB/chengr/pcre-8.43</span><br></pre></td></tr></table></figure><p>安装zlib</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://prdownloads.sourceforge.net/libpng/zlib-1.2.11.tar.gz</span><br><span class="line"> ./configure  --prefix=/home/LAB/chengr/zlib</span><br><span class="line"> make &amp;&amp; make check &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>安装 nginx，官网配置说明 ：<a href="https://nginx.org/en/docs/configure.html" target="_blank" rel="noopener">https://nginx.org/en/docs/configure.html</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">curl -# -O http://nginx.org/download/nginx-1.15.8.tar.gz</span><br><span class="line">tar -zvxf nginx-1.15.8.tar.gz</span><br><span class="line">cd nginx-1.15.8</span><br><span class="line">(./configure: error: the HTTP rewrite module requires the PCRE library.)</span><br><span class="line">(./configure: error: the HTTP magzip module requires the zlib library.)</span><br><span class="line">与nginx模块一起编译，要求指定源码目录</span><br><span class="line">./configure --prefix=/home/LAB/chengr/nginx  --with-pcre=/home/LAB/chengr/pcre-8.39  --with-zlib=/home/LAB/chengr/zlib-1.2.11</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>下载openssl(配置openresty)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -# -O https://www.openssl.org/source/openssl-1.0.2r.tar.gz(https://www.openssl.org/source/)</span><br><span class="line">tar -zvxf openssl-1.0.2r.tar.gz</span><br><span class="line">./config --prefix=/home/LAB/chengr/openssl  -fPIC no-gost no-shared no-zlib</span><br><span class="line">make depend</span><br></pre></td></tr></table></figure><p>安装luarock:<br>按照教程来 <a href="https://github.com/luarocks/luarocks/wiki/Installation-instructions-for-Unix" target="_blank" rel="noopener">https://github.com/luarocks/luarocks/wiki/Installation-instructions-for-Unix</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">（其中configure 改为./configure    --prefix=/home/LAB/chengr/luarocks   --lua-suffix=jit    --with-lua=/home/LAB/chengr/openresty/luajit    --with-lua-include=/home/LAB/chengr/openresty/luajit/include/luajit-2.1）</span><br><span class="line">make</span><br><span class="line">  make install</span><br><span class="line">  make bootstrap</span><br></pre></td></tr></table></figure><p>安装 openresty 官网教程：<a href="https://openresty.org/cn/installation.html" target="_blank" rel="noopener">https://openresty.org/cn/installation.html</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">curl -# -O https://openresty.org/download/openresty-1.13.6.2.tar.gz  </span><br><span class="line">tar -xzvf openresty-1.13.6.2.tar.gz  </span><br><span class="line">cd cd openresty-1.13.6.2  </span><br><span class="line">mkdir openresty  </span><br><span class="line">./configure --prefix=/home/LAB/chengr/openresty  --with-luajit --with-stream   --with-http_iconv_module --with-http_realip_module   --with-ld-opt=&quot;-Wl,-rpath,/usr/local/lib&quot;  --with-http_stub_status_module   --with-http_ssl_module --with-http_sub_module  </span><br><span class="line">//按照kong官网要求加上如下配置  </span><br><span class="line">   --with-pcre-jit </span><br><span class="line">   --with-http_ssl_module </span><br><span class="line">   --with-http_realip_module </span><br><span class="line">   --with-http_stub_status_module </span><br><span class="line">   --with-http_v2_module   </span><br><span class="line">   --with-openssl=/home/LAB/chengr/openssl-1.0.2r</span><br><span class="line"></span><br><span class="line">make   </span><br><span class="line">sudo make install</span><br><span class="line">【】</span><br></pre></td></tr></table></figure><p>安装postgresql （官网教程：<a href="https://www.postgresql.org/docs/current/install-procedure.html%EF%BC%89" target="_blank" rel="noopener">https://www.postgresql.org/docs/current/install-procedure.html）</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -# -O https://ftp.postgresql.org/pub/source/v11.2/postgresql-11.2.tar.gz</span><br></pre></td></tr></table></figure><p>按安装性能测试工具：siege ab</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl -# -O http://download.joedog.org/siege/siege-4.0.4.tar.gz</span><br><span class="line">tar -zvxf siege-4.0.4.tar.gz   </span><br><span class="line">cd siege-4.0.4</span><br><span class="line">./configure --prefix=/home/LAB/chengr/siege  </span><br><span class="line">make     </span><br><span class="line">sudo make install   </span><br><span class="line"> siege/bin/siege –help</span><br></pre></td></tr></table></figure><hr><p>ab（需要提前安装 apr 、apr-util、pcre、openssl）<br>apr</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://archive.apache.org/dist/apr/apr-1.4.5.tar.gz</span><br><span class="line">tar -zxf apr-1.4.5.tar.gz  </span><br><span class="line">cd  apr-1.4.5  </span><br><span class="line">./configure --prefix=/home/LAB/chengr/apr  </span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>apr-util</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://archive.apache.org/dist/apr/apr-util-1.3.12.tar.gz</span><br><span class="line">tar -zxf apr-util-1.3.12.tar.gz</span><br><span class="line">cd apr-util-1.3.12</span><br><span class="line">./configure --prefix=/home/LAB/chengr/apr-util --with-apr=/home/LAB/chengr/apr/</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>pcre</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://jaist.dl.sourceforge.net/project/pcre/pcre/8.39/pcre-8.39.tar.gz</span><br><span class="line">tar -zxf pcre-8.39.tar.gz</span><br><span class="line">cd pcre-8.10</span><br><span class="line">./configure --prefix=/home/LAB/chengr/pcre</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>最终安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd httpd-2.4.38</span><br><span class="line">./configure --prefix=/home/LAB/chengr/httpd --with-apr=/home/LAB/chengr/apr --with-apr-util=/home/LAB/chengr/apr-util --with-pcre=/home/LAB/chengr/pcre --enable-ssl --with-ssl=/home/LAB/chengr/openssl</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>curl -# -O <a href="https://www-us.apache.org/dist//httpd/httpd-2.4.38.tar.gz" target="_blank" rel="noopener">https://www-us.apache.org/dist//httpd/httpd-2.4.38.tar.gz</a></p><p>按照教程安装 <a href="https://www.cnblogs.com/chevin/p/10222681.html" target="_blank" rel="noopener">https://www.cnblogs.com/chevin/p/10222681.html</a></p><p>（下载 httpd wget <a href="https://www.apache.org/dist/httpd/httpd-2.4.38.tar.gz" target="_blank" rel="noopener">https://www.apache.org/dist/httpd/httpd-2.4.38.tar.gz</a> ）</p><p>./config --prefix=/home/LAB/chengr/openssl  -fPIC no-gost no-shared no-zlib<br>make depend<br>解决：<a href="http://www.bubuko.com/infodetail-621556.html" target="_blank" rel="noopener">http://www.bubuko.com/infodetail-621556.html</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">chengr@bd46:~$ tree -L 2 -d</span><br><span class="line">.</span><br><span class="line">|-- apr</span><br><span class="line">|   |-- bin</span><br><span class="line">|   `-- lib</span><br><span class="line"></span><br><span class="line">|-- apr-util</span><br><span class="line">|   |-- bin</span><br><span class="line">|   `-- lib</span><br><span class="line">|-- httpd</span><br><span class="line">|   |-- bin</span><br><span class="line">|   |-- build</span><br><span class="line">|   |-- cgi-bin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">|-- openssl</span><br><span class="line">|   |-- bin</span><br><span class="line">|   |-- lib</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">|   `-- VMS</span><br><span class="line">|-- pcre</span><br><span class="line">|   |-- bin</span><br><span class="line">|   |-- lib</span><br><span class="line"></span><br><span class="line">|-- siege</span><br><span class="line">|   |-- bin</span><br></pre></td></tr></table></figure><p>添加到环境变量中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">#add for apr 2019-3-10</span><br><span class="line">export APR_HOME=/home/LAB/chengr/apr</span><br><span class="line">export PATH=$PATH:$APR_HOME/bin</span><br><span class="line">#export LIB_PATH+=$APR_HOME/lib</span><br><span class="line">#end</span><br><span class="line"></span><br><span class="line">#add for apr-util 2019-3-10</span><br><span class="line">export APRUTIL_HOME=/home/LAB/chengr/apr-util</span><br><span class="line">export PATH=$PATH:$APRUTIL_HOME/bin</span><br><span class="line">#export LIB_PATH+=$APRUTIL_HOME/lib</span><br><span class="line">#end</span><br><span class="line"></span><br><span class="line">#add for httpd 2019-3-10</span><br><span class="line">export HTTPD_HOME=/home/LAB/chengr/httpd</span><br><span class="line">export PATH=$PATH:$HTTPD_HOME/bin</span><br><span class="line">#export LIB_PATH+=$HTTPD_HOME/lib</span><br><span class="line">#end</span><br><span class="line"></span><br><span class="line">#add for openssl 2019-3-10</span><br><span class="line">export OPENSSL_HOME=/home/LAB/chengr/openssl</span><br><span class="line">export PATH=$PATH:$OPENSSL_HOME/bin</span><br><span class="line">#export LIB_PATH+=$OPENSSL_HOME/lib</span><br><span class="line">#end</span><br><span class="line"></span><br><span class="line">#add for pcre 2019-3-10</span><br><span class="line">export PCRE_HOME=/home/LAB/chengr/pcre</span><br><span class="line">export PATH=$PATH:$PCRE_HOME/bin</span><br><span class="line">#export LIB_PATH+=$HTTPD_HOME/lib</span><br><span class="line">#end</span><br><span class="line"></span><br><span class="line">#add for siege 2019-3-10</span><br><span class="line">export SIEGE_HOME=/home/LAB/chengr/siege</span><br><span class="line">export PATH=$PATH:$SIEGE_HOME/bin</span><br><span class="line">#end</span><br><span class="line"></span><br><span class="line">#add for luarocks 2019-3-10</span><br><span class="line">export LUAROCKS_HOME=/home/LAB/chengr/luarocks</span><br><span class="line">export PATH=$PATH:$LUAROCKS_HOME/bin</span><br><span class="line">#export LIB_PATH+=$LUAROCKS_HOME/lib</span><br><span class="line">#end</span><br><span class="line"></span><br><span class="line">#add for nginx 2019-3-10</span><br><span class="line">export NGINX_HOME=/home/LAB/chengr/nginx</span><br><span class="line">export PATH=$PATH:$NGINX_HOME/sbin</span><br><span class="line">#end</span><br><span class="line"></span><br><span class="line">#add for openresty 2019-3-10</span><br><span class="line">export OPENRESTY_HOME=/home/LAB/chengr/openresty</span><br><span class="line">export PATH=$PATH:$OPENRESTY_HOME/bin</span><br><span class="line">#export LIB_PATH+=$OPENRESTY_HOME/lib</span><br><span class="line">#end</span><br><span class="line"></span><br><span class="line">#add for postgresql 2019-3-10</span><br><span class="line">export POSTGRESQL_HOME=/home/LAB/chengr/postgresql</span><br><span class="line">export PATH=$PATH:$POSTGRESQL_HOME/bin</span><br><span class="line">#export LIB_PATH+=$POSTGRESQL_HOME/lib</span><br><span class="line">#end</span><br></pre></td></tr></table></figure><p>jhipster<br><a href="https://blog.csdn.net/zhao50632/article/details/54582177" target="_blank" rel="noopener">https://blog.csdn.net/zhao50632/article/details/54582177</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>nginx+mongodb</title>
      <link href="/2019/03/06/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/nginx-mongodb/"/>
      <url>/2019/03/06/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/nginx-mongodb/</url>
      
        <content type="html"><![CDATA[<br>  install luarock:https://blog.csdn.net/kgzhang/article/details/72885199  <br>  install lua_nginx_moudle https://www.cnblogs.com/uglyliu/p/8534473.html<br>install nginx-gridfx https://blog.csdn.net/jameshadoop/article/details/52665342  + https://blog.csdn.net/caiwenfeng_for_23/article/details/44230513 +https://github.com/mdirolf/nginx-gridfs<p>./configure --user=nginx --group=nginx --prefix=/usr/local/nginx  --with-http_realip_module --with-http_stub_status_module --with-http_ssl_module --with-http_flv_module --with-http_gzip_static_module --with-cc-opt=-Wno-error --with-stream --add-module=/opt/nginx_module/ngx_devel_kit --add-module=/opt/nginx_module/lua-nginx-module --add-module=/opt/nginx_module/nginx-gridfs</p><p>./configure --user=nginx --group=nginx --prefix=/usr/local/nginx --with-cc-opt=-Wno-error --add-module=/opt/nginx_module/ngx_devel_kit --add-module=/opt/nginx_module/lua-nginx-module --add-module=/opt/nginx_module/nginx-gridfs</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>API_Key</title>
      <link href="/2019/03/06/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/API-Key/"/>
      <url>/2019/03/06/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/API-Key/</url>
      
        <content type="html"><![CDATA[<h2 id="how-kong-generate-api-key-in-plugin-key-auth">How Kong  generate api key in plugin key-auth</h2><p>在 github <a href="https://github.com/Kong/kong" target="_blank" rel="noopener">https://github.com/Kong/kong</a> ，我们可以看到关于Kong的代码<br>在https://github.com/eyolas/kong-plugin-key-auth-referer/blob/master/kong/plugins/key-auth-referer/daos.lua 上，我们可以看到其中包含代码<br><code>local utils = require &quot;kong.tools.utils&quot;</code><br><code> key = {type = &quot;string&quot;, required = false, unique = true, default = utils.random_string}</code><br>按照目录搜索<code>https://github.com/Kong/kong/blob/master/kong/tools/utils.lua</code>，从中可以查询到函数<code>random_string</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">local function random_string()</span><br><span class="line">    -- get 24 bytes, which will return a 32 char string after encoding</span><br><span class="line">    -- this is done in attempt to maintain backwards compatibility as</span><br><span class="line">    -- much as possible while improving the strength of this function</span><br><span class="line">    return encode_base64(get_rand_bytes(24, true))</span><br><span class="line">           :gsub(&quot;/&quot;, char(rand(48, 57)))  -- 0 - 10</span><br><span class="line">           :gsub(&quot;+&quot;, char(rand(65, 90)))  -- A - Z</span><br><span class="line">           :gsub(&quot;=&quot;, char(rand(97, 122))) -- a - z</span><br><span class="line">  end</span><br></pre></td></tr></table></figure><p>由此可知，当使用key-auth插件，但不指明key值时，就会默认自动生成 24位字符，对于产生的特殊字符进行替换</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
